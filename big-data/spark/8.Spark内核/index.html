<!-- build time:Tue Aug 31 2021 19:51:18 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/atom.xml"><link rel="alternate" type="application/json" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://github.com/Mayizono/miyazono.github.io/big-data/spark/8.Spark%E5%86%85%E6%A0%B8/"><title>| Yume Shoka = 冬樱茶</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline"></h1><div class="meta"><span class="item" title="创建时间：2021-08-31 18:42:35"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-08-31T18:42:35+08:00">2021-08-31</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>30k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>27 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Yume Shoka</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gicliwyw55j20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giciuv0socj20zk0m8qes.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipey84bjtj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipexoj0moj20zk0m8kgu.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1giclfb3vzhj20zk0m8wny.jpg"></li><li class="item" data-background-image="https://tva2.sinaimg.cn/large/6833939bly1gipet8c1a2j20zk0m8kct.jpg"></li></ul></div><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div></header><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://github.com/Mayizono/miyazono.github.io/big-data/spark/8.Spark%E5%86%85%E6%A0%B8/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Miyazono"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="冬樱茶"></span><div class="body md" itemprop="articleBody"><h1 id="spark内核"><a class="anchor" href="#spark内核">#</a> Spark 内核</h1><hr><blockquote><p>所谓的内核，就是 Spark 内部核心原理。</p></blockquote><h2 id="一-内核解析的分解"><a class="anchor" href="#一-内核解析的分解">#</a> 一、内核解析的分解</h2><ol><li>Spark 应用的提交</li><li>Spark 内部的通信</li><li>Spark 作业的调度</li><li>任务的执行</li><li>spark 内存管理</li></ol><h2 id="二-sparksubmit"><a class="anchor" href="#二-sparksubmit">#</a> 二、 SparkSubmit</h2><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 本章节讲述 job 提交应用以后，环境的准备工作。主要包含以下：</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> spark向yarn提交job的过程</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> yarn中application、driver、executor、container是如何相互响应</pre></td></tr></table></figure><ul><li>提交应用</li></ul><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre>bin<span class="token operator">/</span>spark<span class="token operator">-</span>submit \</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">--class org.apache.spark.examples.SparkPi \</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">--master yarn \</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">--deploymode cluster \   表示 yarn 的集群模式</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token punctuation">.</span><span class="token operator">/</span>examples<span class="token operator">/</span>jars<span class="token operator">/</span>spark<span class="token operator">-</span>examples_2<span class="token punctuation">.</span><span class="token number">12</span><span class="token operator">-</span><span class="token number">2.4</span><span class="token number">.5</span><span class="token punctuation">.</span>jar \</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">10</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment">-- 说明：</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment">--master yarn 默认是采用 yarn 的客户端模式，但是在实际过程中，我们都是使用 yarn 的集群模式。</span></pre></td></tr><tr><td data-num="10"></td><td><pre>所以增加：<span class="token comment">--deploymode cluster \</span></pre></td></tr></table></figure><h3 id="21-spark向yarn提交"><a class="anchor" href="#21-spark向yarn提交">#</a> 2.1 Spark 向 yarn 提交</h3><h4 id="211-sparksubmit"><a class="anchor" href="#211-sparksubmit">#</a> 2.1.1 SparkSubmit</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 作用：</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 解析参数</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> 提交参数，初始数环境，并获取<span class="token string">"org.apache.spark.deploy.yarn.YarnClusterApplication"</span>的对象，调用对象的<span class="token keyword">start</span>方法</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 执行SparkSubmit的mian方法</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> 在main方法中：</pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token number">1</span>）、 new SparkSubmit</pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token number">2</span>）、 submit<span class="token punctuation">.</span>doSubmit<span class="token punctuation">(</span>args<span class="token punctuation">)</span> <span class="token comment">--> 执行提交程序，点击 doSubmit</span></pre></td></tr><tr><td data-num="5"></td><td><pre>          ①、 val appArgs <span class="token operator">=</span> parseArguments<span class="token punctuation">(</span>args<span class="token punctuation">)</span>  <span class="token comment">--> 解析参数，解析应用提交的参数，点击 parseArguments</span></pre></td></tr><tr><td data-num="6"></td><td><pre>                  a、parse<span class="token punctuation">(</span>args<span class="token punctuation">.</span>asJava<span class="token punctuation">)</span>   <span class="token comment">--> 具体进行参数的解析，点击 parse，返回参数的解析，方法的内部调用了 handle 方法</span></pre></td></tr><tr><td data-num="7"></td><td><pre>                     <span class="token keyword">action</span> <span class="token operator">=</span> <span class="token keyword">Option</span><span class="token punctuation">(</span><span class="token keyword">action</span><span class="token punctuation">)</span><span class="token punctuation">.</span>getOrElse<span class="token punctuation">(</span>SUBMIT<span class="token punctuation">)</span>，<span class="token comment">--> 默认值为 submit</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                  b、handle<span class="token punctuation">(</span>opt: String<span class="token punctuation">,</span> <span class="token keyword">value</span>: String<span class="token punctuation">)</span> <span class="token comment">-->opt: 参数的名称，value：参数的值。</span></pre></td></tr><tr><td data-num="9"></td><td><pre>                      左边是参数  <span class="token operator">=</span><span class="token operator">></span> 右边是赋值的变量</pre></td></tr><tr><td data-num="10"></td><td><pre>                     <span class="token comment">// --master yarn => master</span></pre></td></tr><tr><td data-num="11"></td><td><pre>                     <span class="token comment">// --deploy-mode cluster => deployMode</span></pre></td></tr><tr><td data-num="12"></td><td><pre>                     <span class="token comment">// --class SparkPI(WordCount) => 【mainClass】</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                     </pre></td></tr><tr><td data-num="14"></td><td><pre>          <span class="token string">"如上为解析参数"</span></pre></td></tr><tr><td data-num="15"></td><td><pre>       ②、appArgs<span class="token punctuation">.</span><span class="token keyword">action</span> <span class="token keyword">match</span> &#123;<span class="token keyword">case</span> SparkSubmitAction<span class="token punctuation">.</span>SUBMIT <span class="token operator">=</span><span class="token operator">></span> submit<span class="token punctuation">(</span>appArgs<span class="token punctuation">,</span> uninitLog<span class="token punctuation">)</span><span class="token comment">--> 点击 submit</span></pre></td></tr><tr><td data-num="16"></td><td><pre>          a、submit中又调用了doRunMain<span class="token punctuation">(</span><span class="token punctuation">)</span>，doRunMain<span class="token punctuation">(</span><span class="token punctuation">)</span>中调用了runMain<span class="token punctuation">(</span><span class="token punctuation">)</span>方法</pre></td></tr><tr><td data-num="17"></td><td><pre>              <span class="token comment">-- runMain (args, uninitLog)，运行主程序，在 runmain () 方法中：</span></pre></td></tr><tr><td data-num="18"></td><td><pre>                  <span class="token number">1.</span>准备提交环境</pre></td></tr><tr><td data-num="19"></td><td><pre>                  <span class="token comment">-- val (childArgs, childClasspath, sparkConf, childMainClass) = prepareSubmitEnvironment(args)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>                  </pre></td></tr><tr><td data-num="21"></td><td><pre>                  <span class="token number">2.</span>设定当前类的加载器</pre></td></tr><tr><td data-num="22"></td><td><pre>                  <span class="token comment">-- Thread.currentThread.setContextClassLoader(loader)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>                  </pre></td></tr><tr><td data-num="24"></td><td><pre>                  <span class="token number">3.</span>通过类名加载这个类，<span class="token string">'反射的方式'</span></pre></td></tr><tr><td data-num="25"></td><td><pre>                  <span class="token comment">-- mainClass = Utils.classForName(childMainClass)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>                  </pre></td></tr><tr><td data-num="27"></td><td><pre>                  <span class="token number">4.</span>创建第<span class="token number">3</span>步类的实例，并将类型转换为SparkApplication</pre></td></tr><tr><td data-num="28"></td><td><pre>                  <span class="token comment">-- app: SparkApplication = mainClass.newInstance().asInstanceOf[SparkApplication]</span></pre></td></tr><tr><td data-num="29"></td><td><pre>                  </pre></td></tr><tr><td data-num="30"></td><td><pre>                   childMainClass到底是谁？</pre></td></tr><tr><td data-num="31"></td><td><pre>                       cluster模式：childMainClass <span class="token operator">=</span> YARN_CLUSTER_SUBMIT_CLASS</pre></td></tr><tr><td data-num="32"></td><td><pre>                                   <span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>deploy<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>YarnClusterApplication</pre></td></tr><tr><td data-num="33"></td><td><pre>                       client模式：childMainClass <span class="token operator">=</span> args<span class="token punctuation">.</span>mainClass<span class="token operator">=</span>class SparkPI<span class="token punctuation">(</span>WordCount<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre>                    </pre></td></tr><tr><td data-num="35"></td><td><pre>                   <span class="token number">5.</span>YarnClusterApplication<span class="token punctuation">.</span><span class="token keyword">start</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                   <span class="token comment">--  app.start(childArgs.toArray, sparkConf)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>                   </pre></td></tr><tr><td data-num="38"></td><td><pre>             <span class="token string">"如上为提交环境，并启动org.apache.spark.deploy.yarn.YarnClusterApplication"</span></pre></td></tr></table></figure><h4 id="222-yarnyarnclusterapplication"><a class="anchor" href="#222-yarnyarnclusterapplication">#</a> 2.2.2 yarn.YarnClusterApplication</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 作用：</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 调用YarnClusterApplication的<span class="token keyword">start</span>方法，创建yarn的resourcemanagerClient，RM的客户端</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> 执行RM客户端执行run方法</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3.</span> 在run方法中，启动一个应用程序application，也就是一个进程，并提交应用程序，则会执行这个进程的main方法。</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 通过反射调用<span class="token keyword">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>方法，在<span class="token keyword">start</span><span class="token punctuation">(</span><span class="token punctuation">)</span>方法中：</pre></td></tr><tr><td data-num="2"></td><td><pre>   <span class="token comment">-- 1）new Client(new ClientArguments(args), conf).run()</span></pre></td></tr><tr><td data-num="3"></td><td><pre>          ①new ClientArguments<span class="token punctuation">(</span>args<span class="token punctuation">)</span>，是配置参数的封装</pre></td></tr><tr><td data-num="4"></td><td><pre>          ②new Client，在client类中的属性有：</pre></td></tr><tr><td data-num="5"></td><td><pre>              <span class="token comment">--val yarnClient = YarnClient.createYarnClient，点击 createYarnClient 方法，在这个方法中：</span></pre></td></tr><tr><td data-num="6"></td><td><pre>                  <span class="token comment">-- YarnClient client = new YarnClientImpl ()，点击 YarnClientImpl 类，在类中有一个属性</span></pre></td></tr><tr><td data-num="7"></td><td><pre>                      rmclient：resourcemanagerClient</pre></td></tr><tr><td data-num="8"></td><td><pre>                      <span class="token comment">-- protected ApplicationClientProtocol rmClient</span></pre></td></tr><tr><td data-num="9"></td><td><pre>          <span class="token string">"如上就是创建RM客户端对象"</span>，接下来执行run方法</pre></td></tr><tr><td data-num="10"></td><td><pre>          ③run<span class="token punctuation">(</span><span class="token punctuation">)</span>，RM客户端对象执行run方法，点击run，在run方法的内部：</pre></td></tr><tr><td data-num="11"></td><td><pre>              <span class="token number">1.</span> 提交应用，返回应用的id。</pre></td></tr><tr><td data-num="12"></td><td><pre>              <span class="token comment">-- this.appId = submitApplication ()，点击 submitApplication (), 查看具体提交的过程</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                     <span class="token number">1.</span> 初始化hadoop的环境</pre></td></tr><tr><td data-num="14"></td><td><pre>                  	 <span class="token comment">--yarnClient.init(hadoopConf)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                  	 <span class="token number">2.</span> 启动yarn客户端<span class="token punctuation">,</span>与yarn之间进行连接</pre></td></tr><tr><td data-num="16"></td><td><pre>      				<span class="token comment">-- yarnClient.start()</span></pre></td></tr><tr><td data-num="17"></td><td><pre>      				<span class="token number">3.</span> yarn客户端创建一个应用application</pre></td></tr><tr><td data-num="18"></td><td><pre>      				<span class="token comment">--val newApp = yarnClient.createApplication()</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                     <span class="token number">4.</span> 获取应用的id，在yarn应用程序中，每一个应用都是有唯一的应用id</pre></td></tr><tr><td data-num="20"></td><td><pre>      				<span class="token comment">-- appId = newAppResponse.getApplicationId()</span></pre></td></tr><tr><td data-num="21"></td><td><pre>      				<span class="token number">5.</span> 提交yarn应用程序，提交的是什么呢？</pre></td></tr><tr><td data-num="22"></td><td><pre>      				<span class="token comment">--yarnClient.submitApplication (appContext)，点击 appContext</span></pre></td></tr><tr><td data-num="23"></td><td><pre>      				   <span class="token comment">--// Set up the appropriate contexts to launch our AM</span></pre></td></tr><tr><td data-num="24"></td><td><pre>      				         配置java虚拟机的启动参数，点击createContainerLaunchContext，</pre></td></tr><tr><td data-num="25"></td><td><pre>      				         在这个方法的内部进行了command的封装：</pre></td></tr><tr><td data-num="26"></td><td><pre>      				         【集群模式】command <span class="token operator">=</span> bin<span class="token operator">/</span>java org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>deploy<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>ApplicationMaster</pre></td></tr><tr><td data-num="27"></td><td><pre>                              【client模式】command <span class="token operator">=</span> bin<span class="token operator">/</span>java org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>deploy<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>ExecutorLauncher</pre></td></tr><tr><td data-num="28"></td><td><pre>                              <span class="token comment">--val containerContext = createContainerLaunchContext(newAppResponse)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>                              基本参数配置的封装</pre></td></tr><tr><td data-num="30"></td><td><pre>                              <span class="token comment">--val appContext = createApplicationSubmissionContext(newApp, containerContext)</span></pre></td></tr></table></figure><h4 id="223-yarnapplicationmaster"><a class="anchor" href="#223-yarnapplicationmaster">#</a> 2.2.3 yarn.ApplicationMaster</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 作用</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 封装ApplicationMaster的参数</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> 根据参数，创建ApplicationMaster对象</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3.</span> 执行ApplicationMaster的run方法，在run方法中，最后调用到runDriver方法，在这个方法中：</pre></td></tr><tr><td data-num="5"></td><td><pre>   a、启动用户的应用，并返回这个应用的<span class="token string">"线程"</span>，具体实现如下：</pre></td></tr><tr><td data-num="6"></td><td><pre>           a、启动用户提交的应用程序；</pre></td></tr><tr><td data-num="7"></td><td><pre>           b、在ApplicationMaster中创建一个线程，线程的名称就是<span class="token string">"Driver"</span></pre></td></tr><tr><td data-num="8"></td><td><pre>           c、启动这个线程，并执行run方法，在run方法中，就是执行我们提交的应用程序类的main方法</pre></td></tr><tr><td data-num="9"></td><td><pre>           d、返回这个<span class="token string">"Driver"</span>线程</pre></td></tr><tr><td data-num="10"></td><td><pre>    b、 执行一个方法，用于返回<span class="token string">"sparkContext"</span>的对象，如果没有返回，就不会执行下面的代码，当返回了这个上下文的对象以后：</pre></td></tr><tr><td data-num="11"></td><td><pre>    c、 ApplicationMaster通过ApplicationMaste的客户端，向ResourceManager注册自己，并申请资源</pre></td></tr><tr><td data-num="12"></td><td><pre>    d、 分配资源，具体实现如下： </pre></td></tr><tr><td data-num="13"></td><td><pre>            a、在ResourceManager端获取一个ApplicationMaster的客户端，返回一个分配器</pre></td></tr><tr><td data-num="14"></td><td><pre>            b、分配器进行资源的分配：</pre></td></tr><tr><td data-num="15"></td><td><pre>                 a、ApplicationMaster的客户端申请一个分配器响应</pre></td></tr><tr><td data-num="16"></td><td><pre>                 b、分配器响应返回所有被分配的容器container<span class="token punctuation">(</span>资源列表<span class="token punctuation">)</span>给到ApplicationMaster</pre></td></tr><tr><td data-num="17"></td><td><pre>                 c、如果分配的资源列表的数量大于<span class="token number">0</span>，则对容器进行处理，处理的方式为：</pre></td></tr><tr><td data-num="18"></td><td><pre>                        <span class="token number">1.</span>AM内部会创建一个线程，并调用线程的run方法，在run方法中循环遍历RM返回的可用容器，然后进行</pre></td></tr><tr><td data-num="19"></td><td><pre>                        对每个容器进行匹配，此时涉及到首选位置，根据请求匹配选择哪些容器<span class="token punctuation">.</span>首选位置的选择规则见首选位置说明。</pre></td></tr><tr><td data-num="20"></td><td><pre>                        <span class="token number">2.</span> 运行匹配后的资源，挨个遍历可用的容器，如果运行执行器的数量小于目标执行器的数量<span class="token string">"假如需要4个执行</span></pre></td></tr><tr><td data-num="21"></td><td><pre>                        器，即为目标执行器，此时已经运行了2个执行器，即为运行执行器的数量，此时会启动下面的逻辑"，</pre></td></tr><tr><td data-num="22"></td><td><pre>                        那么在这个容器中会创建一个线程池，一个线程池container对应一个ExecutorRunnable，并调用了这个对象的</pre></td></tr><tr><td data-num="23"></td><td><pre>                        run方法，在这个线程池中，有一个nmClient<span class="token punctuation">(</span>nameManagClient<span class="token punctuation">)</span><span class="token punctuation">,</span>说明AM能够找到NM，在这个run方法中，创建</pre></td></tr><tr><td data-num="24"></td><td><pre>                        NM的客户端，初始化NM，并启动容器container，在启动容器中，封装一个指令，   command：<span class="token operator">/</span>bin<span class="token operator">/</span>java</pre></td></tr><tr><td data-num="25"></td><td><pre>                        <span class="token operator">/</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>CoarseGrainedExecutorBackend，并且启动了这个指令，显然是一个进程</pre></td></tr><tr><td data-num="26"></td><td><pre>                        ，CoarseGrainedExecutorBackend，粗粒度的执行器后台。</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> main方法，在main方法中，分三步骤：</pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">1</span>） 封装参数</pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token comment">--val amArgs = new ApplicationMasterArguments(args)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token number">2</span>）创建ApplicationMaster的对象</pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token comment">--master = new ApplicationMaster(amArgs)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token number">3</span>）执行run方法<span class="token punctuation">,</span>点击run方法</pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token comment">--System.exit(master.run())</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    </pre></td></tr><tr><td data-num="9"></td><td><pre>       ①run方法的实现，点击runImpl</pre></td></tr><tr><td data-num="10"></td><td><pre>       	<span class="token comment">--runImpl()</span></pre></td></tr><tr><td data-num="11"></td><td><pre>            <span class="token comment">// 如果是 client 模式，执行：</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            <span class="token comment">-- runExecutorLauncher()</span></pre></td></tr><tr><td data-num="13"></td><td><pre>             <span class="token comment">// 如果是集群模式，执行，点击 runDriver</span></pre></td></tr><tr><td data-num="14"></td><td><pre>            <span class="token comment">-- runDriver</span></pre></td></tr><tr><td data-num="15"></td><td><pre>               <span class="token number">1.</span> 启动用户的程序<span class="token punctuation">,</span>返回一个线程，点击startUserApplication</pre></td></tr><tr><td data-num="16"></td><td><pre>               <span class="token comment">--userClassThread = startUserApplication()</span></pre></td></tr><tr><td data-num="17"></td><td><pre>                    <span class="token number">1.</span> 通过类加载器加载一个类，并获取这个类的main方法</pre></td></tr><tr><td data-num="18"></td><td><pre>                    <span class="token comment">-- val mainMethod = userClassLoader.loadClass(args.userClass).getMethod("main", classOf[Array[String]])</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                    <span class="token number">2.</span> 创建一个线程</pre></td></tr><tr><td data-num="20"></td><td><pre>                    <span class="token comment">-- val userThread = new Thread</span></pre></td></tr><tr><td data-num="21"></td><td><pre>                    <span class="token number">3.</span> </pre></td></tr><tr><td data-num="22"></td><td><pre>                    <span class="token comment">-- userThread.setContextClassLoader(userClassLoader)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>                    <span class="token number">4.</span> 设定线程的名字为driver，说明driver就是一个applicationMaster的一个线程</pre></td></tr><tr><td data-num="24"></td><td><pre>                    <span class="token comment">-- userThread.setName("Driver")</span></pre></td></tr><tr><td data-num="25"></td><td><pre>                    <span class="token number">5.</span> 启动线程，执行线程的run方法，其实就是执行类userClass的main方法，userClass是哪个类呢？</pre></td></tr><tr><td data-num="26"></td><td><pre>                       通过查到，就是我们提交应用的<span class="token comment">--class，sparkpi，或者是我们自定的类</span></pre></td></tr><tr><td data-num="27"></td><td><pre>                    <span class="token comment">-- userThread.start()</span></pre></td></tr><tr><td data-num="28"></td><td><pre>                        <span class="token comment">-- mainMethod.invoke      </span></pre></td></tr><tr><td data-num="29"></td><td><pre>                    <span class="token number">6.</span> 返回用户线程</pre></td></tr><tr><td data-num="30"></td><td><pre>                    <span class="token comment">-- userThread</span></pre></td></tr><tr><td data-num="31"></td><td><pre>               <span class="token number">2.</span> awaitResult等待结果，线程阻塞，等待对象<span class="token punctuation">(</span>SparkContext<span class="token punctuation">)</span>的返回</pre></td></tr><tr><td data-num="32"></td><td><pre>               <span class="token comment">--val sc = ThreadUtils.awaitResult(sparkContextPromise.future,Duration(totalWaitTime, TimeUnit.MILLISECONDS))</span></pre></td></tr><tr><td data-num="33"></td><td><pre>                 </pre></td></tr><tr><td data-num="34"></td><td><pre>               <span class="token number">3.</span> 返回sparkContext以后，向rm进行注册AM：ApplicationMaster，点击registerAM<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre>                <span class="token comment">--registerAM(host, port, userConf, sc.ui.map(_.webUrl))</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                    ApplicationMaster的客户端向RM注册自己，并申请资源</pre></td></tr><tr><td data-num="37"></td><td><pre>                    <span class="token comment">--client.register(host, port, yarnConf, _sparkConf, uiAddress, historyAddress)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>               <span class="token number">4.</span> 返回RM分配的容器</pre></td></tr><tr><td data-num="39"></td><td><pre>               <span class="token comment">--createAllocator(driverRef, userConf)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>                   <span class="token comment">// 1.AM 的客户端，' 在 RM 端 '，创建分配器，返回一个分配器</span></pre></td></tr><tr><td data-num="41"></td><td><pre>                   <span class="token comment">-- allocator = client.createAllocator</span></pre></td></tr><tr><td data-num="42"></td><td><pre>                   <span class="token comment">// 2. 分配器分配资源，点击 allocateResources</span></pre></td></tr><tr><td data-num="43"></td><td><pre>                   <span class="token comment">-- allocator.allocateResources()</span></pre></td></tr><tr><td data-num="44"></td><td><pre>                          <span class="token comment">// 1.AM 的客户端，申请一个分配响应</span></pre></td></tr><tr><td data-num="45"></td><td><pre>                          <span class="token comment">--val allocateResponse = amClient.allocate(progressIndicator)</span></pre></td></tr><tr><td data-num="46"></td><td><pre>                          <span class="token comment">// 2. 分配器响应获取所有被分配的容器 container (资源列表)</span></pre></td></tr><tr><td data-num="47"></td><td><pre>                         <span class="token comment">--val allocatedContainers = allocateResponse.getAllocatedContainers()</span></pre></td></tr><tr><td data-num="48"></td><td><pre>                         <span class="token comment">// 3. 如果可分配的容器数量大于 0，则调用处理可用容器的方法，点击 handle 方法</span></pre></td></tr><tr><td data-num="49"></td><td><pre>                          <span class="token comment">--if (allocatedContainers.size > 0) =></span></pre></td></tr><tr><td data-num="50"></td><td><pre>                            handleAllocatedContainers<span class="token punctuation">(</span>allocatedContainers<span class="token punctuation">.</span>asScala<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre>                               <span class="token comment">// 1. 内部会创建一个线程，并调用线程的 run 方法，在 run 方法中循环遍历 RM 返回的可用容器，然后进行</span></pre></td></tr><tr><td data-num="52"></td><td><pre>                                  对每个容器进行匹配，此时涉及到首选位置，根据请求匹配选择哪些容器<span class="token punctuation">.</span>首选位置的选择规则见</pre></td></tr><tr><td data-num="53"></td><td><pre>                                  首选位置说明。</pre></td></tr><tr><td data-num="54"></td><td><pre>                               <span class="token comment">// 2. 运行匹配后的资源，点击 runAllocatedContainers</span></pre></td></tr><tr><td data-num="55"></td><td><pre>                               <span class="token comment">--runAllocatedContainers(containersToUse)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>                                      <span class="token comment">// 1. 挨个遍历可用的容器资源</span></pre></td></tr><tr><td data-num="57"></td><td><pre>                                       <span class="token comment">--for (container &lt;- containersToUse)</span></pre></td></tr><tr><td data-num="58"></td><td><pre>                                       <span class="token comment">// 2. 每个容器中，如果运行执行器的数量小于目标执行器的数量，执行如下代码</span></pre></td></tr><tr><td data-num="59"></td><td><pre>                                       <span class="token comment">--runningExecutors.size() &lt; targetNumExecutors</span></pre></td></tr><tr><td data-num="60"></td><td><pre>                                       <span class="token comment">// 3. 线程池，在线程池的内部有：</span></pre></td></tr><tr><td data-num="61"></td><td><pre>                                       <span class="token comment">--launcherPool.execute(new Runnable </span></pre></td></tr><tr><td data-num="62"></td><td><pre>                                            <span class="token comment">// 1. 执行的池子是一个线程池</span></pre></td></tr><tr><td data-num="63"></td><td><pre>                                            <span class="token comment">--launcherPool = ThreadUtils.newDaemonCachedThreadPool</span></pre></td></tr><tr><td data-num="64"></td><td><pre>                                       		<span class="token comment">// 2. 一个线程 container 对应一个 ExecutorRunnable，并调用了这个对象的 run 方法</span></pre></td></tr><tr><td data-num="65"></td><td><pre>                                       		<span class="token comment">--new ExecutorRunnable...run()</span></pre></td></tr><tr><td data-num="66"></td><td><pre>                                       		     <span class="token comment">//a、在 ExecutorRunnable 中：说明 AM 能够找到 NM</span></pre></td></tr><tr><td data-num="67"></td><td><pre>                                       		     <span class="token comment">--nmClient，nodeManager</span></pre></td></tr><tr><td data-num="68"></td><td><pre>                                       		     <span class="token comment">//b、run () 中：其实就是 AM 与 NM 建立连接</span></pre></td></tr><tr><td data-num="69"></td><td><pre>                                                     <span class="token comment">// 创建 NM 的客户端</span></pre></td></tr><tr><td data-num="70"></td><td><pre>                                                     <span class="token comment">--nmClient = NMClient.createNMClient()</span></pre></td></tr><tr><td data-num="71"></td><td><pre>                                                     <span class="token comment">// 初始化 NM</span></pre></td></tr><tr><td data-num="72"></td><td><pre>                                                     <span class="token comment">--nmClient.init(conf)</span></pre></td></tr><tr><td data-num="73"></td><td><pre>                                                      <span class="token comment">// 启动 NM</span></pre></td></tr><tr><td data-num="74"></td><td><pre>                                                     <span class="token comment">-- nmClient.start()</span></pre></td></tr><tr><td data-num="75"></td><td><pre>                                                      <span class="token comment">// 启动容器，点击</span></pre></td></tr><tr><td data-num="76"></td><td><pre>                                                      <span class="token comment">--startContainer()</span></pre></td></tr><tr><td data-num="77"></td><td><pre>                                                           <span class="token comment">// NM 启动容器，启动 executor</span></pre></td></tr><tr><td data-num="78"></td><td><pre>                                                           <span class="token comment">--nmClient.startContainer(container.get, ctx)</span></pre></td></tr><tr><td data-num="79"></td><td><pre>                                                           <span class="token comment">// 封装指令，点击 prepareCommand</span></pre></td></tr><tr><td data-num="80"></td><td><pre>                                                           <span class="token comment">--val commands = prepareCommand()</span></pre></td></tr><tr><td data-num="81"></td><td><pre>                                                                 	commands<span class="token operator">=</span><span class="token operator">/</span>bin<span class="token operator">/</span>java<span class="token operator">/</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>CoarseGrainedExecutorBackend<span class="token comment">--> 粗粒度的执行器后台，是一个进程</span></pre></td></tr><tr><td data-num="82"></td><td><pre>                                                           <span class="token comment">// 将封装好的指令传递到参数中</span></pre></td></tr><tr><td data-num="83"></td><td><pre>                                                           <span class="token comment">--ctx.setCommands(commands.asJava)</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 首选位置说明</span></pre></td></tr><tr><td data-num="2"></td><td><pre>        <span class="token comment">--1. 移动数据不如移动计算。 </span></pre></td></tr><tr><td data-num="3"></td><td><pre>        <span class="token comment">--2. 首选位置：有多个，和本地化级别有关。</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token comment">--3. 本地化级别：将数据和计算所在的位置称之为本地化</span></pre></td></tr><tr><td data-num="5"></td><td><pre>               <span class="token number">1.</span> 计算和数据在同一个Executor中，称之进程本地化</pre></td></tr><tr><td data-num="6"></td><td><pre>               <span class="token number">2.</span> 计算和数据在同一个节点中，称之节点本地化</pre></td></tr><tr><td data-num="7"></td><td><pre>               <span class="token number">3.</span> 计算和数据在同一个机架中，称之机架本地化</pre></td></tr><tr><td data-num="8"></td><td><pre>               <span class="token number">4.</span> 任意</pre></td></tr></table></figure><p>&lt;img src=&quot;<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618002757.png&quot; alt=&quot;image-20200618002757465&quot; style=&quot;zoom:50%;&quot; /&gt;</p><p>&lt;img src=&quot;<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618002929.png&quot; alt=&quot;image-20200618002929263&quot; style=&quot;zoom:50%;&quot; /&gt;</p><p>![image-20200619202433592](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200619202433.png)</p><h4 id="224-coarsegrainedexecutorbackend"><a class="anchor" href="#224-coarsegrainedexecutorbackend">#</a> 2.2.4 CoarseGrainedExecutorBackend</h4><blockquote><p>执行一次 bin/java 就会执行一个新的进程，则是属于并行执行的感觉，和之前执行的内容是分开的。类似我们在 Windows 中开了一个微信和 qq 程序一样，各自执行，互不影响。</p></blockquote><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 作用：</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   执行CoarseGrainedExecutorBackend<span class="token string">"执行器后台"</span>的main方法，在main方法中：</pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token number">1.</span> 首先封装一些参数</pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token number">2.</span> 执行run方法，在run方法中：</pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token number">1.</span> 通过driver的URI，使得CoarseGrainedExecutorBackend与Driver进行关联</pre></td></tr><tr><td data-num="6"></td><td><pre>        <span class="token number">2.</span> 通过通信环境创建了一个终端，名字为executor，创建一个CoarseGrainedExecutorBackend对象并调用onstart方法：</pre></td></tr><tr><td data-num="7"></td><td><pre>             <span class="token number">1.</span> 获取driver的引用</pre></td></tr><tr><td data-num="8"></td><td><pre>             <span class="token number">2.</span> ExecutorBackend向driver发送消息，注册executor的消息，也称之为反向注册</pre></td></tr><tr><td data-num="9"></td><td><pre>             <span class="token number">3.</span> 在driver端会接收到这个消息，通过executor的引用，发送消息给到ExecutorBackend，注册executor成功 </pre></td></tr><tr><td data-num="10"></td><td><pre>             <span class="token number">4.</span> ExecutorBackend接收driver返回的executor注册成功的消息，</pre></td></tr><tr><td data-num="11"></td><td><pre>            </pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment">-- 说明：</span></pre></td></tr><tr><td data-num="13"></td><td><pre>   executor是一个计算对象，在这个对象里面有一个线程池，每一个线程来处理一个从driver端发送过来的任务</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> commands<span class="token operator">=</span><span class="token operator">/</span>bin<span class="token operator">/</span>java<span class="token operator">/</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>CoarseGrainedExecutorBackend<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="2"></td><td><pre>	执行这个指令，那么是调用这个类的main方法。</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> main方法中：</pre></td></tr><tr><td data-num="4"></td><td><pre>       <span class="token comment">// 1. 首先是对一些参数进行封装</span></pre></td></tr><tr><td data-num="5"></td><td><pre>       <span class="token comment">// 2. 执行 run 方法 </span></pre></td></tr><tr><td data-num="6"></td><td><pre>       <span class="token comment">-- run(driverUrl, executorId, hostname, cores, appId, workerUrl, userClassPath)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>           <span class="token comment">// 1. 通过 driver 的 uri 和 Driver 进行关联</span></pre></td></tr><tr><td data-num="8"></td><td><pre>            <span class="token comment">--driver = fetcher.setupEndpointRefByURI(driverUrl)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>            <span class="token comment">// 2. 通过通信环境创建了一个终端，名字为 executor，</span></pre></td></tr><tr><td data-num="10"></td><td><pre>            在底层：Executor启动后会注册通信，并收到信息onStart，收到消息后，会执行通信对象CoarseGrainedExecutorBackend</pre></td></tr><tr><td data-num="11"></td><td><pre>            的onStart方法，点击CoarseGrainedExecutorBackend</pre></td></tr><tr><td data-num="12"></td><td><pre>            <span class="token comment">--env.rpcEnv.setupEndpoint("Executor", new CoarseGrainedExecutorBackend(</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        env<span class="token punctuation">.</span>rpcEnv<span class="token punctuation">,</span> driverUrl<span class="token punctuation">,</span> executorId<span class="token punctuation">,</span> hostname<span class="token punctuation">,</span> cores<span class="token punctuation">,</span> userClassPath<span class="token punctuation">,</span> env<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>                <span class="token comment">// 1. 获取 driver 的引用</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                <span class="token comment">-- driver = Some(ref)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>                <span class="token comment">// 2.ExecutorBackend 向 driver 发送消息，注册 executor 的消息，也称之为反向注册</span></pre></td></tr><tr><td data-num="17"></td><td><pre>                <span class="token comment">--ref.ask[Boolean](RegisterExecutor(executorId, self, hostname, cores, extractLogUrls))</span></pre></td></tr><tr><td data-num="18"></td><td><pre>                <span class="token comment">// 3. 在 driver 端会接收到这个消息，因为在 driver 端，有一个上下文的对象，sparkcontext，在这个类有一个属性：</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                   private var _schedulerBackend: SchedulerBackend <span class="token operator">=</span> _，点击SchedulerBackend，是一个trait，找到</pre></td></tr><tr><td data-num="20"></td><td><pre>                   实现类：CoarseGrainedSchedulerBackend，在这个类中，有一个方法：receiveAndReply<span class="token punctuation">(</span><span class="token punctuation">)</span>：</pre></td></tr><tr><td data-num="21"></td><td><pre>                      <span class="token comment">//executor 的引用，在 driver 端，发送消息给到 ExecutorBackend，注册 executor 成功</span></pre></td></tr><tr><td data-num="22"></td><td><pre>                      <span class="token comment">--executorRef.send(RegisteredExecutor)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>                      </pre></td></tr><tr><td data-num="24"></td><td><pre>                      <span class="token comment">// ExecutorBackend 类中有一个 recive 方法，用来接收 driver 返回的 executor 注册成功的消息，executor 是一</span></pre></td></tr><tr><td data-num="25"></td><td><pre>                         个计算对象，在这个对象里面有一个线程池，每一个线程来处理一个从driver端发送过来的任务</pre></td></tr><tr><td data-num="26"></td><td><pre>                     <span class="token comment">--executor = new Executor(executorId, hostname, env, userClassPath, isLocal = false)</span></pre></td></tr></table></figure><p>![image-20200618150421861](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618150421.png)</p><p>![image-20200618150442390](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618150442.png)</p><h4 id="225-总结"><a class="anchor" href="#225-总结">#</a> 2.2.5 总结</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. application 是在一个 nodemanager 中 container 中，并且在这个 container 中创建了一个 driver 线程</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">-- 2. 在一个 nodemanager 中，可以创建多个 container，在每个 container 中，会创建 ExecutorBackend 对象，在这个对象中，会创建一个 executor 对象，在这个对象中一个线程池，一个线程用来处理 driver 发来的一个 task，至于能同时执行多少个 task，和 executor 中的 core 数量有关。</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">-- 3. ApplicationMaster 周旋于 Driver 和 ResourceManager 之间</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 4. spark 有两个进程，也就是两个分支</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    创建RM的客户端，创建AM，在AM中，创建Driver的线程</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token string">"分支1"</span>：此时会执行Driver线程的run方法，在run方法中就是执行了应用程序的main方法</pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token string">"分支2"</span>：构建SparkContext上下文的对象，再向RM注册AM，然后申请资源和返回可用的资源，最后Driver进行资源的选择，按照首选位置的原则。</pre></td></tr><tr><td data-num="8"></td><td><pre>    所以如下图片有一个错误：资源满足以后才执行main方法，实际上是创建了driver线程，还没有申请资源就已经开始执行main方法了。</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment">-- 5. 进程、线程、对象</span></pre></td></tr><tr><td data-num="10"></td><td><pre>   <span class="token string">"进程"</span>：SparkSubmit、ApplicationMaster和CoarseGrainedExecutorBackend</pre></td></tr><tr><td data-num="11"></td><td><pre>   <span class="token string">"线程"</span>：Driver，但是我们一般称SparkContext称之为Driver</pre></td></tr><tr><td data-num="12"></td><td><pre>   <span class="token string">"对象"</span>：Executor和YarnClusterApplication</pre></td></tr><tr><td data-num="13"></td><td><pre>   </pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment">-- 6. client 和 cluster 模式的区别：</span></pre></td></tr><tr><td data-num="15"></td><td><pre>      Driver的位置不同，其余的逻辑是一样的。</pre></td></tr><tr><td data-num="16"></td><td><pre>      Cluster：在集群中，在nodemanager中的AM对象中，是一个线程</pre></td></tr><tr><td data-num="17"></td><td><pre>      client：在集群之外</pre></td></tr></table></figure><p>&lt;img src=&quot;<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618155642.png&quot; alt=&quot;image-20200618155642818&quot; style=&quot;zoom:150%;&quot; /&gt;</p><h2 id="三-spark内部组件及通信"><a class="anchor" href="#三-spark内部组件及通信">#</a> 三、Spark 内部组件及通信</h2><h3 id="31-通信原理"><a class="anchor" href="#31-通信原理">#</a> 3.1 通信原理</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 通信原理 - IO - RPC</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">1.</span> 基本的网络通信：Socket<span class="token punctuation">,</span> ServerSocket</pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token number">2.</span> 通信框架：AKKA<span class="token punctuation">(</span>旧<span class="token punctuation">)</span><span class="token punctuation">,</span>  Netty<span class="token punctuation">(</span>新<span class="token punctuation">)</span><span class="token punctuation">(</span>AIO<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token number">3.</span> 三种IO方式：BIO（阻塞式）<span class="token punctuation">,</span> NIO（非阻塞式）<span class="token punctuation">,</span> AIO（异步）</pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token number">4.</span> Linux<span class="token punctuation">,</span> windows</pre></td></tr><tr><td data-num="6"></td><td><pre>	在Linux系统上，AIO的底层实现仍使用EPOLL，与NIO相同，因此在性能上没有明显的优势；Windows的AIO底层实现良好，但是Netty开发人员并没有把Windows作为主要使用平台考虑。微软的windows系统提供了一种异步IO技术：IOCP（I<span class="token operator">/</span>O CompletionPort，I<span class="token operator">/</span>O完成端口）；Linux下由于没有这种异步IO技术，所以使用的是epoll（一种多路复用IO技术的实现）对异步IO进行模拟。所以在Linux上不建议使用AIO</pre></td></tr></table></figure><h3 id="32-组件之间通信"><a class="anchor" href="#32-组件之间通信">#</a> 3.2 组件之间通信</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 组件：Driver、executor</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> 通信环境：NettyRpcEnvFactory<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>   通过env<span class="token punctuation">.</span>rpcEnv<span class="token punctuation">.</span>setupEndpoint，将driver和executor终端放进rpcenv中，那么这个driver和executor就可以通信</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3.</span> 组件之间的通信：</pre></td></tr><tr><td data-num="5"></td><td><pre>    a、通信终端共通类：Endpoint  </pre></td></tr><tr><td data-num="6"></td><td><pre>    b、通信终端：RpcEndpoint<span class="token punctuation">(</span>receive<span class="token punctuation">)</span> <span class="token comment">--> 通信的终端，drive 和 executor, 负责接收数据</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    c、通信终端引用：RpcEndpointRef<span class="token punctuation">(</span>send<span class="token punctuation">,</span>ask<span class="token punctuation">)</span> <span class="token comment">--> 通信终端的指代，负责发送和请求</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">4.</span> 一个终端的生命周期：</pre></td></tr><tr><td data-num="9"></td><td><pre>The life<span class="token operator">-</span><span class="token keyword">cycle</span> <span class="token keyword">of</span> an endpoint <span class="token operator">is</span>:</pre></td></tr><tr><td data-num="10"></td><td><pre>创建终端<span class="token operator">-</span><span class="token operator">></span> 启动终端 <span class="token operator">-</span><span class="token operator">></span> 接收消息 <span class="token operator">-</span><span class="token operator">></span> 停止终端</pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token operator">*</span> &#123;<span class="token variable">@code</span> constructor <span class="token operator">-</span><span class="token operator">></span> onStart <span class="token operator">-</span><span class="token operator">></span> receive<span class="token operator">*</span> <span class="token operator">-</span><span class="token operator">></span> onStop&#125;</pre></td></tr><tr><td data-num="12"></td><td><pre>    </pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token number">5.</span> <span class="token string">"终端和终端的引用是如何关联的呢？"</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token number">1.</span> driver和executor都是通信终端</pre></td></tr><tr><td data-num="15"></td><td><pre>        <span class="token number">2.</span> 现假如是executor向drive发送数据，那么在executor端，通过driver的引用ref给到driver发消息</pre></td></tr><tr><td data-num="16"></td><td><pre>        <span class="token number">3.</span> 在driver中有一个接收器，receive。</pre></td></tr><tr><td data-num="17"></td><td><pre>        <span class="token number">4.</span> 同时driver给Executor发送消息时，在driver端有一个executor的引用，通过executor的引用给到executor发送消息。</pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token number">5.</span> 这样在发送消息的时候，就不用等待返回的结果。</pre></td></tr></table></figure><p>![image-20200618201029135](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618201029.png)</p><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 接收消息就是通过收件箱：Inbox</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> 发送消息就是通过发件箱：outbox</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">3.</span> 一个终端：RpcEndpoint，只有一个收件箱，但是有N个发件箱。</pre></td></tr></table></figure><p>![image-20200618202126937](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618202126.png)</p><h2 id="四-作业的调度"><a class="anchor" href="#四-作业的调度">#</a> 四、作业的调度</h2><h3 id="41-application"><a class="anchor" href="#41-application">#</a> 4.1 Application</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> Yarn中会有application，提交任务以后，就会产生一个应用，并有一个唯一的应用id</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> 在SparkConf中配置了setAppName<span class="token punctuation">(</span>xxxx<span class="token punctuation">)</span><span class="token punctuation">,</span>设置应用的名字</pre></td></tr></table></figure><p>![image-20200618203801740](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618203801.png)</p><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">3.</span> SparkContext，是spark核心的对象，核心类，在这个核心类中的一些重要的参数有：</pre></td></tr><tr><td data-num="2"></td><td><pre>  private var _conf: SparkConf <span class="token operator">=</span> _  <span class="token comment">-- spark 的关键参数</span></pre></td></tr><tr><td data-num="3"></td><td><pre>  private var _env: SparkEnv <span class="token operator">=</span> _    <span class="token comment">-- spark 的环境，内部有 NettyRpcEnv</span></pre></td></tr><tr><td data-num="4"></td><td><pre>  private var _schedulerBackend: SchedulerBackend <span class="token operator">=</span> _   <span class="token comment">-- spark 的调度后台，Rpc 后台信息交互对象</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  private var _taskScheduler: TaskScheduler <span class="token operator">=</span> _         <span class="token comment">-- 任务调度器</span></pre></td></tr><tr><td data-num="6"></td><td><pre>  private var _heartbeatReceiver: RpcEndpointRef <span class="token operator">=</span> _    <span class="token comment">-- 指心跳接收器，通信终端的引用 </span></pre></td></tr><tr><td data-num="7"></td><td><pre>  <span class="token variable">@volatile</span> private var _dagScheduler: DAGScheduler <span class="token operator">=</span> _ <span class="token comment">-- 有向无环图调度器，负责 job 内部调度，负责阶段划分和任务的切分。</span></pre></td></tr><tr><td data-num="8"></td><td><pre> </pre></td></tr><tr><td data-num="9"></td><td><pre> <span class="token comment">-- _conf：下滑线开头，表示内部的变量，不是规范，是早期程序员默认遵守的规范。</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">4.</span> DAGScheduler ，spark非常核心的调度器。</pre></td></tr><tr><td data-num="2"></td><td><pre>      <span class="token number">1.</span>内部有一个对象<span class="token punctuation">,</span>DAGSchedulerEventProcessLoop<span class="token punctuation">,</span><span class="token string">"指事件调度的规则"</span>，点击这个类：</pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token comment">--private[spark] val eventProcessLoop = new DAGSchedulerEventProcessLoop(this)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token number">1.</span>上面类继承于EventLoop<span class="token punctuation">,</span>这个类中有一个属性：事件队列，用来存放事件</pre></td></tr><tr><td data-num="5"></td><td><pre>           BlockingQueue<span class="token punctuation">[</span>E<span class="token punctuation">]</span>：阻塞式队列</pre></td></tr><tr><td data-num="6"></td><td><pre>           LinkedBlockingDeque：双端队列</pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token comment">-- private val eventQueue: BlockingQueue[E] = new LinkedBlockingDeque[E]()</span></pre></td></tr></table></figure><p>![image-20200618211748700](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200618211748.png)</p><h3 id="42-逻辑代码"><a class="anchor" href="#42-逻辑代码">#</a> 4.2 逻辑代码</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> RDD的创建： 从内存中<span class="token operator">/</span>从文件中</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> RDD的转换： 转换算子<span class="token punctuation">(</span>单<span class="token keyword">value</span>类型、双<span class="token keyword">value</span>类型、kv类型<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">3.</span> RDD的行动： 行动算子</pre></td></tr></table></figure><h3 id="43-job"><a class="anchor" href="#43-job">#</a> 4.3 job</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 触发作业的执行，在行动算子的内部会执行过程：</pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">1.</span>sparkContext提交作业</pre></td></tr><tr><td data-num="3"></td><td><pre>	<span class="token comment">--> sc.runjob </span></pre></td></tr><tr><td data-num="4"></td><td><pre>	<span class="token number">2.</span> 有向无环图的调度器执行runjob</pre></td></tr><tr><td data-num="5"></td><td><pre>	<span class="token comment">--> dagScheduler.runJob </span></pre></td></tr><tr><td data-num="6"></td><td><pre>	<span class="token number">3.</span> 提交job</pre></td></tr><tr><td data-num="7"></td><td><pre>	<span class="token comment">--> submitjob</span></pre></td></tr><tr><td data-num="8"></td><td><pre>	<span class="token number">4.</span> 消息队列进行存放消息</pre></td></tr><tr><td data-num="9"></td><td><pre>	<span class="token comment">--> eventProcessLoop.post</span></pre></td></tr><tr><td data-num="10"></td><td><pre>	<span class="token number">5.</span> 消息队列将消息放进队列中，这个消息是：JobSubmitted</pre></td></tr><tr><td data-num="11"></td><td><pre>	<span class="token comment">--> eventQueue.put(event) </span></pre></td></tr><tr><td data-num="12"></td><td><pre>	<span class="token number">6.</span> 在eventQueue有一个线程，线程中有一个run方法</pre></td></tr><tr><td data-num="13"></td><td><pre>	<span class="token comment">--> eventThread </span></pre></td></tr><tr><td data-num="14"></td><td><pre>	<span class="token number">7.</span>  负责取出消息，因为这个队列是一个阻塞式队列，队列中没有消息，那么就处于阻塞式状态</pre></td></tr><tr><td data-num="15"></td><td><pre>	<span class="token comment">--> val event = eventQueue.take() </span></pre></td></tr><tr><td data-num="16"></td><td><pre>	<span class="token number">8.</span> 取到消息</pre></td></tr><tr><td data-num="17"></td><td><pre>	<span class="token comment">--> onReceive(event)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>	<span class="token number">9.</span> 执行处理消息</pre></td></tr><tr><td data-num="19"></td><td><pre>	<span class="token comment">--> doOnReceive(event)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>	<span class="token number">10.</span> 使用模式匹配的的方式处理消息</pre></td></tr><tr><td data-num="21"></td><td><pre>	<span class="token comment">-->  def doOnReceive(event: DAGSchedulerEvent): Unit = event match &#123;</span></pre></td></tr><tr><td data-num="22"></td><td><pre>      <span class="token keyword">case</span> JobSubmitted<span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> rdd<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitions<span class="token punctuation">,</span> callSite<span class="token punctuation">,</span> listener<span class="token punctuation">,</span> properties<span class="token punctuation">)</span> <span class="token operator">=</span><span class="token operator">></span></pre></td></tr><tr><td data-num="23"></td><td><pre>      dagScheduler<span class="token punctuation">.</span>handleJobSubmitted<span class="token punctuation">(</span>jobId<span class="token punctuation">,</span> rdd<span class="token punctuation">,</span> func<span class="token punctuation">,</span> partitions<span class="token punctuation">,</span> callSite<span class="token punctuation">,</span> listener<span class="token punctuation">,</span> properties<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token number">11.</span> 有向无环图调度器处理任务的提交 </pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token comment">--> dagScheduler.handleJobSubmitted(jobId, rdd, func, partitions, callSite, listener, properties)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token number">12.</span> 创建一个活动的job</pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment">--> val job = new ActiveJob</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 总结：</span></pre></td></tr><tr><td data-num="2"></td><td><pre>启动一个行动算子 <span class="token comment">--> runjob  -> 将执行事件放进阻塞式队列中 -> 创建一个线程取出队列中的消息 -> 进行模式匹配，处理任务的提交</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">--> 创建一个运行 job</span></pre></td></tr></table></figure><h3 id="44-stage"><a class="anchor" href="#44-stage">#</a> 4.4 stage</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 阶段的划分，取决于转换算子的依赖类型。</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">-- 2. 宽依赖：ShuffleDependency</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">-- 3. 窄依赖：OneToOneDependency extends NarrowDependency</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 4. 分区的数量</span></pre></td></tr><tr><td data-num="5"></td><td><pre>     a、窄依赖：分区数量保持不变</pre></td></tr><tr><td data-num="6"></td><td><pre>          <span class="token number">1.</span> 获取窄依赖的分区数量，点击 firstParent</pre></td></tr><tr><td data-num="7"></td><td><pre>          <span class="token comment">-- override def getPartitions: Array[Partition] = firstParent[T].partitions</span></pre></td></tr><tr><td data-num="8"></td><td><pre>               <span class="token number">1.</span> 获取依赖关系的第一个rdd分区数量</pre></td></tr><tr><td data-num="9"></td><td><pre>               <span class="token comment">-- dependencies.head.rdd.asInstanceOf[RDD[U]]</span></pre></td></tr><tr><td data-num="10"></td><td><pre>     b、宽依赖：</pre></td></tr><tr><td data-num="11"></td><td><pre>            <span class="token number">1.</span> 获取宽依赖的分区数量</pre></td></tr><tr><td data-num="12"></td><td><pre>            partitioner：是一个分区器，partitioner，由上一个RDD传递过来的，在传递的时候，会进行判断，如果当前的RDD的分区器</pre></td></tr><tr><td data-num="13"></td><td><pre>            和上一级的分区器一样，那么是不会创建shuffleRDD，只有当前RDD的分区器和上一级的分区器不一样时，才会创建</pre></td></tr><tr><td data-num="14"></td><td><pre>            ShuffledRDD</pre></td></tr><tr><td data-num="15"></td><td><pre>            <span class="token comment">--Array.tabulate[Partition](part.numPartitions)(i => new ShuffledRDDPartition(i))</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            </pre></td></tr><tr><td data-num="17"></td><td><pre>            <span class="token number">2.</span> 默认情况下，默认的分区器将上一级的RDD传入</pre></td></tr><tr><td data-num="18"></td><td><pre>            <span class="token comment">--  reduceByKey(defaultPartitioner(self), func)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                <span class="token number">1.</span> 默认的分区数量等于上级RDD的最大值，因为上一级RDD可能有多个</pre></td></tr><tr><td data-num="20"></td><td><pre>                <span class="token comment">-- val defaultNumPartitions = rdds.map(_.partitions.length).max</span></pre></td></tr><tr><td data-num="21"></td><td><pre>                <span class="token number">2.</span> 构造分区器的时候，将默认的分区数量传入，分区器的作用是指定数据去到哪个分区，分区的数量默认和上一级RDD</pre></td></tr><tr><td data-num="22"></td><td><pre>                   保持一致</pre></td></tr><tr><td data-num="23"></td><td><pre>                <span class="token comment">-- new HashPartitioner(defaultNumPartitions)</span></pre></td></tr><tr><td data-num="24"></td><td><pre> <span class="token comment">-- 5. 总结： </span></pre></td></tr><tr><td data-num="25"></td><td><pre>       a、窄依赖默认分区数量保持不变</pre></td></tr><tr><td data-num="26"></td><td><pre>       b、宽依赖，默认和上一级	RDD最大的分区数量保持一致，如果上一级RDD只有一个，那就和上一级RDD保持一致</pre></td></tr><tr><td data-num="27"></td><td><pre>                 但是Shuffle的算子一般都会有改变分区数量的参数</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 6. 从文件中创建 RDD 时默认的分区数量</span></pre></td></tr><tr><td data-num="2"></td><td><pre>      <span class="token number">1.</span> 取<span class="token punctuation">(</span>defaultParallelism<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>的最小值，点击defaultParallelism</pre></td></tr><tr><td data-num="3"></td><td><pre>      <span class="token comment">--math.min(defaultParallelism, 2)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>      <span class="token number">2.</span> 选择yarn模式中的默认平行度。</pre></td></tr><tr><td data-num="5"></td><td><pre>      <span class="token comment">--defaultParallelism = conf.getInt("spark.default.parallelism", math.max(totalCoreCount.get(), 2))</span></pre></td></tr></table></figure><p>![image-20200620130734058](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620130734.png)</p><h3 id="45-task的切分"><a class="anchor" href="#45-task的切分">#</a> 4.5 task 的切分</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. 任务和阶段 stage 的关系</span></pre></td></tr><tr><td data-num="2"></td><td><pre>     定位：DAGScheduler类</pre></td></tr><tr><td data-num="3"></td><td><pre>     <span class="token number">1.</span> 处理任务的提交handleJobSubmitted，在这个方法的内部：</pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token number">1.</span> 将整个job作为一个finalStage</pre></td></tr><tr><td data-num="5"></td><td><pre>    	<span class="token comment">-- var finalStage: ResultStage = null</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    	<span class="token number">2.</span> 创建一个结果阶段，并赋值给finalStage</pre></td></tr><tr><td data-num="7"></td><td><pre>    	    finalRDD：最后提交job时的RDD，点击createResultStage</pre></td></tr><tr><td data-num="8"></td><td><pre>    	<span class="token comment">-- finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    	    <span class="token number">1.</span> 通过当前的RDD获取其上一级的阶段，点击getOrCreateParentStages</pre></td></tr><tr><td data-num="10"></td><td><pre>    	    <span class="token comment">-- val parents = getOrCreateParentStages(rdd, jobId)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    	         <span class="token number">1.</span>获取最后一个RDD的shuffle依赖，每一个shuffle依赖创建一个shufflemapStage</pre></td></tr><tr><td data-num="12"></td><td><pre>    	         <span class="token comment">--getShuffleDependencies(rdd).map &#123; shuffleDep =>getOrCreateShuffleMapStage(shuffleDep, firstJobId)&#125;.toList</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    	          a<span class="token punctuation">.</span> 在getShuffleDependencies方法中，找到resultStage的上一级shuffleRDD</pre></td></tr><tr><td data-num="14"></td><td><pre>    	           val parents <span class="token operator">=</span> new HashSet<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment">-- 存放宽依赖</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                    val visited <span class="token operator">=</span> new HashSet<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment">-- 创建一个 hashSet 集合，用来存放已经被访问过的 RDD</span></pre></td></tr><tr><td data-num="16"></td><td><pre>                    val waitingForVisit <span class="token operator">=</span> new ArrayStack<span class="token punctuation">[</span>RDD<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token comment">-- 集合的栈，创建一个集合，用来存放待访问的 RDD</span></pre></td></tr><tr><td data-num="17"></td><td><pre>                    waitingForVisit<span class="token punctuation">.</span>push<span class="token punctuation">(</span>rdd<span class="token punctuation">)</span>    <span class="token comment">-- 将最后的一个 RDD 传到这个集合中</span></pre></td></tr><tr><td data-num="18"></td><td><pre>                    <span class="token keyword">while</span> <span class="token punctuation">(</span>waitingForVisit<span class="token punctuation">.</span>nonEmpty<span class="token punctuation">)</span> &#123; <span class="token comment">-- 集合是否为空，刚放进去，肯定不是空</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                      val toVisit <span class="token operator">=</span> waitingForVisit<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment">-- pop，弹栈，将刚刚放进去的 RDD 弹出来，并准备去访问</span></pre></td></tr><tr><td data-num="20"></td><td><pre>                      <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>visited<span class="token punctuation">(</span>toVisit<span class="token punctuation">)</span><span class="token punctuation">)</span> &#123;  <span class="token comment">-- 当前放进去的 RDD 是否被访问过，如果没有，则继续向下执行</span></pre></td></tr><tr><td data-num="21"></td><td><pre>                        visited <span class="token operator">+</span><span class="token operator">=</span> toVisit      <span class="token comment">-- 将当前获取的 RDD 放进已经被访问的 RDD 集合中</span></pre></td></tr><tr><td data-num="22"></td><td><pre>                        toVisit<span class="token punctuation">.</span>dependencies<span class="token punctuation">.</span>foreach &#123;  <span class="token comment">-- 获取 RDD 与直接上级的 RDD 的依赖关系，并循环遍历。</span></pre></td></tr><tr><td data-num="23"></td><td><pre>                          <span class="token keyword">case</span> shuffleDep: ShuffleDependency<span class="token punctuation">[</span>_<span class="token punctuation">,</span> _<span class="token punctuation">,</span> _<span class="token punctuation">]</span> <span class="token operator">=</span><span class="token operator">></span> <span class="token comment">-- 如果是宽依赖</span></pre></td></tr><tr><td data-num="24"></td><td><pre>                            parents <span class="token operator">+</span><span class="token operator">=</span> shuffleDep  <span class="token comment">-- 则将依赖加入 parents 集合中</span></pre></td></tr><tr><td data-num="25"></td><td><pre>                          <span class="token keyword">case</span> dependency <span class="token operator">=</span><span class="token operator">></span></pre></td></tr><tr><td data-num="26"></td><td><pre>                            waitingForVisit<span class="token punctuation">.</span>push<span class="token punctuation">(</span>dependency<span class="token punctuation">.</span>rdd<span class="token punctuation">)</span> <span class="token comment">-- 如果是窄依赖，将上级 RDD 放进等待访问的 RDD 中，并</span></pre></td></tr><tr><td data-num="27"></td><td><pre>                                                                 进行循环，判断其与上级RDD的依赖关系，直到当前的RDD为</pre></td></tr><tr><td data-num="28"></td><td><pre>                                                                 shuffleRDD</pre></td></tr><tr><td data-num="29"></td><td><pre>                             &#125;</pre></td></tr><tr><td data-num="30"></td><td><pre>                      &#125;</pre></td></tr><tr><td data-num="31"></td><td><pre>                    &#125;</pre></td></tr><tr><td data-num="32"></td><td><pre>                    parents   <span class="token comment">-- 将上一级 shuffleRDD 放进 parents 的集合中</span></pre></td></tr><tr><td data-num="33"></td><td><pre>                    </pre></td></tr><tr><td data-num="34"></td><td><pre>                    获取当前RDD与直接上级的RDD的依赖关系，返回一个seq序列集合，因为当前的RDD的直接上级的RDD可能有多个</pre></td></tr><tr><td data-num="35"></td><td><pre>                    <span class="token comment">-- toVisit.dependencies</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                 b、通过map方法，对resultStage上级的shuffleRDD进行遍历，调用如下方法：返回获取的ShuffleDependency，执行获取或创建shuffleMapStage，点击这个方法</pre></td></tr><tr><td data-num="37"></td><td><pre>                    <span class="token comment">-- getOrCreateShuffleMapStage</span></pre></td></tr><tr><td data-num="38"></td><td><pre>                        创建shuffleMapStage，每一个shuffleDep创建一个shuffleMapStage</pre></td></tr><tr><td data-num="39"></td><td><pre>                        <span class="token comment">-- createShuffleMapStage(shuffleDep, firstJobId)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>                            new出一个shuffleMapStage</pre></td></tr><tr><td data-num="41"></td><td><pre>                            <span class="token comment">// 将依赖的上一级 RDD 赋值给 rdd</span></pre></td></tr><tr><td data-num="42"></td><td><pre>                            <span class="token comment">--val rdd = shuffleDep.rdd</span></pre></td></tr><tr><td data-num="43"></td><td><pre>                            <span class="token comment">// 又调用了创建或获取上一级阶段</span></pre></td></tr><tr><td data-num="44"></td><td><pre>                            <span class="token comment">-- val parents = getOrCreateParentStages(rdd, jobId)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>                            <span class="token comment">-- val stage = new ShuffleMapStage</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--2. 阶段的类型</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   ResultStage 和 shuffleMapStage</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">--3. 阶段的数量</span></pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token operator">=</span> ResultStage  <span class="token operator">+</span> n <span class="token operator">*</span>  shuffleMapStage</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">--4. 任务和分区的关系</span></pre></td></tr><tr><td data-num="6"></td><td><pre>     <span class="token number">1.</span> 提交最后一个阶段：</pre></td></tr><tr><td data-num="7"></td><td><pre>       <span class="token comment">--submitStage(finalStage)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>           <span class="token number">1.</span> 获取当前阶段的上一级阶段</pre></td></tr><tr><td data-num="9"></td><td><pre>           <span class="token comment">--  val missing = getMissingParentStages(stage).sortBy(_.id)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>           <span class="token number">2.</span> 如果有上一级阶段不为空，则循环遍历上一阶段，先假如上一级阶段只有一个，则提交上一个阶段，又调用提交阶段</pre></td></tr><tr><td data-num="11"></td><td><pre>           <span class="token comment">--for (parent &lt;- missing) &#123;submitStage(parent)&#125;</span></pre></td></tr><tr><td data-num="12"></td><td><pre>           </pre></td></tr><tr><td data-num="13"></td><td><pre>  <span class="token string">"总结：在提交阶段时，从最后一个阶段往前找，直到最前面的一个阶段，然后再依次从前往后进行提交阶段"</span>。             </pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token number">2.</span> 当没有上一级阶段以后，提交任务</pre></td></tr><tr><td data-num="15"></td><td><pre>       <span class="token comment">-- submitMissingTasks(stage, jobId.get)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>          <span class="token comment">// 1. 对当前阶段进行模式匹配，确认是 shuffleMapSrage 还是 ResultStage，返回结果为 taskIdToLocations, 任务本地化路径</span></pre></td></tr><tr><td data-num="17"></td><td><pre>          <span class="token comment">// 2. 如果当前阶段是 ShuffleMapStage，则创建 ShuffleMapTask</span></pre></td></tr><tr><td data-num="18"></td><td><pre>                如果当前阶段是ResultStage ，则创建ResultTask</pre></td></tr><tr><td data-num="19"></td><td><pre>           val tasks: Seq<span class="token punctuation">[</span>Task<span class="token punctuation">[</span>_<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> try &#123;</pre></td></tr><tr><td data-num="20"></td><td><pre>            <span class="token keyword">case</span> stage: ShuffleMapStage</pre></td></tr><tr><td data-num="21"></td><td><pre>            partitionsToCompute<span class="token punctuation">.</span>map  <span class="token comment">--> 计算分区的数量，每一个分区，会执行如下创建任务的代码。</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            &#123;<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            new ShuffleMapTask<span class="token punctuation">(</span>stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptNumber</pre></td></tr><tr><td data-num="24"></td><td><pre>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>&#125;</pre></td></tr><tr><td data-num="25"></td><td><pre>           <span class="token keyword">case</span> stage: ResultStage <span class="token operator">=</span><span class="token operator">></span></pre></td></tr><tr><td data-num="26"></td><td><pre>            &#123;                   </pre></td></tr><tr><td data-num="27"></td><td><pre>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="28"></td><td><pre>            new ResultTask<span class="token punctuation">(</span>stage<span class="token punctuation">.</span>id<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>latestInfo<span class="token punctuation">.</span>attemptNumber<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="29"></td><td><pre>            <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="30"></td><td><pre>                   &#125;</pre></td></tr><tr><td data-num="31"></td><td><pre><span class="token comment">-- 5. task 的类型：</span></pre></td></tr><tr><td data-num="32"></td><td><pre>      a、如果当前阶段是ShuffleMapStage，则创建ShuffleMapTask</pre></td></tr><tr><td data-num="33"></td><td><pre>      b、如果当前阶段是ResultStage ，则创建ResultTask</pre></td></tr><tr><td data-num="34"></td><td><pre>    </pre></td></tr><tr><td data-num="35"></td><td><pre><span class="token comment">-- 6 . 任务的总数量</span></pre></td></tr><tr><td data-num="36"></td><td><pre>      <span class="token operator">=</span> 每个阶段的任务总和</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 总结：</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 通过resultStage最后一个RDD，进行循环依次向上找，获取resultStage阶段，上一级为shuffleDep的ShuffleDependency，</pre></td></tr><tr><td data-num="3"></td><td><pre>   存放到一个parents集合中</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">2.</span> 采用map算子，parents集合中的每个ShuffleDependency，获取到所有上级依赖为shuffleDep的RDD，然后每一个shuffleDep会创建</pre></td></tr><tr><td data-num="5"></td><td><pre>一个ShuffleMapStage阶段。</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token number">3.</span> 当找到job最前面一个RDD以后，开始从第一个阶段提交阶段，提交阶段时，首先获取当前阶段最后一个RDD的分区数量，在一个阶段中，每一个分区就会创建一个task，task的类型和阶段的类型匹配：</pre></td></tr><tr><td data-num="7"></td><td><pre>      a、如果当前阶段是ShuffleMapStage，则创建ShuffleMapTask</pre></td></tr><tr><td data-num="8"></td><td><pre>      b、如果当前阶段是ResultStage ，则创建ResultTask</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token number">4.</span> 当前阶段提交完成以后，就提交下一个阶段，依次类推，最后就会提交resultStage。</pre></td></tr></table></figure><h2 id="五-任务的执行"><a class="anchor" href="#五-任务的执行">#</a> 五、任务的执行</h2><h3 id="51-任务包含的内容"><a class="anchor" href="#51-任务包含的内容">#</a> 5.1 任务包含的内容</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span>任务的提交：</pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token comment">--new ShuffleMapTask(stage.id, stage.latestInfo.attemptNumber,taskBinary, part, locs, properties, serializedTaskMetrics, Option(jobId),Option(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span></pre></td></tr><tr><td data-num="3"></td><td><pre>  </pre></td></tr><tr><td data-num="4"></td><td><pre>  <span class="token number">2.</span> 提交的重要几个参数有：</pre></td></tr><tr><td data-num="5"></td><td><pre>     a、<span class="token string">"stage.id"</span>：任务从属的阶段id</pre></td></tr><tr><td data-num="6"></td><td><pre>     b、<span class="token string">"taskBinary"</span>：是一个广播变量，内容为：阶段的<span class="token string">"RDD"</span>和<span class="token string">"依赖关系"</span>序列化以后的二进制字节码，因为RDD是不保存数据，一旦任务执行失败，需要知道RDD的元数据信息以及依赖关系，才能进行重新计算。</pre></td></tr><tr><td data-num="7"></td><td><pre>         <span class="token number">1.</span> 是一个广播变量</pre></td></tr><tr><td data-num="8"></td><td><pre>         <span class="token comment">--var taskBinary: Broadcast[Array[Byte]] = null</span></pre></td></tr><tr><td data-num="9"></td><td><pre>         <span class="token number">2.</span> 将任务的二进制的字节码赋值给了这个广播变量</pre></td></tr><tr><td data-num="10"></td><td><pre>         <span class="token comment">--taskBinary = sc.broadcast(taskBinaryBytes)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>         <span class="token number">3.</span> 任务的二进制的字节码是通过对阶段匹配，如果是shuffle阶段，就会采用闭合的序列化器将阶段的RDD和阶段的依赖进行序列化</pre></td></tr><tr><td data-num="12"></td><td><pre>         <span class="token comment">--taskBinaryBytes = stage match &#123;</span></pre></td></tr><tr><td data-num="13"></td><td><pre>           <span class="token keyword">case</span> stage: ShuffleMapStage <span class="token operator">=</span><span class="token operator">></span></pre></td></tr><tr><td data-num="14"></td><td><pre>                JavaUtils<span class="token punctuation">.</span>bufferToArray<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                  closureSerializer<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span><span class="token punctuation">(</span>stage<span class="token punctuation">.</span>rdd<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>shuffleDep<span class="token punctuation">)</span>: AnyRef<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>             <span class="token keyword">case</span> stage: ResultStage <span class="token operator">=</span><span class="token operator">></span></pre></td></tr><tr><td data-num="17"></td><td><pre>            	JavaUtils<span class="token punctuation">.</span>bufferToArray<span class="token punctuation">(</span>closureSerializer<span class="token punctuation">.</span>serialize<span class="token punctuation">(</span><span class="token punctuation">(</span>stage<span class="token punctuation">.</span>rdd<span class="token punctuation">,</span> stage<span class="token punctuation">.</span>func<span class="token punctuation">)</span>: AnyRef<span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>            &#125;</pre></td></tr><tr><td data-num="19"></td><td><pre>      c、 <span class="token string">"part"</span> ：分区，指当前的task和哪个<span class="token keyword">partition</span>有关</pre></td></tr><tr><td data-num="20"></td><td><pre>          <span class="token comment">-- val part = partitions(id)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>      d、 <span class="token string">"locs"</span> ： 任务的首选位置</pre></td></tr><tr><td data-num="22"></td><td><pre>          <span class="token comment">-- val locs = taskIdToLocations(id)</span></pre></td></tr></table></figure><h3 id="52-序列化"><a class="anchor" href="#52-序列化">#</a> 5.2 序列化</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 默认的序列化：<span class="token string">"JavaSerializer"</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">1.</span> 在SparkContext中创建了SparkEnv，点击创建的方法，一层一层往里点：</pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token comment">-- _env = createSparkEnv(_conf, isLocal, listenerBus)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>        <span class="token number">1.</span> 最终看到了默认的序列化器为：JavaSerializer</pre></td></tr><tr><td data-num="5"></td><td><pre>        <span class="token comment">--val serializer = instantiateClassFromConf[Serializer](</span></pre></td></tr><tr><td data-num="6"></td><td><pre>      		<span class="token string">"spark.serializer"</span><span class="token punctuation">,</span> <span class="token string">"org.apache.spark.serializer.JavaSerializer"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>   				 logDebug<span class="token punctuation">(</span>s<span class="token string">"Using serializer: $&#123;serializer.getClass&#125;"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">2.</span> kryo序列化:</pre></td></tr><tr><td data-num="9"></td><td><pre>      <span class="token comment">--1. 特点：</span></pre></td></tr><tr><td data-num="10"></td><td><pre>          a、性能优</pre></td></tr><tr><td data-num="11"></td><td><pre>          b、序列化结果文件的字节数少</pre></td></tr><tr><td data-num="12"></td><td><pre>          c、可以绕过java的序列化，将不能序列的对象也能进行序列化</pre></td></tr><tr><td data-num="13"></td><td><pre>          d、但是，我们在实际的情况下，并不是所有的对象都会采用kryo序列化。</pre></td></tr><tr><td data-num="14"></td><td><pre>     <span class="token comment">--2. 那么哪些对象采用 kryo 序列化会比较有优势呢？</span></pre></td></tr><tr><td data-num="15"></td><td><pre>          <span class="token string">"总结：在shuffle阶段，当为kv类型时，k、v的数据类型如果都支持kryo序列，则会采用kryo进行序列化。</span></pre></td></tr><tr><td data-num="16"></td><td><pre>                支持ktyo序列化的数据类型有：String和值类型(anyVal)"</pre></td></tr><tr><td data-num="17"></td><td><pre>          </pre></td></tr><tr><td data-num="18"></td><td><pre>         底层：当有shuffle阶段时，会选择最好的序列化器</pre></td></tr><tr><td data-num="19"></td><td><pre>         <span class="token comment">-- Pick the best serializer for shuffling an RDD of key-value pairs.</span></pre></td></tr><tr><td data-num="20"></td><td><pre>         <span class="token number">2.</span> 判断选择的规则：</pre></td></tr><tr><td data-num="21"></td><td><pre>            如果kv的k和v都能使用kryo序列化器时，则选择kryo序列化器，否则选择默认的序列化器：javaSerializer</pre></td></tr><tr><td data-num="22"></td><td><pre>            当为如下类型（值类型）或者是string类型的时候，则可以使用kyro序列化器</pre></td></tr><tr><td data-num="23"></td><td><pre>            <span class="token comment">--if (canUseKryo(keyClassTag) &amp;&amp; canUseKryo(valueClassTag)) &#123;</span></pre></td></tr><tr><td data-num="24"></td><td><pre>              kryoSerializer</pre></td></tr><tr><td data-num="25"></td><td><pre>            &#125; <span class="token keyword">else</span> &#123;</pre></td></tr><tr><td data-num="26"></td><td><pre>              defaultSerializer</pre></td></tr><tr><td data-num="27"></td><td><pre>            &#125;</pre></td></tr><tr><td data-num="28"></td><td><pre>            </pre></td></tr><tr><td data-num="29"></td><td><pre>              <span class="token comment">--  ClassTag.Boolean,</span></pre></td></tr><tr><td data-num="30"></td><td><pre>                  ClassTag<span class="token punctuation">.</span>Byte<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="31"></td><td><pre>                  ClassTag<span class="token punctuation">.</span><span class="token keyword">Char</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="32"></td><td><pre>                  ClassTag<span class="token punctuation">.</span><span class="token keyword">Double</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="33"></td><td><pre>                  ClassTag<span class="token punctuation">.</span><span class="token keyword">Float</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="34"></td><td><pre>                  ClassTag<span class="token punctuation">.</span><span class="token keyword">Int</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="35"></td><td><pre>                  ClassTag<span class="token punctuation">.</span>Long<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                  ClassTag<span class="token punctuation">.</span><span class="token boolean">Null</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="37"></td><td><pre>                  ClassTag<span class="token punctuation">.</span>Short</pre></td></tr></table></figure><h3 id="53-任务的调度"><a class="anchor" href="#53-任务的调度">#</a> 5.3 任务的调度</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. driver 生成的任务以后存放在哪里了？</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   a、当driver生成任务以后，并不是立即将任务task就发送给executor，因为可能发送过程有异常，也可能发送过去的时候，executor对象还没有创建，都会导致任务task发送失败</pre></td></tr><tr><td data-num="3"></td><td><pre>  </pre></td></tr><tr><td data-num="4"></td><td><pre>      <span class="token number">1.</span> 一个阶段stage生成tasks以后，如果这个阶段的tasks的数量大于<span class="token number">0</span>，那么这个任务调度器就会提交任务，在提交任务中，会将这个</pre></td></tr><tr><td data-num="5"></td><td><pre>          stage的任务封装成一个TaskSet<span class="token punctuation">,</span>任务集进行提交，点击submitTasks</pre></td></tr><tr><td data-num="6"></td><td><pre>      <span class="token comment">-- if (tasks.size > 0)，taskScheduler.submitTasks(new TaskSet( tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties))</span></pre></td></tr><tr><td data-num="7"></td><td><pre>              <span class="token number">1.</span>首先取出任务</pre></td></tr><tr><td data-num="8"></td><td><pre>              <span class="token comment">--val tasks = taskSet.tasks</span></pre></td></tr><tr><td data-num="9"></td><td><pre>              <span class="token number">2.</span> 创建一个任务集taskset的管理者manager</pre></td></tr><tr><td data-num="10"></td><td><pre>              <span class="token comment">-- val manager = createTaskSetManager(taskSet, maxTaskFailures)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>              <span class="token number">3.</span> 构建调度器，将刚刚创建的任务集管理者放到调度器中，点击addTaskSetManager</pre></td></tr><tr><td data-num="12"></td><td><pre>              <span class="token comment">--schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>                  <span class="token number">1.</span>是一个抽象方法，类是一个trait，有两个实现类，分别是：</pre></td></tr><tr><td data-num="14"></td><td><pre>                        FIFOSchedulableBuilder <span class="token comment">--> 先进先出调度器</span></pre></td></tr><tr><td data-num="15"></td><td><pre>                        FairSchedulableBuilder <span class="token comment">--> 公平调度器</span></pre></td></tr><tr><td data-num="16"></td><td><pre>                        那么我们新增加进去的manager是采用什么调度器呢？</pre></td></tr><tr><td data-num="17"></td><td><pre>                            a、通过源码可知，默认的调度模式为FIFO模式</pre></td></tr><tr><td data-num="18"></td><td><pre>                            <span class="token comment">-- private val schedulingModeConf = conf.get(SCHEDULER_MODE_PROPERTY, SchedulingMode.FIFO.toString)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                            b、创建一个任务调度池，当driver生成任务以后，会将任务放进任务池中，由manager来进行调度</pre></td></tr><tr><td data-num="20"></td><td><pre>                            val rootPool: Pool <span class="token operator">=</span> new Pool<span class="token punctuation">(</span><span class="token string">""</span><span class="token punctuation">,</span> schedulingMode<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>                   <span class="token number">2.</span> 将manager直接放进调度池中，</pre></td></tr><tr><td data-num="22"></td><td><pre>                    rootPool<span class="token punctuation">.</span>addSchedulable<span class="token punctuation">(</span>manager<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>                <span class="token number">4.</span> 点击<span class="token punctuation">.</span>reviveOffers：恢复当前的操作</pre></td></tr><tr><td data-num="24"></td><td><pre>               <span class="token comment">--backend.reviveOffers()</span></pre></td></tr><tr><td data-num="25"></td><td><pre>                   <span class="token number">1.</span>driver的终端，自己给自己发消息</pre></td></tr><tr><td data-num="26"></td><td><pre>                    <span class="token comment">-- driverEndpoint.send(ReviveOffers)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>                    <span class="token number">2.</span>在DriverEndpoint中，就有一个receive方法，在这个方法中，匹配获取的消息，如果是ReviveOffers<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="28"></td><td><pre>                    则执行makeOffers<span class="token punctuation">(</span><span class="token punctuation">)</span>方法，点击makeOffers<span class="token punctuation">(</span><span class="token punctuation">)</span>方法</pre></td></tr><tr><td data-num="29"></td><td><pre>                     <span class="token comment">-- case ReviveOffers =>makeOffers()</span></pre></td></tr><tr><td data-num="30"></td><td><pre>                         a、DriverEndpoint调度器从任务池中取出任务，取任务的具体方式：点击resourceOffers</pre></td></tr><tr><td data-num="31"></td><td><pre>                          <span class="token comment">-- val taskDescs = scheduler.resourceOffers(workOffers)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>                               a、获取一个排好序的任务集合，实现方式，点击getSortedTaskSetQueue</pre></td></tr><tr><td data-num="33"></td><td><pre>                                <span class="token comment">--val sortedTaskSets = rootPool.getSortedTaskSetQueue</span></pre></td></tr><tr><td data-num="34"></td><td><pre>                                     a、如下为任务集的调度的算法，依据算法对任务集进行比较排序，返回排好序的任务集，然后将</pre></td></tr><tr><td data-num="35"></td><td><pre>                                     返回任务集存放到一个arraybuffer集合中，并返回给到sortedTaskSets，不同的调度的算法</pre></td></tr><tr><td data-num="36"></td><td><pre>                                     是不一样的。</pre></td></tr><tr><td data-num="37"></td><td><pre>                                     <span class="token string">"FIFO调度算法"</span>：先比较优先级，优先级高的先调度，如果优先级相等，则比较阶段id，阶段</pre></td></tr><tr><td data-num="38"></td><td><pre>                                                    id小的先执行。</pre></td></tr><tr><td data-num="39"></td><td><pre>                                     <span class="token string">"Fair调度算法"</span>：根据运行任务的数量、权重【默认值为<span class="token number">1</span>】、最小分配数量【默认值为<span class="token number">0</span>】，</pre></td></tr><tr><td data-num="40"></td><td><pre>                                                    进行综合分配</pre></td></tr><tr><td data-num="41"></td><td><pre>                                      <span class="token comment">-- val sortedSchedulableQueue =</span></pre></td></tr><tr><td data-num="42"></td><td><pre>      schedulableQueue<span class="token punctuation">.</span>asScala<span class="token punctuation">.</span>toSeq<span class="token punctuation">.</span>sortWith<span class="token punctuation">(</span>taskSetSchedulingAlgorithm<span class="token punctuation">.</span>comparator<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        </pre></td></tr><tr><td data-num="44"></td><td><pre>                         b、如果任务不为空，则driver发射任务</pre></td></tr><tr><td data-num="45"></td><td><pre>                          <span class="token comment">-- if (!taskDescs.isEmpty) &#123;launchTasks(taskDescs)&#125;</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 总结</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   <span class="token number">1.</span> 一个stage生成tasks以后，由taskSchedule负责任务的调度</pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token number">2.</span> 一个stage就会有一个任务集，taskSet</pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token number">3.</span> 每一个taskSet都会被封装成TaskSetManager，负责监控管理同一个Stage中的Tasks，TaskScheduler调度模式有两种：</pre></td></tr><tr><td data-num="5"></td><td><pre>        a、FIFOSchedulableBuilder <span class="token comment">--> 先进先出调度器【默认调度模式】</span></pre></td></tr><tr><td data-num="6"></td><td><pre>        b、FairSchedulableBuilder <span class="token comment">--> 公平调度器</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>   <span class="token number">4.</span> TaskScheduler初始化过程中会实例化rootPool任务池，driver准备的任务和管理者会发送到这个任务池中，</pre></td></tr><tr><td data-num="9"></td><td><pre>      由TaskScheduler负责将任务调度结果发送给executor</pre></td></tr><tr><td data-num="10"></td><td><pre>   <span class="token number">5.</span> driver的终端自己给自己发送一个消息<span class="token string">"ReviveOffers"</span>，driverEndpoint收到ReviveOffer消息后调用makeOffers方法，TaskScheduler就开始进行任务集的调度</pre></td></tr><tr><td data-num="11"></td><td><pre>   <span class="token number">6.</span> 根据<span class="token string">"调度算法"</span>对任务集进行排序，获取一个排好序的队列<span class="token string">"排序在前的就先执行，排序在后的就后执行"</span>，将排好序的队列放到一个arraybuffer集合中，并返回给到sortedTaskSets</pre></td></tr><tr><td data-num="12"></td><td><pre>       </pre></td></tr><tr><td data-num="13"></td><td><pre>       <span class="token string">"FIFO调度算法"</span>：先比较优先级，优先级高的先调度，如果优先级相等，则比较阶段id，阶段 id小的先执行。</pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token string">"Fair调度算法"</span>：根据运行任务的数量、weight【默认值为<span class="token number">1</span>】、minShare【默认值为<span class="token number">0</span>】，进行综合分配</pre></td></tr><tr><td data-num="15"></td><td><pre>        minShare、weight的值均在公平调度配置文件<span class="token string">"fairscheduler.xml"</span>中被指定，调度池在构建阶段会读取此文件的相关配置</pre></td></tr><tr><td data-num="16"></td><td><pre>   <span class="token number">7.</span> <span class="token string">"driverEndpoint"</span>调度器就从这个排好序的任务队列的数组中取任务tasks。</pre></td></tr><tr><td data-num="17"></td><td><pre>   <span class="token number">8.</span> 如果获取的任务不为空，则dirver开始发射任务</pre></td></tr><tr><td data-num="18"></td><td><pre>   </pre></td></tr><tr><td data-num="19"></td><td><pre><span class="token comment">-- 2. 说明：</span></pre></td></tr><tr><td data-num="20"></td><td><pre>   <span class="token number">1.</span> 从任务池中取出的任务，包含了本地化级别信息以及等待的时长<span class="token punctuation">(</span><span class="token string">"默认每个级别等待时间为3s，也可以单独设置每个级别的等待时间"</span><span class="token punctuation">)</span>，当在driver在发送任务的时候，会根据本地化级别进行发送任务<span class="token punctuation">.</span></pre></td></tr><tr><td data-num="21"></td><td><pre>   </pre></td></tr><tr><td data-num="22"></td><td><pre><span class="token comment">-- 3. 区分本地化级别和调度算法</span></pre></td></tr><tr><td data-num="23"></td><td><pre>    调度算法：是指driverEndpoint在调度任务集时，确定哪个任务集先执行，哪个任务集后执行</pre></td></tr><tr><td data-num="24"></td><td><pre>    本地化级别：是指driver在发送向executor发送任务的首选位置，确定任务发送到哪个executor中，如果发送不成功，并进行降级处理</pre></td></tr></table></figure><h3 id="54-任务的计算"><a class="anchor" href="#54-任务的计算">#</a> 5.4 任务的计算</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> driver发送任务前，会将任务进行编码：</pre></td></tr><tr><td data-num="2"></td><td><pre>    	<span class="token comment">--val serializedTask = TaskDescription.encode(task)  </span></pre></td></tr><tr><td data-num="3"></td><td><pre>    </pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token number">2.</span> 然后向executor发送已经编码和序列化的任务task</pre></td></tr><tr><td data-num="5"></td><td><pre>   		<span class="token comment">-- executorData.executorEndpoint.send(LaunchTask(new SerializableBuffer(serializedTask))</span></pre></td></tr><tr><td data-num="6"></td><td><pre>   </pre></td></tr><tr><td data-num="7"></td><td><pre>   <span class="token number">3.</span> 在executorbackend就会收到任务<span class="token punctuation">(</span>receive<span class="token punctuation">)</span>并启动任务<span class="token punctuation">,</span>首先是对任务进行解码，然后executor启动任务，点击launchTask</pre></td></tr><tr><td data-num="8"></td><td><pre>    	<span class="token comment">--val taskDesc = TaskDescription.decode(data.value)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        logInfo<span class="token punctuation">(</span><span class="token string">"Got assigned task "</span> <span class="token operator">+</span> taskDesc<span class="token punctuation">.</span>taskId<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        executor<span class="token punctuation">.</span>launchTask<span class="token punctuation">(</span>this<span class="token punctuation">,</span> taskDesc<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>   </pre></td></tr><tr><td data-num="12"></td><td><pre>   <span class="token number">4.</span>  来一个task就使用一个线程来接收</pre></td></tr><tr><td data-num="13"></td><td><pre>        <span class="token comment">--val tr = new TaskRunner(context, taskDescription)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        runningTasks<span class="token punctuation">.</span>put<span class="token punctuation">(</span>taskDescription<span class="token punctuation">.</span>taskId<span class="token punctuation">,</span> tr<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>        threadPool<span class="token punctuation">.</span><span class="token keyword">execute</span><span class="token punctuation">(</span>tr<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token number">5.</span> 线程中有一个run方法，方法中有一个逻辑为：task<span class="token punctuation">.</span>run，通过底层发现，其实调用的是具体task对象的runTask<span class="token punctuation">(</span><span class="token punctuation">)</span>方法</pre></td></tr></table></figure><h3 id="55-shuffle"><a class="anchor" href="#55-shuffle">#</a> 5.5 shuffle</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre>【在<span class="token string">"shuffleMapTask类"</span>中的runTask<span class="token punctuation">(</span><span class="token punctuation">)</span>方法中】</pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token number">1.</span> shuffle<span class="token string">"写操作"</span></pre></td></tr><tr><td data-num="3"></td><td><pre>  <span class="token comment">--var writer: ShuffleWriter[Any, Any] = null</span></pre></td></tr><tr><td data-num="4"></td><td><pre>  <span class="token number">2.</span> 在写操作之前，也会调用迭代器的方式，所以也可以实现<span class="token string">"读的操作"</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  <span class="token comment">--writer.write(rdd.iterator(partition, context)......</span></pre></td></tr><tr><td data-num="6"></td><td><pre>  </pre></td></tr><tr><td data-num="7"></td><td><pre>  【在<span class="token string">"resultTask类"</span>中的runTask<span class="token punctuation">(</span><span class="token punctuation">)</span>方法中，那么就得有读数据的操作】</pre></td></tr><tr><td data-num="8"></td><td><pre>  <span class="token number">1.</span> RDD中不保存数据，所以操作的时候数据是一条一条的执行，则会调用迭代器的方法，点击iterator方法</pre></td></tr><tr><td data-num="9"></td><td><pre>  <span class="token comment">-- func(context, rdd.iterator(partition, context))</span></pre></td></tr><tr><td data-num="10"></td><td><pre>      <span class="token number">1.</span> 一层一层的调，在shuffleRDD中的computer中有：<span class="token string">"读的操作"</span></pre></td></tr><tr><td data-num="11"></td><td><pre>       <span class="token comment">-- SparkEnv.get.shuffleManager.getReader(dep.shuffleHandle, split.index, split.index + 1, context).read()</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">"分支1"</span>： Shuffle map<span class="token punctuation">(</span><span class="token keyword">Write</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>      <span class="token number">1.</span> 点击getWrite</pre></td></tr><tr><td data-num="3"></td><td><pre>      <span class="token comment">-- writer = manager.getWriter[Any, Any](dep.shuffleHandle, partitionId, context)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>            <span class="token number">1.</span> getWriter是一个抽象方法，所在的类为：ShuffleManager，<span class="token string">'shuffle管理器'</span>，获取其实现类：<span class="token string">"SortShuffleManager"</span></pre></td></tr><tr><td data-num="5"></td><td><pre>               是一个可排序的shuffleManager管理器。查询这个管理类的getWriter方法，在这个方法中，对handle的类型进行模式匹</pre></td></tr><tr><td data-num="6"></td><td><pre>               配，所以现在handle就很很重要了，从模式匹配项，可以知道有<span class="token number">3</span>种不同类型的handle，而且handle来自<span class="token string">"getWriter方法"</span></pre></td></tr><tr><td data-num="7"></td><td><pre>               <span class="token comment">-- handle match &#123;</span></pre></td></tr><tr><td data-num="8"></td><td><pre>                  <span class="token keyword">case</span> unsafeShuffleHandle: SerializedShuffleHandle</pre></td></tr><tr><td data-num="9"></td><td><pre>                  <span class="token keyword">case</span> bypassMergeSortHandle: BypassMergeSortShuffleHandle</pre></td></tr><tr><td data-num="10"></td><td><pre>                  <span class="token keyword">case</span> other: BaseShuffleHandle</pre></td></tr><tr><td data-num="11"></td><td><pre>      <span class="token number">2.</span>在 <span class="token string">"manager.getWriter"</span>方法中的handle到底是什么？看源码</pre></td></tr><tr><td data-num="12"></td><td><pre>             <span class="token number">1.</span> 是shuffle管理器注册shuffle获取的，点击registerShuffle</pre></td></tr><tr><td data-num="13"></td><td><pre>             <span class="token comment">--val shuffleHandle: ShuffleHandle = _rdd.context.env.shuffleManager.registerShuffle(</span></pre></td></tr><tr><td data-num="14"></td><td><pre>        shuffleId<span class="token punctuation">,</span> _rdd<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>length<span class="token punctuation">,</span> this<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>             <span class="token number">2.</span> 是一个抽象方法，获取抽象类<span class="token string">"ShuffleManager"</span>的实现类<span class="token string">"SortShuffleManager"</span><span class="token punctuation">,</span>查询<span class="token string">"registerShuffle"</span>方法</pre></td></tr><tr><td data-num="16"></td><td><pre>                    从这里发现，确实有三种handle：</pre></td></tr><tr><td data-num="17"></td><td><pre>                    a、如果忽略索引文件的排序 <span class="token comment">--> 创建 BypassMergeSortShuffleHandle</span></pre></td></tr><tr><td data-num="18"></td><td><pre>                    b、如果可以实现序列化    <span class="token comment">--> 创建 SerializedShuffleHandle</span></pre></td></tr><tr><td data-num="19"></td><td><pre>                    c、如果不是以上两种      <span class="token comment">--> 创建 BaseShuffleHandle</span></pre></td></tr><tr><td data-num="20"></td><td><pre>                   <span class="token comment">--if (SortShuffleWriter.shouldBypassMergeSort(conf, dependency)) &#123;  </span></pre></td></tr><tr><td data-num="21"></td><td><pre>                          new BypassMergeSortShuffleHandle<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="22"></td><td><pre>                            shuffleId<span class="token punctuation">,</span> numMaps<span class="token punctuation">,</span> dependency<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre>                        &#125; <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>SortShuffleManager<span class="token punctuation">.</span>canUseSerializedShuffle<span class="token punctuation">(</span>dependency<span class="token punctuation">)</span><span class="token punctuation">)</span> &#123;  </pre></td></tr><tr><td data-num="24"></td><td><pre>                          new SerializedShuffleHandle<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="25"></td><td><pre>                            shuffleId<span class="token punctuation">,</span> numMaps<span class="token punctuation">,</span> dependency<span class="token punctuation">.</span>asInstanceOf<span class="token punctuation">[</span>ShuffleDependency<span class="token punctuation">[</span>K<span class="token punctuation">,</span> V<span class="token punctuation">,</span> V<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>                        &#125; <span class="token keyword">else</span> &#123;     </pre></td></tr><tr><td data-num="27"></td><td><pre>                          new BaseShuffleHandle<span class="token punctuation">(</span>shuffleId<span class="token punctuation">,</span> numMaps<span class="token punctuation">,</span> dependency<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>                        &#125;</pre></td></tr><tr><td data-num="29"></td><td><pre>                      &#125;</pre></td></tr><tr><td data-num="30"></td><td><pre>                      <span class="token number">1.</span> 点击<span class="token string">"shouldBypassMergeSort"</span><span class="token punctuation">,</span>查看什么情况下忽略排序，如果当前rdd的map端有预聚合功能，就</pre></td></tr><tr><td data-num="31"></td><td><pre>                         不能忽略排序，如reduceByKey算子</pre></td></tr><tr><td data-num="32"></td><td><pre>                        <span class="token comment">-- if (dep.mapSideCombine) &#123;false&#125;</span></pre></td></tr><tr><td data-num="33"></td><td><pre>                        如果map端没有预聚合功能，首先获取忽略合并的阈值，如果没有显示设置，就会默认给<span class="token number">200</span>，如果当前RDD的</pre></td></tr><tr><td data-num="34"></td><td><pre>                        分区器的分区数量小于这个阈值，那么就返回<span class="token boolean">true</span>，则此时创建<span class="token string">"BypassMergeSortShuffleHandle"</span></pre></td></tr><tr><td data-num="35"></td><td><pre>                        <span class="token comment">--else &#123;</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                        val bypassMergeThreshold: <span class="token keyword">Int</span> <span class="token operator">=</span> conf<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token string">"spark.shuffle.sortbypassMergeThreshold"</span><span class="token punctuation">,</span> <span class="token number">200</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>                        dep<span class="token punctuation">.</span>partitioner<span class="token punctuation">.</span>numPartitions <span class="token operator">&lt;=</span> bypassMergeThreshold</pre></td></tr><tr><td data-num="38"></td><td><pre>                        <span class="token comment">-- 所以总结就是当 rdd 的 map 端没有预聚合功能，且分区器的分区数量小于阈值，那么就会创建</span></pre></td></tr><tr><td data-num="39"></td><td><pre>                            <span class="token string">"BypassMergeSortShuffleHandle"</span></pre></td></tr><tr><td data-num="40"></td><td><pre>                     <span class="token number">2.</span> 点击<span class="token string">"canUseSerializedShuffle"</span><span class="token punctuation">,</span>Spark的内存优化后的解决方案<span class="token punctuation">,</span>对象序列化后不需要反序列化。</pre></td></tr><tr><td data-num="41"></td><td><pre>                          <span class="token comment">// 通过以下代码可知，创建 "SerializedShuffleHandle" 的条件为，满足以下三个条件即可：</span></pre></td></tr><tr><td data-num="42"></td><td><pre>                             a、序列化对象需要<span class="token string">"支持"</span>重定义</pre></td></tr><tr><td data-num="43"></td><td><pre>                             b、依赖的map端<span class="token string">"没有"</span>预聚合功能</pre></td></tr><tr><td data-num="44"></td><td><pre>                             c、分区数量<span class="token string">"小于"</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">24</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token number">16777215</span></pre></td></tr><tr><td data-num="45"></td><td><pre>                          <span class="token keyword">if</span> <span class="token punctuation">(</span><span class="token operator">!</span>dependency<span class="token punctuation">.</span>serializer<span class="token punctuation">.</span>supportsRelocationOfSerializedObjects<span class="token punctuation">)</span> &#123; <span class="token boolean">false</span>&#125; </pre></td></tr><tr><td data-num="46"></td><td><pre>                          <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>dependency<span class="token punctuation">.</span>mapSideCombine<span class="token punctuation">)</span> &#123;<span class="token boolean">false</span> &#125; </pre></td></tr><tr><td data-num="47"></td><td><pre>                          <span class="token keyword">else</span> <span class="token keyword">if</span> <span class="token punctuation">(</span>numPartitions <span class="token operator">></span> MAX_SHUFFLE_OUTPUT_PARTITIONS_FOR_SERIALIZED_MODE<span class="token punctuation">)</span> &#123; <span class="token boolean">false</span>&#125; </pre></td></tr><tr><td data-num="48"></td><td><pre>                          <span class="token keyword">else</span> &#123;<span class="token boolean">true</span> &#125;</pre></td></tr><tr><td data-num="49"></td><td><pre>                     <span class="token number">3.</span> 如果以上两个handle都不满足，则选择最后一个handle：<span class="token string">"BaseShuffleHandle"</span> <span class="token comment">--> 默认的 handle</span></pre></td></tr><tr><td data-num="50"></td><td><pre>                                             </pre></td></tr><tr><td data-num="51"></td><td><pre><span class="token string">"分支2"</span>：Shuffle reduce<span class="token punctuation">(</span><span class="token keyword">Read</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 总结： shuffle 的 handle 有三种：</span></pre></td></tr><tr><td data-num="2"></td><td><pre>     <span class="token number">1.</span> BypassMergeSortShuffleHandle  <span class="token comment">--> BypassMergeSortShuffleWriter</span></pre></td></tr><tr><td data-num="3"></td><td><pre>        <span class="token string">"条件"</span>：</pre></td></tr><tr><td data-num="4"></td><td><pre>        a、当前rdd的map端没有预聚合功能，如groupBy</pre></td></tr><tr><td data-num="5"></td><td><pre>        b、分区器的分区数量小于阈值<span class="token punctuation">,</span>默认为<span class="token number">200</span>        </pre></td></tr><tr><td data-num="6"></td><td><pre>     <span class="token number">2.</span> SerializedShuffleHandle      <span class="token comment">--> UnsafeShuffleWriter</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token string">"条件"</span>：</pre></td></tr><tr><td data-num="8"></td><td><pre>        a、序列化对象需要<span class="token string">"支持"</span>重定义</pre></td></tr><tr><td data-num="9"></td><td><pre>        b、依赖的map端<span class="token string">"没有"</span>预聚合功能</pre></td></tr><tr><td data-num="10"></td><td><pre>        c、分区数量<span class="token string">"小于"</span><span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">&lt;&lt;</span> <span class="token number">24</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span> <span class="token operator">=</span> <span class="token number">16777215</span></pre></td></tr><tr><td data-num="11"></td><td><pre>     <span class="token number">3.</span> BaseShuffleHandle           <span class="token comment">--> SortShuffleWriter</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        <span class="token string">"默认的handle"</span></pre></td></tr><tr><td data-num="13"></td><td><pre>如果前两种都不满足，那么就使用默认的<span class="token keyword">write</span></pre></td></tr><tr><td data-num="14"></td><td><pre>拿着这三种handle，再来看这个<span class="token string">"getWrite"</span>方法</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- handle match &#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>     <span class="token comment">-- case unsafeShuffleHandle: SerializedShuffleHandle =></span></pre></td></tr><tr><td data-num="3"></td><td><pre>        new UnsafeShuffleWriter<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>  </pre></td></tr><tr><td data-num="4"></td><td><pre>     <span class="token comment">-- case bypassMergeSortHandle: BypassMergeSortShuffleHandle =></span></pre></td></tr><tr><td data-num="5"></td><td><pre>        new BypassMergeSortShuffleWriter<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="6"></td><td><pre>     <span class="token comment">-- case other: BaseShuffleHandle =></span></pre></td></tr><tr><td data-num="7"></td><td><pre>        new SortShuffleWriter<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="8"></td><td><pre> </pre></td></tr><tr><td data-num="9"></td><td><pre> <span class="token string">"不同的handle对应不同的writer"</span></pre></td></tr><tr><td data-num="10"></td><td><pre>     <span class="token number">1.</span> BypassMergeSortShuffleHandle  <span class="token comment">--> BypassMergeSortShuffleWriter</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        <span class="token comment">// 点击 "BypassMergeSortShuffleWriter" 中的 write 方法，如下代码，根据分区的数量进行循环，' 每一个分区就向磁盘写一个文</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        件'。 即map端的每一个task会为reduce端的每一个task都创建一个临时磁盘文件<span class="token punctuation">,</span>根据<span class="token keyword">key</span>的hashcode<span class="token operator">%</span>分区数量，决定数据去到</pre></td></tr><tr><td data-num="13"></td><td><pre>        哪个分区文件中。</pre></td></tr><tr><td data-num="14"></td><td><pre>        <span class="token comment">-- for (int i = 0; i &lt; numPartitions; i++) &#123;</span></pre></td></tr><tr><td data-num="15"></td><td><pre>      partitionWriters<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> blockManager<span class="token punctuation">.</span>getDiskWriter<span class="token punctuation">(</span>blockId<span class="token punctuation">,</span> <span class="token keyword">file</span><span class="token punctuation">,</span> serInstance<span class="token punctuation">,</span> fileBufferSize<span class="token punctuation">,</span> writeMetrics<span class="token punctuation">)</span><span class="token punctuation">;</span>&#125;</pre></td></tr><tr><td data-num="16"></td><td><pre>       </pre></td></tr><tr><td data-num="17"></td><td><pre>     <span class="token number">2.</span> SerializedShuffleHandle       <span class="token comment">--> UnsafeShuffleWriter </span></pre></td></tr><tr><td data-num="18"></td><td><pre>   </pre></td></tr><tr><td data-num="19"></td><td><pre>     <span class="token number">3.</span> BaseShuffleHandle<span class="token punctuation">,</span><span class="token string">"重要"</span>       <span class="token comment">--> SortShuffleWriter</span></pre></td></tr><tr><td data-num="20"></td><td><pre>         <span class="token comment">// 点击 "SortShuffleWriter" 中的 write 方法，如下代码：</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        <span class="token comment">// 1. "写文件过程"：写磁盘文件时，首先将数据写到内存中，并在内存中的进行排序，如果内存（5M）不够，会溢写磁盘，</span></pre></td></tr><tr><td data-num="22"></td><td><pre>        生成临时文件<span class="token punctuation">(</span>一个数据文件，一个索引文件<span class="token punctuation">)</span>，最终将所有的临时文件合并<span class="token punctuation">(</span>原来的数据文件和索引文件会被删除<span class="token punctuation">)</span>成数据</pre></td></tr><tr><td data-num="23"></td><td><pre>        文件和索引文件。</pre></td></tr><tr><td data-num="24"></td><td><pre>           <span class="token number">2.</span> <span class="token string">"预聚和的原理"</span>：在排序时，构造了一种类似于hashtable的结构，所以相同的<span class="token keyword">key</span>就聚合在一起。</pre></td></tr><tr><td data-num="25"></td><td><pre>           <span class="token number">3.</span> <span class="token string">"排序规则"</span>：首先会按照分区进行排序，然后按照<span class="token keyword">key</span><span class="token punctuation">.</span></pre></td></tr><tr><td data-num="26"></td><td><pre>           <span class="token number">4.</span> <span class="token string">"数据进入不同分区的原则"</span>：按照分区器的原则，默认是hashpartition，根据<span class="token keyword">key</span>的<span class="token keyword">hash</span><span class="token operator">%</span>分区数量。</pre></td></tr><tr><td data-num="27"></td><td><pre>         val partitionLengths <span class="token operator">=</span> sorter<span class="token punctuation">.</span>writePartitionedFile<span class="token punctuation">(</span>blockId<span class="token punctuation">,</span> tmp<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>         shuffleBlockResolver<span class="token punctuation">.</span>writeIndexFileAndCommit<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span></pre></td></tr></table></figure><p>![image-20200621180817513](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200621180817.png)</p><p>![image-20200620004312766](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620004312.png)</p><pre><code class="language-sqlite">-- 面试中常见shuffle的两个问题：
1. 我们现在spark使用了哪种shuffle，哪一种类型的？
   a、sortshuffle。
2. 忽略排序过程的shuffle什么时候会触发？
   a、map 端没有预聚合功能
   b、reduce端的分区数量小于一个阈值，默认是200
</code></pre><h2 id="六-spark内存管理"><a class="anchor" href="#六-spark内存管理">#</a> 六 、 Spark 内存管理</h2><h3 id="61-堆内内存和堆外内存"><a class="anchor" href="#61-堆内内存和堆外内存">#</a> 6.1 堆内内存和堆外内存</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. "堆内内存"：</span></pre></td></tr><tr><td data-num="2"></td><td><pre>        是指jvm所能使用的内存，并不是完全可以控制，如GC垃圾回收器的执行时间是不可控的，当你需要内存进行数据处理时，GC并不能立</pre></td></tr><tr><td data-num="3"></td><td><pre>        马释放内存给你使用。jvm虚拟机默认使用的内存大小是可用内存的<span class="token number">1</span><span class="token operator">/</span><span class="token number">64</span>，最大值是<span class="token number">1</span><span class="token operator">/</span><span class="token number">4</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token comment">--2. "堆外内存"：</span></pre></td></tr><tr><td data-num="5"></td><td><pre>         在jvm虚拟机之外的内存，可以存储我们的数据，这个内存是咱们向操作系统申请过来的，完全可控。<span class="token string">"默认是不启用堆外内存"</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment">--3. 设置堆外内存的参数：</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        a、启动堆外内存参数：spark<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>offHeap<span class="token punctuation">.</span>enabled</pre></td></tr><tr><td data-num="8"></td><td><pre>        b、设定堆外内存的大小： spark<span class="token punctuation">.</span>memory<span class="token punctuation">.</span>offHeap<span class="token punctuation">.</span>size </pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token comment">--4. 在 spark 中，堆内和堆外内存可以进行统一的管理。</span></pre></td></tr></table></figure><h3 id="62-内存空间分配"><a class="anchor" href="#62-内存空间分配">#</a> 6.2 内存空间分配</h3><h4 id="621-早期内存管理"><a class="anchor" href="#621-早期内存管理">#</a> 6.2.1 早期内存管理</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token string">"早期各个区域的内存分配好了以后，就需要严格遵守这个规则，内存大小不可变。"</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">--1. 内存空间的分配：</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">1.</span> Storage：缓存RDD数据和广播变量的数据， <span class="token string">"内存大小占比60%"</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">2.</span> Execution：用于缓存在shuffle过程中的中间数据， <span class="token string">"内存大小占比20%"</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">3.</span> Other：用户自定义的一些数据结构或者是Spark内部的元数据 ： <span class="token string">"内存大小占比20%"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment">-- 2. Storage 内存和 Execution 内存都有预留空间，目的是防止 OOM，因为 Spark 堆内内存大小的记录是不准确的，需要留出保险区域。</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment">-- 3. 当前不同区域内存大小分配存在的问题：</span></pre></td></tr><tr><td data-num="10"></td><td><pre>      Execution的内存过小，而Storage内存大小过多。</pre></td></tr><tr><td data-num="11"></td><td><pre>      </pre></td></tr><tr><td data-num="12"></td><td><pre> 从而就产生了新的内存分配原则</pre></td></tr></table></figure><ul><li>堆内内存</li></ul><p>![image-20200620012427321](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620012427.png)</p><ul><li>堆外内存</li></ul><p>![image-20200620015214858](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620015214.png)</p><h4 id="622-统一内存管理"><a class="anchor" href="#622-统一内存管理">#</a> 6.2.2 统一内存管理</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 什么是统一内存管理？</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   Spark1<span class="token punctuation">.</span><span class="token number">6</span> 之后引入的统一内存管理机制，各个区域内存的大小是可变的<span class="token punctuation">.</span></pre></td></tr><tr><td data-num="3"></td><td><pre> <span class="token comment">--2. 与静态内存管理的区别:</span></pre></td></tr><tr><td data-num="4"></td><td><pre>   统一内存管理<span class="token string">"存储内存"</span>和<span class="token string">"执行内存共享"</span>同一块空间，可以动态占用对方的空闲区域</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">-- 3. 当前 spark 默认的内存分配是按照统一内存管理的模式。</span></pre></td></tr></table></figure><ul><li>堆内内存</li></ul><p>![image-20200620015026859](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620015026.png)</p><ul><li>堆外内存</li></ul><p>![image-20200620015251558](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620015251.png)</p><h4 id="623-同一管理内存的优点"><a class="anchor" href="#623-同一管理内存的优点">#</a> 6.2.3 同一管理内存的优点</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 优点</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1</span><span class="token punctuation">)</span>设定基本的存储内存和执行内存区域（spark<span class="token punctuation">.</span>storage<span class="token punctuation">.</span>storageFraction参数），该设定确定了双方各自拥有的空间的范围；</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2</span><span class="token punctuation">)</span>双方的空间都不足时，则存储到硬盘；若己方空间不足而对方空余时，可借用对方的空间<span class="token punctuation">;</span>（存储空间不足是指不足以放下一个完整的Block）</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3</span><span class="token punctuation">)</span>执行内存的空间被对方占用后，可让对方将占用的部分转存到硬盘，然后”归还”借用的空间；</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">4</span><span class="token punctuation">)</span>存储内存的空间被对方占用后，无法让对方”归还”，因为需要考虑 Shuffle过程中的很多因素，实现起来较为复杂。</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">-- 2. 统一内存管理的动态占用机制图如下：</span></pre></td></tr></table></figure><p>![image-20200620015447725](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200620015447.png)</p><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 注意事项</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 如果是storage借了Execution的内存，那么当Execution需使用时，storage占用Execution的内存就要想办法还给Execution，一般可以进行落盘，但是在内存中的数据有一个存储级别，如果仅仅是Memory_Only的话，那么此时占用内存的数据就会丢失。</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span>  如果是Execution借了storage的内存，那么当storage需使用时，Execution并不会把内存还给storage，那么此时storage的数据就会溢写磁盘，如果不能溢写的话，那么就会丢失或淘汰。</pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 面试题：</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 动态占用机制图是什么情况？</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> 为什么cache为丢失数据？</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">3.</span> 阶段的划分</pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token number">4.</span> task的发送</pre></td></tr></table></figure></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2020-08-24 00:48:28" itemprop="dateModified" datetime="2020-08-24T00:48:28+08:00">2020-08-24</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Miyazono 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="Miyazono 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="Miyazono 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Miyazono <i class="ic i-at"><em>@</em></i>冬樱茶</li><li class="link"><strong>本文链接：</strong> <a href="https://github.com/Mayizono/miyazono.github.io/big-data/spark/8.Spark%E5%86%85%E6%A0%B8/">https://github.com/Mayizono/miyazono.github.io/big-data/spark/8.Spark内核/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/big-data/spark/7.SparkStreaming/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gicmnywqgpj20zk0m8dwx.jpg" title="未命名"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>未命名</h3></a></div><div class="item right"><a href="/big-data/spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva2.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclfw2t96j20zk0m8x6p.jpg" title="未命名"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>未命名</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#spark%E5%86%85%E6%A0%B8"><span class="toc-number">1.</span> <span class="toc-text">Spark 内核</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-%E5%86%85%E6%A0%B8%E8%A7%A3%E6%9E%90%E7%9A%84%E5%88%86%E8%A7%A3"><span class="toc-number">1.1.</span> <span class="toc-text">一、内核解析的分解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-sparksubmit"><span class="toc-number">1.2.</span> <span class="toc-text">二、 SparkSubmit</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-spark%E5%90%91yarn%E6%8F%90%E4%BA%A4"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 Spark 向 yarn 提交</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#211-sparksubmit"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">2.1.1 SparkSubmit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#222-yarnyarnclusterapplication"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">2.2.2 yarn.YarnClusterApplication</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#223-yarnapplicationmaster"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">2.2.3 yarn.ApplicationMaster</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#224-coarsegrainedexecutorbackend"><span class="toc-number">1.2.1.4.</span> <span class="toc-text">2.2.4 CoarseGrainedExecutorBackend</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#225-%E6%80%BB%E7%BB%93"><span class="toc-number">1.2.1.5.</span> <span class="toc-text">2.2.5 总结</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-spark%E5%86%85%E9%83%A8%E7%BB%84%E4%BB%B6%E5%8F%8A%E9%80%9A%E4%BF%A1"><span class="toc-number">1.3.</span> <span class="toc-text">三、Spark 内部组件及通信</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 通信原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-%E7%BB%84%E4%BB%B6%E4%B9%8B%E9%97%B4%E9%80%9A%E4%BF%A1"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 组件之间通信</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E4%BD%9C%E4%B8%9A%E7%9A%84%E8%B0%83%E5%BA%A6"><span class="toc-number">1.4.</span> <span class="toc-text">四、作业的调度</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-application"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 Application</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-%E9%80%BB%E8%BE%91%E4%BB%A3%E7%A0%81"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 逻辑代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-job"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 job</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#44-stage"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 stage</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#45-task%E7%9A%84%E5%88%87%E5%88%86"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.5 task 的切分</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E4%BB%BB%E5%8A%A1%E7%9A%84%E6%89%A7%E8%A1%8C"><span class="toc-number">1.5.</span> <span class="toc-text">五、任务的执行</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#51-%E4%BB%BB%E5%8A%A1%E5%8C%85%E5%90%AB%E7%9A%84%E5%86%85%E5%AE%B9"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 任务包含的内容</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#52-%E5%BA%8F%E5%88%97%E5%8C%96"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 序列化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#53-%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%B0%83%E5%BA%A6"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 任务的调度</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#54-%E4%BB%BB%E5%8A%A1%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">1.5.4.</span> <span class="toc-text">5.4 任务的计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#55-shuffle"><span class="toc-number">1.5.5.</span> <span class="toc-text">5.5 shuffle</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD-spark%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">1.6.</span> <span class="toc-text">六 、 Spark 内存管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#61-%E5%A0%86%E5%86%85%E5%86%85%E5%AD%98%E5%92%8C%E5%A0%86%E5%A4%96%E5%86%85%E5%AD%98"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 堆内内存和堆外内存</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#62-%E5%86%85%E5%AD%98%E7%A9%BA%E9%97%B4%E5%88%86%E9%85%8D"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 内存空间分配</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#621-%E6%97%A9%E6%9C%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">1.6.2.1.</span> <span class="toc-text">6.2.1 早期内存管理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#622-%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86"><span class="toc-number">1.6.2.2.</span> <span class="toc-text">6.2.2 统一内存管理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#623-%E5%90%8C%E4%B8%80%E7%AE%A1%E7%90%86%E5%86%85%E5%AD%98%E7%9A%84%E4%BC%98%E7%82%B9"><span class="toc-number">1.6.2.3.</span> <span class="toc-text">6.2.3 同一管理内存的优点</span></a></li></ol></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Miyazono" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Miyazono</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">22</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">4</span> <span class="name">分类</span></a></div></nav><div class="social"><a href="https://github.com/amehime" title="https:&#x2F;&#x2F;github.com&#x2F;amehime" class="item github"><i class="ic i-github"></i></a> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9hbWVoaW1l" title="https:&#x2F;&#x2F;twitter.com&#x2F;amehime"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9ydXJpc216aw==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;rurismzk"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTEyODg2ODIz" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;12886823"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20vYW1laGltZQ==" title="https:&#x2F;&#x2F;weibo.com&#x2F;amehime"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS9hbWVoaW1l" title="https:&#x2F;&#x2F;about.me&#x2F;amehime"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/mikutap/" rel="section"><i class="ic i-star"></i>mikutap</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/big-data/spark/7.SparkStreaming/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/big-data/spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/6.SparkSQL/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/kafka/" title="分类于 Kafka">Kafka</a></div><span><a href="/big-data/kafka/Kafka%E6%80%BB%E7%BB%93/" title="Kafka学习">Kafka学习</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/3.Spark%E7%BC%96%E7%A8%8B2/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/2_Canal/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/4_Kibana/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/flink/" title="分类于 Flink">Flink</a></div><span><a href="/big-data/flink/1_Nginx/" title="负载均衡Nginx的使用">负载均衡Nginx的使用</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/flume/" title="分类于 Flume">Flume</a></div><span><a href="/big-data/flume/Flume%E7%BB%83%E4%B9%A0%E9%A2%98/" title="Flume练习题">Flume练习题</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/7.SparkStreaming/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/2.Spark%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%BC%96%E7%A8%8B/" title="未命名">未命名</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Miyazono @ Yume Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">311k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">4:43</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<a href="https://github.com/amehime/hexo-theme-shoka">Shoka</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"big-data/spark/8.Spark内核/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->