<!-- build time:Tue Sep 07 2021 18:15:22 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/atom.xml"><link rel="alternate" type="application/json" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://github.com/Mayizono/miyazono.github.io/big-data/spark/6.SparkSQL/"><title>| Yume Shoka = 冬樱茶</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline"></h1><div class="meta"><span class="item" title="创建时间：2021-08-31 18:42:35"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2021-08-31T18:42:35+08:00">2021-08-31</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>17k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>16 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Yume Shoka</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giclip4jbpj20zk0m87cv.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1gipet4bz0yj20zk0m8e81.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1gipeybxm1pj20zk0m8niv.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giph4wqtg4j20zk0m8x6p.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1gipesrnqv3j20zk0m8ava.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giciuv0socj20zk0m8qes.jpg"></li></ul></div><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div></header><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://github.com/Mayizono/miyazono.github.io/big-data/spark/6.SparkSQL/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Miyazono"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="冬樱茶"></span><div class="body md" itemprop="articleBody"><h1 id="sparksql"><a class="anchor" href="#sparksql">#</a> SparkSQL</h1><hr><h2 id="一-sparksql概述"><a class="anchor" href="#一-sparksql概述">#</a> 一、 SparkSQL 概述</h2><h3 id="11-sparksql是什么"><a class="anchor" href="#11-sparksql是什么">#</a> 1.1 SparkSQL 是什么？</h3><p>![image-20200612190658269](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612190658.png)</p><p>![image-20200612190701687](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612190701.png)</p><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre>Spark <span class="token keyword">SQL</span>是Spark用于<span class="token string">"结构化数据"</span><span class="token punctuation">(</span>structured <span class="token keyword">data</span><span class="token punctuation">)</span>处理的Spark模块</pre></td></tr></table></figure><h3 id="12-hive-和-sparksql解析"><a class="anchor" href="#12-hive-和-sparksql解析">#</a> 1.2 Hive 和 SparkSQL 解析</h3><ul><li>Hive 和 SparkSQL 之间的关系</li></ul><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> Hive是<span class="token keyword">SQL</span><span class="token operator">-</span><span class="token keyword">on</span><span class="token operator">-</span>Hadoop的工具，但由于底层还是基于MR，所以效率低。</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> 产生了大量提升<span class="token keyword">SQL</span><span class="token operator">-</span><span class="token keyword">on</span><span class="token operator">-</span>Hadoop的工具，表现较为突出的是：</pre></td></tr><tr><td data-num="3"></td><td><pre>Drill</pre></td></tr><tr><td data-num="4"></td><td><pre>Impala</pre></td></tr><tr><td data-num="5"></td><td><pre>Shark</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token number">3.</span> Shark是Spark生态环境组件之一，基于Hive开发，性能较hive提高了<span class="token number">10</span><span class="token operator">-</span><span class="token number">100</span>倍。</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token number">4.</span> 由于Shark性能提升时，有很多Hive的依赖<span class="token punctuation">(</span>如hive的解析器，查询优化器等<span class="token punctuation">)</span>，制约了Shark的发展。</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token number">5.</span> <span class="token number">2014.6</span><span class="token number">.1</span>，Shark项目终止，开始了SparkSQL项目。</pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token number">6.</span> 自此，Hive的底层引擎可以是tez、mr、Spark</pre></td></tr></table></figure><ul><li>SparkSQL</li></ul><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 简化RDD，提高开发效率</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> 提供了<span class="token number">2</span>个编程抽象，类型spark core中的RDD：</pre></td></tr><tr><td data-num="3"></td><td><pre>  a、DataFrame <span class="token comment">--DF</span></pre></td></tr><tr><td data-num="4"></td><td><pre>  b、DataSet   <span class="token comment">--DS</span></pre></td></tr></table></figure><h3 id="13-dataframe是什么"><a class="anchor" href="#13-dataframe是什么">#</a> 1.3 DataFrame 是什么</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--  DataFrame 是什么</span></pre></td></tr><tr><td data-num="2"></td><td><pre>DataFrame 是一种以RDD为基础的分布式数据集，类似传统数据库中的二维表格。</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- DataFrame 与 RDD 的区别</span></pre></td></tr><tr><td data-num="5"></td><td><pre>   <span class="token number">1.</span> DF带有结构<span class="token punctuation">(</span><span class="token keyword">Schema</span><span class="token punctuation">)</span>信息<span class="token punctuation">,</span>即包含了二维表数据集每一列的列名和类型；</pre></td></tr><tr><td data-num="6"></td><td><pre>   <span class="token number">2.</span> Hive类似，DataFrame也支持嵌套数据类型（struct、array和map）</pre></td></tr><tr><td data-num="7"></td><td><pre>   <span class="token number">3.</span> 在性能上，DF的执行性能优于RDD，因为它底层会自动优化执行过程，它是如何做到的呢？利用基于关系代数的等价变换，将高成本的操作替换为低成本操作的过程，如简化shuffle阶段，先过滤再进行IO等等。</pre></td></tr></table></figure><p>![image-20200612191859183](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612191859.png)</p><h3 id="14-dataset是什么"><a class="anchor" href="#14-dataset是什么">#</a> 1.4 DataSet 是什么</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. DataSet 是什么？</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    是分布式数据集合，是DataFrame的扩展，是一个强类型集合。</pre></td></tr></table></figure><h3 id="15-三者之间的关系"><a class="anchor" href="#15-三者之间的关系">#</a> 1.5 三者之间的关系</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. 三者出现的时间顺序</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   Spark1<span class="token punctuation">.</span><span class="token number">0</span> <span class="token operator">=</span><span class="token operator">></span> RDD </pre></td></tr><tr><td data-num="3"></td><td><pre>   Spark1<span class="token punctuation">.</span><span class="token number">3</span> <span class="token operator">=</span><span class="token operator">></span> DataFrame</pre></td></tr><tr><td data-num="4"></td><td><pre>   Spark1<span class="token punctuation">.</span><span class="token number">6</span> <span class="token operator">=</span><span class="token operator">></span> Dataset</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">--2. 三者之间的关系</span></pre></td></tr><tr><td data-num="7"></td><td><pre>   a、DataFrame是在RDD上进行扩展，将数据增加了结构信息</pre></td></tr><tr><td data-num="8"></td><td><pre>   b、DataSet是在DataFrame的基础上进行扩展，增加数据的类型。</pre></td></tr><tr><td data-num="9"></td><td><pre>   c、DataFrame是DataSet的一个特例，即为数据类型<span class="token keyword">ROW</span>的DataSet</pre></td></tr></table></figure><h2 id="二-sparksql核心编程"><a class="anchor" href="#二-sparksql核心编程">#</a> 二、 SparkSQL 核心编程</h2><h3 id="21-sparksql的环境对象"><a class="anchor" href="#21-sparksql的环境对象">#</a> 2.1 SparkSQL 的环境对象</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. 上下文的环境对象</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> SparkCore  <span class="token comment">--> SparkContext, 使用 sc 来代替</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> SparkSQL   <span class="token comment">--> SparkSession，使用 spark 代替，实际上是内部封装了 SparkContext, 底层实现还是 SparkContext</span></pre></td></tr></table></figure><p>![image-20200612193832283](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612193832.png)</p><h3 id="22-dataframe"><a class="anchor" href="#22-dataframe">#</a> 2.2 DataFrame</h3><h4 id="221-创建dataframe"><a class="anchor" href="#221-创建dataframe">#</a> 2.2.1 创建 DataFrame</h4><blockquote><p>一共有 三种方式：</p><ol><li>通过 Spark 的数据源进行创建</li><li>从一个存在的 RDD 进行转换</li><li>还可以从 HiveTable 进行查询返回</li></ol></blockquote><p>暂时先讲第一种，就是从数据源中创建，另外两种后续章节讨论。</p><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 启动 Spark-Local 模式中的 Spark</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token punctuation">[</span>atguigu<span class="token variable">@hadoop105</span> spark<span class="token operator">-</span><span class="token keyword">local</span><span class="token punctuation">]</span>$ bin<span class="token operator">/</span>spark<span class="token operator">-</span>shell </pre></td></tr><tr><td data-num="3"></td><td><pre> </pre></td></tr><tr><td data-num="4"></td><td><pre> <span class="token comment">-- 2. 创建 DataFrame</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  scala<span class="token operator">></span> val df <span class="token operator">=</span> spark<span class="token punctuation">.</span><span class="token keyword">read</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"examples/src/main/resources/people.json"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre> </pre></td></tr><tr><td data-num="7"></td><td><pre>  打印结果：df: org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">.</span>DataFrame <span class="token operator">=</span> <span class="token punctuation">[</span>age: <span class="token keyword">bigint</span><span class="token punctuation">,</span> name: string<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="8"></td><td><pre> </pre></td></tr><tr><td data-num="9"></td><td><pre> <span class="token comment">-- 3. 说明：</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token number">1.</span> 为啥数据类型是<span class="token keyword">bigint</span>，是因为从文件中读取数据，不知道数据的长度，所用使用<span class="token keyword">bigint</span>来表示，如果是从内存创建df，那么Spark可以知道数据的具体类型。</pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token number">2.</span> spark<span class="token punctuation">.</span><span class="token keyword">read</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"path:String"</span><span class="token punctuation">)</span>，从指定路径下读取json格式的文件</pre></td></tr><tr><td data-num="12"></td><td><pre> </pre></td></tr><tr><td data-num="13"></td><td><pre> <span class="token comment">-- 4. 展示 df 的内容： show</span></pre></td></tr></table></figure><p>![image-20200612194906529](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612194906.png)</p><h4 id="222-sql语法"><a class="anchor" href="#222-sql语法">#</a> 2.2.2 SQL 语法</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- SQL 语法说明：</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">SQL</span>语法风格是指我们查询数据的时候使用<span class="token keyword">SQL</span>语句来查询，这种风格的查询必须要有临时视图或者全局视图来辅助</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 1. 创建临时视图和全局视图</span></pre></td></tr><tr><td data-num="5"></td><td><pre>          a、 创建临时视图，</pre></td></tr><tr><td data-num="6"></td><td><pre>              createTempView </pre></td></tr><tr><td data-num="7"></td><td><pre>              createOrReplaceTempView :原视图存在则覆盖，不存在则创建</pre></td></tr><tr><td data-num="8"></td><td><pre>              <span class="token comment">-- 案例</span></pre></td></tr><tr><td data-num="9"></td><td><pre>              df<span class="token punctuation">.</span>createTempView<span class="token punctuation">(</span><span class="token string">"People"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre>          b、 创建全局视图</pre></td></tr><tr><td data-num="12"></td><td><pre>              createGlobalTempView  </pre></td></tr><tr><td data-num="13"></td><td><pre>              createOrReplaceGlobalTempView  :原视图存在则覆盖，不存在则创建</pre></td></tr><tr><td data-num="14"></td><td><pre>              <span class="token comment">-- 案例</span></pre></td></tr><tr><td data-num="15"></td><td><pre>              df<span class="token punctuation">.</span>createGlobalTempView<span class="token punctuation">(</span><span class="token string">"People"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>      </pre></td></tr><tr><td data-num="17"></td><td><pre>         c、 两种视图含义上的区别：</pre></td></tr><tr><td data-num="18"></td><td><pre>             临时视图：表示仅此次的sparkSession可以使用</pre></td></tr><tr><td data-num="19"></td><td><pre>             全局视图：表示多次连接均可使用，可以理解为多次连接Mysql</pre></td></tr><tr><td data-num="20"></td><td><pre>         </pre></td></tr><tr><td data-num="21"></td><td><pre>         d、 两种视图在访问上的区别：</pre></td></tr><tr><td data-num="22"></td><td><pre>             全局视图需要加上：<span class="token string">"global_temp."</span>才能进行访问。</pre></td></tr><tr><td data-num="23"></td><td><pre>         </pre></td></tr><tr><td data-num="24"></td><td><pre>         e、 <span class="token keyword">view</span> 和 <span class="token keyword">table</span>的区别：</pre></td></tr><tr><td data-num="25"></td><td><pre>             <span class="token keyword">view</span>:  是临时结果，视图，由查询结果得到的对象，不能进行增删改，只能查询</pre></td></tr><tr><td data-num="26"></td><td><pre>             <span class="token keyword">table</span>：是长久存在，可以进行增删改查操作。</pre></td></tr><tr><td data-num="27"></td><td><pre>            </pre></td></tr><tr><td data-num="28"></td><td><pre>   <span class="token comment">-- 总结：</span></pre></td></tr><tr><td data-num="29"></td><td><pre>     创建临时或者全部表，也就是视图，临时表是仅在本次连接可用，新的连接sparkSession就不能使用，但是全局表是可以跨连接使用，类似咱们的mysql，多次访问mysql的数据库，数据库中的表单都是可以访问的，同时在创建视图的时候，需要给创建的视图进行命名，如果视图名称已存在，那么会报错可以使用createorReplace，如果表存在，那么直接覆盖，如果不存在，则直接创建。</pre></td></tr><tr><td data-num="30"></td><td><pre> </pre></td></tr><tr><td data-num="31"></td><td><pre> <span class="token comment">-- 2. spark.newSession : 创建新的 SparkSQL 的连接</span></pre></td></tr><tr><td data-num="32"></td><td><pre> <span class="token comment">-- 3. spark.sql ("sql 语句").show</span></pre></td></tr></table></figure><p>![image-20200612200712373](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612200712.png)</p><h4 id="223-dsl"><a class="anchor" href="#223-dsl">#</a> 2.2.3 DSL</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 什么是 DSL</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   一个特定领域的语言，用来管理结构。</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 好处：</span></pre></td></tr><tr><td data-num="5"></td><td><pre>   不用创建临时的绘图。</pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">-- 具体的应用见 API，用到的方法和展示的方式是相同的</span></pre></td></tr></table></figure><h4 id="224-sql语法和dsl语法的区别"><a class="anchor" href="#224-sql语法和dsl语法的区别">#</a> 2.2.4 SQL 语法和 DSL 语法的区别</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. 两个的用途是什么：均是用来查询，SQL 是针对数据结构，DSL 是针对数据类型</span></pre></td></tr><tr><td data-num="2"></td><td><pre> <span class="token comment">--2. 区别是什么</span></pre></td></tr><tr><td data-num="3"></td><td><pre>      a、<span class="token keyword">sql</span>需要建立临时的表，而dsl不需要</pre></td></tr><tr><td data-num="4"></td><td><pre>      b、调用<span class="token keyword">sql</span>的对象不同，使用<span class="token keyword">sql</span>使用的是sparkSession的对象，而dsl是dataframe或者是dataSet</pre></td></tr><tr><td data-num="5"></td><td><pre>      c、语法上的差异：</pre></td></tr><tr><td data-num="6"></td><td><pre>         <span class="token keyword">sql</span>：spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">(</span><span class="token keyword">sql</span>文<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>         DSL: ds<span class="token operator">/</span>df<span class="token punctuation">.</span></pre></td></tr></table></figure><h3 id="23-dataframedatesetrdd三者之间的转换"><a class="anchor" href="#23-dataframedatesetrdd三者之间的转换">#</a> 2.3 DataFrame/DateSet/RDD 三者之间的转换</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. RDD &lt;=> DF</span></pre></td></tr><tr><td data-num="2"></td><td><pre>      a、RDD <span class="token comment">--> DF </span></pre></td></tr><tr><td data-num="3"></td><td><pre>         <span class="token string">"rdd.toDF("</span>列名<span class="token number">1</span><span class="token string">"，"</span>列名<span class="token number">2</span><span class="token string">"，...)"</span></pre></td></tr><tr><td data-num="4"></td><td><pre>      b、DF <span class="token comment">--> RDD</span></pre></td></tr><tr><td data-num="5"></td><td><pre>         <span class="token string">"df.rdd"</span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">-- 2. RDD  &lt;=> DS</span></pre></td></tr><tr><td data-num="8"></td><td><pre>      a、 RDD <span class="token operator">=</span><span class="token operator">></span> DS</pre></td></tr><tr><td data-num="9"></td><td><pre>           将rdd的数据转换为样例类的格式。</pre></td></tr><tr><td data-num="10"></td><td><pre>           <span class="token string">"rdd.toDS"</span>  </pre></td></tr><tr><td data-num="11"></td><td><pre>      b、 DS <span class="token operator">=</span><span class="token operator">></span> RDD</pre></td></tr><tr><td data-num="12"></td><td><pre>           <span class="token string">"ds.rdd"</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment">-- 3. DF &lt;=> DS</span></pre></td></tr><tr><td data-num="15"></td><td><pre>     a、DF <span class="token operator">=</span><span class="token operator">></span> DS </pre></td></tr><tr><td data-num="16"></td><td><pre>       <span class="token string">"df.as[样例类]"</span>，该样例类必须存在，而且df中的数据个样例类对应</pre></td></tr><tr><td data-num="17"></td><td><pre>     b、 DS <span class="token operator">=</span><span class="token operator">></span> DS</pre></td></tr><tr><td data-num="18"></td><td><pre>       <span class="token string">"ds.toDF"</span></pre></td></tr><tr><td data-num="19"></td><td><pre>       </pre></td></tr><tr><td data-num="20"></td><td><pre><span class="token comment">-- 说明：</span></pre></td></tr><tr><td data-num="21"></td><td><pre>        a、通过DF转换得来的RDD的数据类型是<span class="token keyword">ROW</span>。</pre></td></tr><tr><td data-num="22"></td><td><pre>        b、通过DS转换得来的RDD的数据类型和DS的数据类型一致</pre></td></tr><tr><td data-num="23"></td><td><pre>        c、RDD:只关心数据本身</pre></td></tr><tr><td data-num="24"></td><td><pre>           DataFrame:关心数据的结构</pre></td></tr><tr><td data-num="25"></td><td><pre>           DataSet:关心数据类型</pre></td></tr></table></figure><p>![image-20200612193232509](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612193232.png)</p><h3 id="24-idea编程"><a class="anchor" href="#24-idea编程">#</a> 2.4 IDEA 编程</h3><h4 id="241-添加依赖"><a class="anchor" href="#241-添加依赖">#</a> 2.4.1 添加依赖</h4><figure class="highlight xml"><figcaption data-lang="XML"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-sql_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></pre></td></tr></table></figure><h4 id="242-构建sparksession对象"><a class="anchor" href="#242-构建sparksession对象">#</a> 2.4.2 构建 sparkSession 对象</h4><ol><li>重要：连接 SparkSQL</li></ol><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 1. 创建环境</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"sparksql"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token comment">// 2. 创建 SparkSession 对象</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ol start="2"><li>添加隐式转换，每次构建完对象以后都需要增加这个 隐式转换的代码</li></ol><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 3. 增加隐式转换</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">import</span> <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>"<span class="token number">1.</span> 这里的spark不是Scala中的包名，而是创建的sparkSession对象的变量名称</pre></td></tr><tr><td data-num="5"></td><td><pre> <span class="token number">2.</span> spark对象不能使用<span class="token keyword">var</span>声明，因为Scala只支持<span class="token keyword">val</span>修饰的对象的引入"</pre></td></tr></table></figure><ol start="3"><li>说明</li></ol><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 为啥要导入隐式转换</span></pre></td></tr><tr><td data-num="2"></td><td><pre>sparkSQL是在spark的基础上进行延伸，属于功能的扩展，使用隐式转换，体现了OCP开发原则。</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 构建对象为什么不直接 new 呢？</span></pre></td></tr><tr><td data-num="5"></td><td><pre>因为sparkSession是对sparkContext的包装，创建这个对象时，需要很多步骤，将这些过程进行封装，让开发更容易，使用一个构建器来创建对象。</pre></td></tr></table></figure><h4 id="243-代码实现"><a class="anchor" href="#243-代码实现">#</a> 2.4.3 代码实现</h4><ol><li>创建 df</li></ol><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"input/people.json"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ol start="2"><li>查看 DataFrame 的 Schema 信息</li></ol><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre>frame<span class="token punctuation">.</span>printSchema<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>![image-20200612213154690](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612213154.png)</p><ol start="3"><li>只查看 &quot;username&quot; 列数据</li></ol><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre>frame<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">"name"</span><span class="token punctuation">,</span><span class="token string">"age"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>![image-20200612213954376](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612213954.png)</p><ol start="4"><li>查看 &quot;username&quot; 列数据以及 &quot;age+1&quot; 数据</li></ol><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre>说明:</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">1.</span> 涉及到运算的时候<span class="token punctuation">,</span> 每列都必须<span class="token string">"使用$, 或者采用引号表达式：单引号+字段名"</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">2.</span> <span class="token keyword">as</span> 取别名</pre></td></tr></table></figure><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre>frame<span class="token punctuation">.</span>select<span class="token punctuation">(</span><span class="token string">'age,'</span>age <span class="token operator">+</span> <span class="token number">1</span> as <span class="token string">"newAge"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>![image-20200612214218042](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612214218.png)</p><ol start="5"><li>查看 &quot;age&quot; 大于 &quot;20&quot; 的数据</li></ol><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre>frame<span class="token punctuation">.</span>filter<span class="token punctuation">(</span><span class="token symbol">'age</span> <span class="token operator">></span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><p>![image-20200612214550513](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200612214550.png)</p><h3 id="25-udf和udaf"><a class="anchor" href="#25-udf和udaf">#</a> 2.5 UDF 和 UDAF</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 什么是 UDF，什么是 UDAF?</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    a、UDF : UserDefinedFunction<span class="token punctuation">,</span>用户自定义函数，可以类比为map方法，给你一个数据，然后对每条数据进行处理，如取出日期中年信息</pre></td></tr><tr><td data-num="3"></td><td><pre>    b、UDAF : UserDefinedAggregateorFunction，用户自定义<span class="token string">"聚合"</span>函数，可以类比<span class="token keyword">sql</span>中的count，sum、avg、max、min等方法</pre></td></tr></table></figure><h4 id="251-udf"><a class="anchor" href="#251-udf">#</a> 2.5.1 UDF</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 创建dataFrame</pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">2.</span> 自定义和注册udf</pre></td></tr><tr><td data-num="3"></td><td><pre>         方法：spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span>形参<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>         形参：有两个形参</pre></td></tr><tr><td data-num="5"></td><td><pre>              形参<span class="token number">1</span>：自定义函数的名字</pre></td></tr><tr><td data-num="6"></td><td><pre>              形参<span class="token number">2</span>：自定义函数的逻辑，是一个函数</pre></td></tr><tr><td data-num="7"></td><td><pre>       </pre></td></tr><tr><td data-num="8"></td><td><pre>     <span class="token number">3.</span> 使用自定义函数：</pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token number">3.1</span> 使用自定义的udf函数用于<span class="token keyword">sql</span>语法</pre></td></tr><tr><td data-num="10"></td><td><pre>            a、创建临时或全局视图</pre></td></tr><tr><td data-num="11"></td><td><pre>            b、使用spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">(</span><span class="token keyword">sql</span>文<span class="token punctuation">)</span>的方法调用自定的UDF方法</pre></td></tr><tr><td data-num="12"></td><td><pre>            </pre></td></tr><tr><td data-num="13"></td><td><pre>        <span class="token number">3.2</span> 使用于DSL语法</pre></td></tr><tr><td data-num="14"></td><td><pre>            a、获取注册udf的返回值</pre></td></tr><tr><td data-num="15"></td><td><pre>            b、使用df<span class="token punctuation">.</span><span class="token keyword">select</span><span class="token punctuation">(</span>调用函数<span class="token punctuation">(</span>列名<span class="token punctuation">)</span><span class="token punctuation">)</span>，调用自定的udf函数</pre></td></tr></table></figure><ul><li>代码实现</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 1. 创建 dataFrame</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"input/people.json"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token comment">/*</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    2. 自定义和注册 udf，并获取返回值</pre></td></tr><tr><td data-num="6"></td><td><pre>     方法：spark.udf.register (形参)</pre></td></tr><tr><td data-num="7"></td><td><pre>     形参：有两个形参</pre></td></tr><tr><td data-num="8"></td><td><pre>          形参 1：自定义函数的名字</pre></td></tr><tr><td data-num="9"></td><td><pre>          形参 2：自定义函数的逻辑，是一个函数</pre></td></tr><tr><td data-num="10"></td><td><pre>      */</pre></td></tr><tr><td data-num="11"></td><td><pre>     <span class="token keyword">val</span> udf<span class="token operator">:</span> UserDefinedFunction <span class="token operator">=</span> spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">"newName"</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>x <span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">)</span> <span class="token keyword">=></span> <span class="token string">"Name:"</span>  <span class="token operator">+</span> x <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token comment">// 3.1、使用 sql 语法使用自定义 udf 函数</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment">//  a、创建临时或全局视图</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    frame<span class="token punctuation">.</span>createOrReplaceTempView<span class="token punctuation">(</span><span class="token string">"people"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token comment">// 使用 spark.sql (sql 文) 的方法调用自定的 UDF 方法</span></pre></td></tr><tr><td data-num="18"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select newName(name) from people"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token comment">// 3.2、使用于 DSL 语法使用自定义 udf 函数</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    frame<span class="token punctuation">.</span>select<span class="token punctuation">(</span>udf<span class="token punctuation">(</span><span class="token symbol">'name</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="252-udaf"><a class="anchor" href="#252-udaf">#</a> 2.5.2 UDAF</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre>自定义的UDAF分为两种：弱类型自定义聚合函数、强类型自定义函数</pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token comment">--1. 关于强类型自定义函数的说明：</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    将数据转换为dataset，此时二维表中的一条数据封装为一个对象因为聚合函数是强类型，那么<span class="token keyword">sql</span>中没有类型的概念，所以<span class="token keyword">SQL</span>语法无法使用， 可以采用DSL语法方法进行访问将聚合函数转换为查询的列让DataSet访问</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment">--2、强类型自定义函数和弱类型自定义的区别：</span></pre></td></tr><tr><td data-num="7"></td><td><pre>       a、<span class="token string">"使用范围区别"</span>：</pre></td></tr><tr><td data-num="8"></td><td><pre>          弱类型自定义函数支持<span class="token keyword">SQL</span>语法和DSL语法，</pre></td></tr><tr><td data-num="9"></td><td><pre>          而强类型语言仅支持DSL语法，因为<span class="token keyword">SQL</span>没有类型的概念</pre></td></tr><tr><td data-num="10"></td><td><pre>       b、<span class="token string">"声明自定义方法方式的差别"</span>：</pre></td></tr><tr><td data-num="11"></td><td><pre>          <span class="token string">"弱类型语言"</span>：</pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>             <span class="token number">1</span>）自定义函数，继承extends UserDefinedAggregatorFunction</pre></td></tr><tr><td data-num="14"></td><td><pre>             <span class="token number">2</span><span class="token punctuation">)</span> 重写<span class="token number">8</span>个方法：</pre></td></tr><tr><td data-num="15"></td><td><pre>                方法<span class="token number">1</span>：指明输入值的数据类型，不能是map类型，只能是anyval中的类型，特别注意数据的格式</pre></td></tr><tr><td data-num="16"></td><td><pre>                override def inputSchema: StructType <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="17"></td><td><pre>                方法<span class="token number">2</span>：指明缓冲区的数据类型</pre></td></tr><tr><td data-num="18"></td><td><pre>                override def bufferSchema: StructType <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="19"></td><td><pre>                方法<span class="token number">3</span>：指明输出值的数据类型</pre></td></tr><tr><td data-num="20"></td><td><pre>                override def dataType: DataType <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="21"></td><td><pre>                方法<span class="token number">4</span>：数据的稳定性，设定<span class="token boolean">true</span></pre></td></tr><tr><td data-num="22"></td><td><pre>                override def <span class="token keyword">deterministic</span>: <span class="token keyword">Boolean</span> <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="23"></td><td><pre>                方法<span class="token number">5</span>：初始化缓冲区的值，对缓冲区</pre></td></tr><tr><td data-num="24"></td><td><pre>                override def initialize<span class="token punctuation">(</span>buffer: MutableAggregationBuffer<span class="token punctuation">)</span>: Unit <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="25"></td><td><pre>                方法<span class="token number">6</span>：更新缓冲区的数据，每来一条数据，将数据更新到缓冲区内</pre></td></tr><tr><td data-num="26"></td><td><pre>                override def <span class="token keyword">update</span><span class="token punctuation">(</span>buffer: MutableAggregationBuffer<span class="token punctuation">,</span> input: <span class="token keyword">Row</span><span class="token punctuation">)</span>: Unit <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="27"></td><td><pre>                方法<span class="token number">7</span>：合并缓冲区中的数据，两两合并</pre></td></tr><tr><td data-num="28"></td><td><pre>                override def <span class="token keyword">merge</span><span class="token punctuation">(</span>buffer1: MutableAggregationBuffer<span class="token punctuation">,</span> buffer2: <span class="token keyword">Row</span><span class="token punctuation">)</span>: Unit <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="29"></td><td><pre>                方法<span class="token number">8</span>： 计算最后的结果</pre></td></tr><tr><td data-num="30"></td><td><pre>                override def evaluate<span class="token punctuation">(</span>buffer: <span class="token keyword">Row</span><span class="token punctuation">)</span>: <span class="token keyword">Any</span> <span class="token operator">=</span> ???</pre></td></tr><tr><td data-num="31"></td><td><pre></pre></td></tr><tr><td data-num="32"></td><td><pre>          <span class="token string">"强类型语言"</span>：</pre></td></tr><tr><td data-num="33"></td><td><pre>                <span class="token number">1</span>）自定义函数，继承extends Aggregator</pre></td></tr><tr><td data-num="34"></td><td><pre>                <span class="token number">2</span><span class="token punctuation">)</span> 指明父类中的三个泛型</pre></td></tr><tr><td data-num="35"></td><td><pre>                   <span class="token punctuation">[</span><span class="token operator">-</span><span class="token operator">IN</span><span class="token punctuation">,</span> BUF<span class="token punctuation">,</span> <span class="token keyword">OUT</span><span class="token punctuation">]</span></pre></td></tr><tr><td data-num="36"></td><td><pre>                    <span class="token operator">-</span><span class="token operator">IN</span>: 指输入的数据类型，和java中 ? super <span class="token operator">IN</span>相同，指传入的参数类型为<span class="token operator">IN</span>类型或是<span class="token operator">IN</span>的父类类型</pre></td></tr><tr><td data-num="37"></td><td><pre>                    BUF：指缓冲区的数据类型</pre></td></tr><tr><td data-num="38"></td><td><pre>                    <span class="token keyword">OUT</span>：指输出的数据类型</pre></td></tr><tr><td data-num="39"></td><td><pre></pre></td></tr><tr><td data-num="40"></td><td><pre>                    此时<span class="token operator">-</span><span class="token operator">IN</span>：是指原表的一条数据，因为已经是被封装成了一个对象，所以是People</pre></td></tr><tr><td data-num="41"></td><td><pre>                    BUF：<span class="token punctuation">(</span>对象的年龄，次数<span class="token punctuation">)</span>，<span class="token punctuation">(</span><span class="token keyword">Int</span><span class="token punctuation">,</span><span class="token keyword">Int</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>                    <span class="token keyword">OUT</span>：<span class="token punctuation">(</span>平均年龄<span class="token punctuation">)</span>，<span class="token punctuation">(</span><span class="token keyword">Int</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>                 <span class="token number">3</span><span class="token punctuation">)</span> 重写<span class="token number">6</span>个方法</pre></td></tr><tr><td data-num="44"></td><td><pre>                    方法<span class="token number">1</span>：初始化缓冲区的值</pre></td></tr><tr><td data-num="45"></td><td><pre>                    override def zero: avgAGE</pre></td></tr><tr><td data-num="46"></td><td><pre>                    方法<span class="token number">2</span>：将数据添加到缓冲区</pre></td></tr><tr><td data-num="47"></td><td><pre>                    override def reduce<span class="token punctuation">(</span>b: avgAGE<span class="token punctuation">,</span> a: People<span class="token punctuation">)</span>: avgAGE</pre></td></tr><tr><td data-num="48"></td><td><pre>                    方法<span class="token number">3</span>：合并缓冲区，两两进行合并</pre></td></tr><tr><td data-num="49"></td><td><pre>                    override def <span class="token keyword">merge</span><span class="token punctuation">(</span>b1: avgAGE<span class="token punctuation">,</span> b2: avgAGE<span class="token punctuation">)</span>: avgAGE</pre></td></tr><tr><td data-num="50"></td><td><pre>                    方法<span class="token number">4</span>：计算最后的结果</pre></td></tr><tr><td data-num="51"></td><td><pre>                    override def finish<span class="token punctuation">(</span>reduction: avgAGE<span class="token punctuation">)</span>: Long</pre></td></tr><tr><td data-num="52"></td><td><pre>                    方法<span class="token number">5</span>：固定写法，输入的编码器</pre></td></tr><tr><td data-num="53"></td><td><pre>                    override def bufferEncoder: Encoder<span class="token punctuation">[</span>avgAGE<span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>product</pre></td></tr><tr><td data-num="54"></td><td><pre>                    方法<span class="token number">6</span>：固定的写法，输入的解码器</pre></td></tr><tr><td data-num="55"></td><td><pre>                    override def outputEncoder: Encoder<span class="token punctuation">[</span>Long<span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>scalaLong</pre></td></tr><tr><td data-num="56"></td><td><pre></pre></td></tr><tr><td data-num="57"></td><td><pre></pre></td></tr><tr><td data-num="58"></td><td><pre>       c、 <span class="token string">"使用上的区别"</span></pre></td></tr><tr><td data-num="59"></td><td><pre>             <span class="token string">"弱语言"</span>：</pre></td></tr><tr><td data-num="60"></td><td><pre>               使用在<span class="token keyword">sql</span>语法上：</pre></td></tr><tr><td data-num="61"></td><td><pre>               a、创建临时视图或者全局视图</pre></td></tr><tr><td data-num="62"></td><td><pre>               b、new 自定义方法</pre></td></tr><tr><td data-num="63"></td><td><pre>                  val uadf <span class="token operator">=</span>  new MyUADF</pre></td></tr><tr><td data-num="64"></td><td><pre>               c、注册自定义方法</pre></td></tr><tr><td data-num="65"></td><td><pre>                   spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span>函数名，uadf<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="66"></td><td><pre>               d、使用自定义方法</pre></td></tr><tr><td data-num="67"></td><td><pre>                   spark<span class="token punctuation">.</span><span class="token keyword">sql</span><span class="token punctuation">(</span><span class="token string">"select 函数名(输入列) from  全局表"</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="68"></td><td><pre></pre></td></tr><tr><td data-num="69"></td><td><pre>               使用在DSL上：</pre></td></tr><tr><td data-num="70"></td><td><pre>               a、new 自定义方法</pre></td></tr><tr><td data-num="71"></td><td><pre>                  val uadf <span class="token operator">=</span>  new MyUADF</pre></td></tr><tr><td data-num="72"></td><td><pre>               b、注册自定义方法，并获取表达式的返回值</pre></td></tr><tr><td data-num="73"></td><td><pre>                  val UADF: UserDefinedAggregateFunction <span class="token operator">=</span> spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span>函数名，uadf<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="74"></td><td><pre>               c、使用自定义方法</pre></td></tr><tr><td data-num="75"></td><td><pre>                  df<span class="token punctuation">.</span><span class="token keyword">select</span><span class="token punctuation">(</span>UADF<span class="token punctuation">(</span>输入列<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="76"></td><td><pre></pre></td></tr><tr><td data-num="77"></td><td><pre>             <span class="token string">"强类型"</span>：只用在DSL的语法中</pre></td></tr><tr><td data-num="78"></td><td><pre>                    <span class="token comment">// 1. 创建 df</span></pre></td></tr><tr><td data-num="79"></td><td><pre>                    val frame: DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span><span class="token keyword">read</span><span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"input/people.json"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="80"></td><td><pre>                    <span class="token comment">// 2. 将 df 转换成 ds</span></pre></td></tr><tr><td data-num="81"></td><td><pre>                    val ds: Dataset<span class="token punctuation">[</span>People<span class="token punctuation">]</span> <span class="token operator">=</span> frame<span class="token punctuation">.</span><span class="token keyword">as</span><span class="token punctuation">[</span>People<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="82"></td><td><pre>                    <span class="token comment">// 3. 创建自定义的 UADF 对象</span></pre></td></tr><tr><td data-num="83"></td><td><pre>                    val udaf <span class="token operator">=</span> new MyUADF</pre></td></tr><tr><td data-num="84"></td><td><pre>                    <span class="token comment">// 4. 将对象转化为一个列</span></pre></td></tr><tr><td data-num="85"></td><td><pre>                    val <span class="token keyword">column</span>: TypedColumn<span class="token punctuation">[</span>People<span class="token punctuation">,</span> Long<span class="token punctuation">]</span> <span class="token operator">=</span> udaf<span class="token punctuation">.</span>toColumn</pre></td></tr><tr><td data-num="86"></td><td><pre>                    <span class="token comment">// 5. 调用自定义函数</span></pre></td></tr><tr><td data-num="87"></td><td><pre>                    ds<span class="token punctuation">.</span><span class="token keyword">select</span><span class="token punctuation">(</span><span class="token keyword">column</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token keyword">show</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="88"></td><td><pre></pre></td></tr><tr><td data-num="89"></td><td><pre></pre></td></tr><tr><td data-num="90"></td><td><pre>     <span class="token comment">--3、如何选择强类型和弱类型自定义方法</span></pre></td></tr><tr><td data-num="91"></td><td><pre>        当自定义的方法中，考虑数据作为一个对象进行传输时，需要考虑使用强类型自定义函数</pre></td></tr></table></figure><ul><li>弱类型自定聚合函数</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">object</span> SparkSQL2_udaf <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"udaf"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">import</span>  <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token comment">// 创建 dataframe</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span>User<span class="token punctuation">]</span> <span class="token operator">=</span> spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span> </pre></td></tr><tr><td data-num="10"></td><td><pre>        List<span class="token punctuation">(</span>User<span class="token punctuation">(</span><span class="token string">"scala"</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span> User<span class="token punctuation">(</span><span class="token string">"spark"</span><span class="token punctuation">,</span> <span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span> User<span class="token punctuation">(</span><span class="token string">"context"</span><span class="token punctuation">,</span> <span class="token number">30</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token comment">//a、注册自定义的 uadf</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token keyword">val</span> udaf <span class="token operator">=</span> <span class="token keyword">new</span> MyUDAF</pre></td></tr><tr><td data-num="15"></td><td><pre>    <span class="token comment">//b、注册自定义函数，并获取返回值。</span></pre></td></tr><tr><td data-num="16"></td><td><pre>     <span class="token keyword">val</span> UADF<span class="token operator">:</span> UserDefinedAggregateFunction <span class="token operator">=</span> spark<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>register<span class="token punctuation">(</span><span class="token string">"myUADF"</span><span class="token punctuation">,</span>udaf<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment">// 方式 1：使用与 mysql 语法</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select myUADF(age) from User"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token comment">// 方式 2： 使用与 DSL 语法</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    frame<span class="token punctuation">.</span>select<span class="token punctuation">(</span>UADF<span class="token punctuation">(</span><span class="token symbol">'age</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre></pre></td></tr><tr><td data-num="25"></td><td><pre>  <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre> <span class="token comment">// 1. 需求：求年龄的平均值</span></pre></td></tr><tr><td data-num="28"></td><td><pre>  <span class="token keyword">class</span> MyUDAF <span class="token keyword">extends</span> UserDefinedAggregateFunction<span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token comment">// 方法 1：输入数据的类型，将年龄一个一个给传进来</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> inputSchema<span class="token operator">:</span> StructType <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="31"></td><td><pre>      StructType<span class="token punctuation">(</span>Array<span class="token punctuation">(</span>StructField<span class="token punctuation">(</span><span class="token string">"age"</span><span class="token punctuation">,</span>IntegerType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token comment">// 方法 2：缓冲区的数据类型，数据的类型，需要记录年龄的总和，次数，可以存放到一个 map 集合中</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token comment">// 关于数据的格式有：LongType</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> bufferSchema<span class="token operator">:</span> StructType <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="36"></td><td><pre>      StructType<span class="token punctuation">(</span>Array<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        StructField<span class="token punctuation">(</span><span class="token string">"totalAge"</span><span class="token punctuation">,</span>IntegerType<span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        StructField<span class="token punctuation">(</span><span class="token string">"count"</span><span class="token punctuation">,</span>IntegerType<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token comment">// 方法 3：结果数据的数据类型，返回值的数据类型</span></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> dataType<span class="token operator">:</span> DataType <span class="token operator">=</span> IntegerType</pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token comment">// 方法 4：数据是否安全</span></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> deterministic<span class="token operator">:</span> <span class="token builtin">Boolean</span> <span class="token operator">=</span> <span class="token boolean">true</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    <span class="token comment">// 方法 5：缓冲区初始化，就是给缓冲区的每个值设定一个初始值</span></pre></td></tr><tr><td data-num="45"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> initialize<span class="token punctuation">(</span>buffer<span class="token operator">:</span> MutableAggregationBuffer<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="46"></td><td><pre>      buffer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">0</span></pre></td></tr><tr><td data-num="47"></td><td><pre>      buffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">=</span><span class="token number">0</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    <span class="token comment">// 方法 6：更新缓冲区</span></pre></td></tr><tr><td data-num="50"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> update<span class="token punctuation">(</span>buffer<span class="token operator">:</span> MutableAggregationBuffer<span class="token punctuation">,</span> input<span class="token operator">:</span> Row<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="51"></td><td><pre></pre></td></tr><tr><td data-num="52"></td><td><pre>      buffer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span>  input<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre>      buffer<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="54"></td><td><pre></pre></td></tr><tr><td data-num="55"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="56"></td><td><pre>    <span class="token comment">// 方法 7：因为是多 executor 执行，合并所有分区的数据</span></pre></td></tr><tr><td data-num="57"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>buffer1<span class="token operator">:</span> MutableAggregationBuffer<span class="token punctuation">,</span> buffer2<span class="token operator">:</span> Row<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="58"></td><td><pre>      buffer1<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer1<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span>  buffer2<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="59"></td><td><pre>      buffer1<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer1<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">+</span> buffer2<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="60"></td><td><pre></pre></td></tr><tr><td data-num="61"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="62"></td><td><pre>    <span class="token comment">// 方法 8：计算最后的结果</span></pre></td></tr><tr><td data-num="63"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> evaluate<span class="token punctuation">(</span>buffer<span class="token operator">:</span> Row<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Any</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="64"></td><td><pre>      buffer<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> buffer<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="65"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="66"></td><td><pre>  <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="67"></td><td><pre>  <span class="token keyword">case</span> <span class="token keyword">class</span> User <span class="token punctuation">(</span>name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span>age <span class="token operator">:</span><span class="token builtin">Int</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="68"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><ul><li>解析：</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre>buffer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">=</span> buffer<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">+</span>  input<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   buffer<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token operator">:</span> 理解为设置索引位置为<span class="token number">0</span>的值</pre></td></tr><tr><td data-num="3"></td><td><pre>   buffer<span class="token punctuation">.</span>getInt<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span> ：获取索引为<span class="token number">0</span>位置的数据</pre></td></tr></table></figure><ul><li>强类型自定义的函数</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">object</span> SparkSQL5_UADF <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token keyword">def</span> main<span class="token punctuation">(</span>args<span class="token operator">:</span> Array<span class="token punctuation">[</span><span class="token builtin">String</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Unit</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"UADF"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">import</span>  <span class="token namespace">spark<span class="token punctuation">.</span>implicits<span class="token punctuation">.</span></span>_</pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token comment">// 1. 创建 df</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>json<span class="token punctuation">(</span><span class="token string">"input/people.json"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token comment">// 2. 将 df 转换成 ds</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">val</span> ds<span class="token operator">:</span> Dataset<span class="token punctuation">[</span>People<span class="token punctuation">]</span> <span class="token operator">=</span> frame<span class="token punctuation">.</span>as<span class="token punctuation">[</span>People<span class="token punctuation">]</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment">// 3. 创建自定义的 UADF 对象</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">val</span> udaf <span class="token operator">=</span> <span class="token keyword">new</span> MyUADF</pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token comment">// 4. 将对象转化为一个列</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    <span class="token keyword">val</span> column<span class="token operator">:</span> TypedColumn<span class="token punctuation">[</span>People<span class="token punctuation">,</span> <span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> udaf<span class="token punctuation">.</span>toColumn</pre></td></tr><tr><td data-num="14"></td><td><pre>   <span class="token comment">// 5. 调用自定义函数</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    ds<span class="token punctuation">.</span>select<span class="token punctuation">(</span>column<span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>  <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>  <span class="token comment">/*</span></pre></td></tr><tr><td data-num="19"></td><td><pre>  需求：统计平均年龄</pre></td></tr><tr><td data-num="20"></td><td><pre>  1. 自定义类，继承与 extends Aggregator</pre></td></tr><tr><td data-num="21"></td><td><pre>  2. 指定 Aggregator 的泛型，分别是：</pre></td></tr><tr><td data-num="22"></td><td><pre>    [-IN, BUF, OUT]</pre></td></tr><tr><td data-num="23"></td><td><pre>    -IN: 指输入的数据类型，和 java 中？super IN 相同，指传入的参数类型为 IN 类型或是 IN 的父类类型</pre></td></tr><tr><td data-num="24"></td><td><pre>    BUF：指缓冲区的数据类型</pre></td></tr><tr><td data-num="25"></td><td><pre>    OUT：指输出的数据类型</pre></td></tr><tr><td data-num="26"></td><td><pre></pre></td></tr><tr><td data-num="27"></td><td><pre>    此时 - IN：是指原表的一条数据，因为已经是被封装成了一个对象，所以是 People</pre></td></tr><tr><td data-num="28"></td><td><pre>    BUF：(对象的年龄，次数)，(Int,Int)</pre></td></tr><tr><td data-num="29"></td><td><pre>    OUT：(平均年龄)，(Int)</pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>   */</pre></td></tr><tr><td data-num="32"></td><td><pre>  <span class="token keyword">case</span> <span class="token keyword">class</span> People<span class="token punctuation">(</span><span class="token keyword">var</span> name<span class="token operator">:</span><span class="token builtin">String</span><span class="token punctuation">,</span> <span class="token keyword">var</span> age <span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>  <span class="token keyword">case</span> <span class="token keyword">class</span> avgAGE <span class="token punctuation">(</span><span class="token keyword">var</span> sumAge<span class="token operator">:</span> <span class="token builtin">Long</span><span class="token punctuation">,</span><span class="token keyword">var</span> count<span class="token operator">:</span><span class="token builtin">Long</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>  <span class="token keyword">class</span> MyUADF <span class="token keyword">extends</span>  Aggregator<span class="token punctuation">[</span>People<span class="token punctuation">,</span>avgAGE<span class="token punctuation">,</span><span class="token builtin">Long</span><span class="token punctuation">]</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="37"></td><td><pre>      <span class="token comment">//  方法 1：初始化缓冲区的值</span></pre></td></tr><tr><td data-num="38"></td><td><pre>      <span class="token keyword">override</span> <span class="token keyword">def</span> zero<span class="token operator">:</span> avgAGE <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="39"></td><td><pre>      avgAGE<span class="token punctuation">(</span><span class="token number">0L</span><span class="token punctuation">,</span><span class="token number">0L</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="41"></td><td><pre>   <span class="token comment">// 方法 2：将数据添加到缓冲区</span></pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> reduce<span class="token punctuation">(</span>b<span class="token operator">:</span> avgAGE<span class="token punctuation">,</span> a<span class="token operator">:</span> People<span class="token punctuation">)</span><span class="token operator">:</span> avgAGE <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="43"></td><td><pre>      b<span class="token punctuation">.</span>sumAge <span class="token operator">+=</span> a<span class="token punctuation">.</span>age</pre></td></tr><tr><td data-num="44"></td><td><pre>      b<span class="token punctuation">.</span>count <span class="token operator">+=</span>  <span class="token number">1</span></pre></td></tr><tr><td data-num="45"></td><td><pre>      b</pre></td></tr><tr><td data-num="46"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token comment">//  方法 3：合并缓冲区，两两进行合并</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> merge<span class="token punctuation">(</span>b1<span class="token operator">:</span> avgAGE<span class="token punctuation">,</span> b2<span class="token operator">:</span> avgAGE<span class="token punctuation">)</span><span class="token operator">:</span> avgAGE <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="49"></td><td><pre>      b1<span class="token punctuation">.</span>count <span class="token operator">=</span> b1<span class="token punctuation">.</span>count <span class="token operator">+</span> b2<span class="token punctuation">.</span>count</pre></td></tr><tr><td data-num="50"></td><td><pre>      b1<span class="token punctuation">.</span>sumAge <span class="token operator">=</span>b1<span class="token punctuation">.</span>sumAge <span class="token operator">+</span> b2<span class="token punctuation">.</span>sumAge</pre></td></tr><tr><td data-num="51"></td><td><pre>      b1</pre></td></tr><tr><td data-num="52"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="53"></td><td><pre>    <span class="token comment">//  方法 4：计算最后的结果</span></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> finish<span class="token punctuation">(</span>reduction<span class="token operator">:</span> avgAGE<span class="token punctuation">)</span><span class="token operator">:</span> <span class="token builtin">Long</span> <span class="token operator">=</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="55"></td><td><pre>      reduction<span class="token punctuation">.</span>sumAge <span class="token operator">/</span> reduction<span class="token punctuation">.</span>count</pre></td></tr><tr><td data-num="56"></td><td><pre></pre></td></tr><tr><td data-num="57"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="58"></td><td><pre>   <span class="token comment">//  方法 5：固定写法，输入的编码器</span></pre></td></tr><tr><td data-num="59"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> bufferEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span>avgAGE<span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>product</pre></td></tr><tr><td data-num="60"></td><td><pre>  <span class="token comment">//  方法 6：固定的写法，输入的解码器</span></pre></td></tr><tr><td data-num="61"></td><td><pre>    <span class="token keyword">override</span> <span class="token keyword">def</span> outputEncoder<span class="token operator">:</span> Encoder<span class="token punctuation">[</span><span class="token builtin">Long</span><span class="token punctuation">]</span> <span class="token operator">=</span> Encoders<span class="token punctuation">.</span>scalaLong</pre></td></tr><tr><td data-num="62"></td><td><pre>  <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="63"></td><td><pre></pre></td></tr><tr><td data-num="64"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><h3 id="26-数据的加载和保存"><a class="anchor" href="#26-数据的加载和保存">#</a> 2.6 数据的加载和保存</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre>数据加载和保存的方式有很多种方式，根据不同的需求，主要有以下几种：</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token comment">-- 方式 1：通用的数据加载和保存方式</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">-- 方式 2：parquet</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 方式 3：JSON</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">-- 方式 4：CSV</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">-- 方式 5：Mysql</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">-- 方式 6：Hive</span></pre></td></tr></table></figure><h4 id="261-通用的数据加载和保存方式"><a class="anchor" href="#261-通用的数据加载和保存方式">#</a> 2.6.1 通用的数据加载和保存方式</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 什么是通用的方式？</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  指使用相同的API，根据不同的参数，读取和保存不同格式的数据。</pre></td></tr><tr><td data-num="3"></td><td><pre>  </pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token comment">-- 说明：</span></pre></td></tr><tr><td data-num="5"></td><td><pre>   SparkSQL默认读取和保存的文件格式是parquet。</pre></td></tr></table></figure><h5 id="2611-读取数据"><a class="anchor" href="#2611-读取数据">#</a> 2.6.1.1 读取数据</h5><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">--1. 通用的数据加载方式 [默认为 parquet 格式]</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    方式：spark<span class="token punctuation">.</span><span class="token keyword">read</span><span class="token punctuation">.</span><span class="token keyword">load</span><span class="token punctuation">(</span>pat:String<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">--2. 读取不同格式的数据，可以对不同的数据格式进行设定</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    方式：spark<span class="token punctuation">.</span><span class="token keyword">read</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"数据格式"</span>:string<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token keyword">load</span><span class="token punctuation">(</span>path:String<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>    说明：</pre></td></tr><tr><td data-num="7"></td><td><pre>    a、<span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"数据格式"</span>:string<span class="token punctuation">)</span>:数据格式可以是：<span class="token string">"csv"</span>、<span class="token string">"mysql"</span>、<span class="token string">"json"</span>、<span class="token string">"jdbc"</span>、<span class="token string">"textFile"</span>、<span class="token string">"orc"</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    b、数据的路径</pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment">--3. 还可以加 option，导入一些参数</span></pre></td></tr><tr><td data-num="11"></td><td><pre>     方式：spark<span class="token punctuation">.</span><span class="token keyword">read</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"…"</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">.</span><span class="token keyword">option</span><span class="token punctuation">(</span><span class="token string">"…"</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token keyword">load</span><span class="token punctuation">(</span><span class="token string">"…"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>     在<span class="token string">"jdbc"</span>格式下需要传入JDBC相应参数，url、<span class="token keyword">user</span>、password和dbtable</pre></td></tr><tr><td data-num="13"></td><td><pre>我们前面都是使用<span class="token keyword">read</span> API 先把文件加载到 DataFrame然后再查询，其实，我们也可以直接在文件上进行查询:  <span class="token string">"文件格式.`文件路径`"</span></pre></td></tr></table></figure><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 情况 1：直接 load</span></pre></td></tr><tr><td data-num="2"></td><td><pre>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"input/users.parquet"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">// 情况 2：指定文件格式</span></pre></td></tr><tr><td data-num="4"></td><td><pre>spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"input/people.json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token comment">// 情况 3：使用文件格式.`文件路径` 方式</span></pre></td></tr><tr><td data-num="6"></td><td><pre>spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select * from json.`input/people.json`"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 因为在实际生产情况下，json 文件的数据格式的场景是非常多的，Spark 对于 json 文件格式要求如下：</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token number">1.</span> JSON文件的格式要求整个文件满足JSON的语法规则</pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token number">2.</span> Spark读取文件默认是以行为单位进行读取</pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token number">3.</span> Spark读取JSON文件时，要求文件中的每一行满足JSON格式</pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token number">4.</span> 如果文件格式不正确，那么不会发生错误，而是解析结果不是我们预期的结果。</pre></td></tr></table></figure><h5 id="2612-保存数据"><a class="anchor" href="#2612-保存数据">#</a> 2.6.1.2 保存数据</h5><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> 保存的方法：</pre></td></tr><tr><td data-num="2"></td><td><pre>       spark<span class="token punctuation">.</span><span class="token keyword">write</span><span class="token punctuation">.</span><span class="token keyword">save</span><span class="token punctuation">(</span>path:String<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token number">2.</span> 默认的保存格式为parquet格式</pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token number">3.</span> 如果想要指定保存的格式<span class="token punctuation">,</span>增加format方法，在format的方法中指定形参数据保存的格式</pre></td></tr><tr><td data-num="5"></td><td><pre>       frame<span class="token punctuation">.</span><span class="token keyword">write</span><span class="token punctuation">.</span><span class="token function">format</span><span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token keyword">save</span><span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token number">4.</span> 如果保存的路径已经存在，那么会报错：output already <span class="token keyword">exists</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    <span class="token number">5.</span> 如果文件路径已经存在时不能创建，那么在实际的生产的情况下，岂不是会生成很多小文件？</pre></td></tr><tr><td data-num="8"></td><td><pre>       解决方案：使用<span class="token keyword">mode</span>，指定模式</pre></td></tr><tr><td data-num="9"></td><td><pre>       方法：<span class="token keyword">mode</span><span class="token punctuation">(</span>形参<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="10"></td><td><pre>       形参：saveMode: SaveMode<span class="token punctuation">,</span>数据类型是一个枚举类</pre></td></tr><tr><td data-num="11"></td><td><pre>       枚举类的对象有：</pre></td></tr><tr><td data-num="12"></td><td><pre>       a、Append:追加，如果原文件目录或表存在，那么在原路径下进行生产一个新的文件</pre></td></tr><tr><td data-num="13"></td><td><pre>       b、Overwrite:重写，如果原文件目录或表存在，那么将原路径下的文件进行直接覆盖</pre></td></tr><tr><td data-num="14"></td><td><pre>       c、ErrorIfExists：默认值，如果原文件目录存在，则报错</pre></td></tr><tr><td data-num="15"></td><td><pre>       d、<span class="token keyword">Ignore</span>：如果原文件目录或表存在，那么不报错，但是也不保存数据</pre></td></tr></table></figure><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre>frame<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">"Overwrite"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="262-csv"><a class="anchor" href="#262-csv">#</a> 2.6.2 CSV</h4><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 读取文件</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"sep"</span><span class="token punctuation">,</span> <span class="token string">";"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"inferSchema"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"header"</span><span class="token punctuation">,</span> <span class="token string">"true"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">"input/people.csv"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>    frame<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre> <span class="token comment">// 保存数据</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    frame<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">"Append"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"json"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">"output"</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="263-mysql"><a class="anchor" href="#263-mysql">#</a> 2.6.3 MySQL</h4><ul><li>方式 1：使用 option 的方式进行参数配置</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 从 MYsql 中读取数据</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> <span class="token string">"jdbc:mysql://hadoop105:3306/mysql"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"driver"</span><span class="token punctuation">,</span> <span class="token string">"com.mysql.jdbc.Driver"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> <span class="token string">"db"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>      <span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre>   <span class="token comment">// 保存到数据库中</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    frame<span class="token punctuation">.</span>write<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token string">"jdbc"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="11"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"url"</span><span class="token punctuation">,</span> <span class="token string">"jdbc:mysql://hadoop105:3306/mysql"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"driver"</span><span class="token punctuation">,</span> <span class="token string">"com.mysql.jdbc.Driver"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>      <span class="token punctuation">.</span>option<span class="token punctuation">(</span><span class="token string">"dbtable"</span><span class="token punctuation">,</span> <span class="token string">"db1"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre>      <span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">"Append"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><ul><li>方式 2：使用 jdbc 的方法</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 创建连接</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">val</span> props<span class="token operator">:</span> Properties <span class="token operator">=</span> <span class="token keyword">new</span> Properties<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre>    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"user"</span><span class="token punctuation">,</span> <span class="token string">"root"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>    props<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"password"</span><span class="token punctuation">,</span> <span class="token string">"123456"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">val</span> df<span class="token operator">:</span> DataFrame <span class="token operator">=</span> spark<span class="token punctuation">.</span>read</pre></td></tr><tr><td data-num="6"></td><td><pre>                        <span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">"jdbc:mysql://hadoop105:3306/mysql"</span><span class="token punctuation">,</span> <span class="token string">"db"</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre></pre></td></tr><tr><td data-num="8"></td><td><pre>    df<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token comment">// 将数据保存到 Mysql 中</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    <span class="token keyword">val</span> rdd<span class="token operator">:</span> RDD<span class="token punctuation">[</span><span class="token builtin">Int</span><span class="token punctuation">]</span> <span class="token operator">=</span> spark<span class="token punctuation">.</span>sparkContext<span class="token punctuation">.</span>makeRDD<span class="token punctuation">(</span>List<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">6</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    <span class="token keyword">val</span> frame<span class="token operator">:</span> DataFrame <span class="token operator">=</span> rdd<span class="token punctuation">.</span>toDF<span class="token punctuation">(</span><span class="token string">"id"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    frame<span class="token punctuation">.</span>write<span class="token punctuation">.</span>mode<span class="token punctuation">(</span><span class="token string">"Append"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>jdbc<span class="token punctuation">(</span><span class="token string">"jdbc:mysql://hadoop105:3306/mysql"</span><span class="token punctuation">,</span> <span class="token string">"db2"</span><span class="token punctuation">,</span> props<span class="token punctuation">)</span></pre></td></tr></table></figure><h4 id="264-hive"><a class="anchor" href="#264-hive">#</a> 2.6.4 Hive</h4><pre><code>1. Spark中内嵌了hive。
</code></pre><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"Hive"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>     <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession</pre></td></tr><tr><td data-num="3"></td><td><pre>      <span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="4"></td><td><pre>      <span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span>   <span class="token comment">// 支持 hive</span></pre></td></tr><tr><td data-num="5"></td><td><pre>      <span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>      <span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="7"></td><td><pre>     <span class="token comment">// 创建表</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token comment">//    spark.sql("create table aa (id int)")</span></pre></td></tr><tr><td data-num="9"></td><td><pre>     <span class="token comment">// 查询表</span></pre></td></tr><tr><td data-num="10"></td><td><pre><span class="token comment">//    spark.sql("show tables").show()</span></pre></td></tr><tr><td data-num="11"></td><td><pre>    </pre></td></tr><tr><td data-num="12"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"load data  local inpath 'input/id.text' into table aa"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="13"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"select * from aa "</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><pre><code>2. 外置Hive
 步骤：
 a、导入依赖
 b、将hive
 c、取消tez引擎
 d、代码实现，访问hive中的表
</code></pre><ul><li>导入依赖</li></ul><figure class="highlight xml"><figcaption data-lang="XML"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.spark<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="3"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>spark-hive_2.12<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>2.4.5<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="6"></td><td><pre></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="8"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">></span></span>org.apache.hive<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">></span></span>hive-exec<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">></span></span>3.1.2<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">></span></span></pre></td></tr></table></figure><ul><li>将 hive-site.xml 文件拷贝到项目的 resources 目录中，代码实现</li></ul><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"hive"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"show databases"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h2 id="三-项目实战"><a class="anchor" href="#三-项目实战">#</a> 三、项目实战</h2><h3 id="31-数据准备"><a class="anchor" href="#31-数据准备">#</a> 3.1 数据准备</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 我们这次 Spark-sql 操作中所有的数据均来自 Hive，首先在 Hive 中创建表，，并导入数据。一共有 3 张表： 1 张用户行为表，1 张城市表，1 张产品表</span></pre></td></tr></table></figure><figure class="highlight scala"><figcaption data-lang="scala"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">// 修改 hadoop 的用户</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   System<span class="token punctuation">.</span>setProperty<span class="token punctuation">(</span><span class="token string">"HADOOP_USER_NAME"</span><span class="token punctuation">,</span> <span class="token string">"atguigu"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre>    <span class="token keyword">val</span> sparkConf<span class="token operator">:</span> SparkConf <span class="token operator">=</span> <span class="token keyword">new</span> SparkConf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setMaster<span class="token punctuation">(</span><span class="token string">"local[*]"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>setAppName<span class="token punctuation">(</span><span class="token string">"pro"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="5"></td><td><pre>    <span class="token keyword">val</span> spark<span class="token operator">:</span> SparkSession <span class="token operator">=</span> SparkSession<span class="token punctuation">.</span>builder<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>enableHiveSupport<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>config<span class="token punctuation">(</span>sparkConf<span class="token punctuation">)</span><span class="token punctuation">.</span>getOrCreate<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="6"></td><td><pre>   </pre></td></tr><tr><td data-num="7"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"use  spark_sql"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"show databases"</span><span class="token punctuation">)</span><span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="11"></td><td><pre>      <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="12"></td><td><pre>        |CREATE TABLE `user_visit_action`(</pre></td></tr><tr><td data-num="13"></td><td><pre>        |  `date` string,</pre></td></tr><tr><td data-num="14"></td><td><pre>        |  `user_id` bigint,</pre></td></tr><tr><td data-num="15"></td><td><pre>        |  `session_id` string,</pre></td></tr><tr><td data-num="16"></td><td><pre>        |  `page_id` bigint,</pre></td></tr><tr><td data-num="17"></td><td><pre>        |  `action_time` string,</pre></td></tr><tr><td data-num="18"></td><td><pre>        |  `search_keyword` string,</pre></td></tr><tr><td data-num="19"></td><td><pre>        |  `click_category_id` bigint,</pre></td></tr><tr><td data-num="20"></td><td><pre>        |  `click_product_id` bigint,</pre></td></tr><tr><td data-num="21"></td><td><pre>        |  `order_category_ids` string,</pre></td></tr><tr><td data-num="22"></td><td><pre>        |  `order_product_ids` string,</pre></td></tr><tr><td data-num="23"></td><td><pre>        |  `pay_category_ids` string,</pre></td></tr><tr><td data-num="24"></td><td><pre>        |  `pay_product_ids` string,</pre></td></tr><tr><td data-num="25"></td><td><pre>        |  `city_id` bigint)</pre></td></tr><tr><td data-num="26"></td><td><pre>        |row format delimited fields terminated by '\t'</pre></td></tr><tr><td data-num="27"></td><td><pre>      """<span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"load data local inpath 'input/user_visit_action.txt' into table user_visit_action"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    </pre></td></tr><tr><td data-num="32"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="33"></td><td><pre>      <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="34"></td><td><pre>        |CREATE TABLE `product_info`(</pre></td></tr><tr><td data-num="35"></td><td><pre>        |  `product_id` bigint,</pre></td></tr><tr><td data-num="36"></td><td><pre>        |  `product_name` string,</pre></td></tr><tr><td data-num="37"></td><td><pre>        |  `extend_info` string)</pre></td></tr><tr><td data-num="38"></td><td><pre>        |row format delimited fields terminated by '\t'</pre></td></tr><tr><td data-num="39"></td><td><pre>      """<span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"load data local inpath 'input/product_info.txt' into table product_info"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre></pre></td></tr><tr><td data-num="43"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="44"></td><td><pre>      <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        |CREATE TABLE `city_info`(</pre></td></tr><tr><td data-num="46"></td><td><pre>        |  `city_id` bigint,</pre></td></tr><tr><td data-num="47"></td><td><pre>        |  `city_name` string,</pre></td></tr><tr><td data-num="48"></td><td><pre>        |  `area` string)</pre></td></tr><tr><td data-num="49"></td><td><pre>        |row format delimited fields terminated by '\t'</pre></td></tr><tr><td data-num="50"></td><td><pre>      """<span class="token punctuation">.</span>stripMargin<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre></pre></td></tr><tr><td data-num="52"></td><td><pre>    spark<span class="token punctuation">.</span>sql<span class="token punctuation">(</span><span class="token string">"load data local inpath 'input/city_info.txt' into table city_info"</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="53"></td><td><pre></pre></td></tr><tr><td data-num="54"></td><td><pre>    spark<span class="token punctuation">.</span>stop<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><h3 id="32-需求-各区域热门商品-top3"><a class="anchor" href="#32-需求-各区域热门商品-top3">#</a> 3.2 需求 ： 各区域热门商品 Top3</h3><h4 id="321-需求"><a class="anchor" href="#321-需求">#</a> 3.2.1 需求</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 这里的热门商品是从点击量的维度来看的，计算各个区域前三大热门商品，并备注上每个商品在主要城市中的分布比例，超过两个城市用其他显示</span></pre></td></tr></table></figure><table><thead><tr><th><em><strong>* 地区 *</strong></em></th><th><em><strong>* 商品名称 *</strong></em></th><th><em><strong>* 点击次数 *</strong></em></th><th><em><strong>* 城市备注 *</strong></em></th></tr></thead><tbody><tr><td><em><strong>* 华北 *</strong></em></td><td>商品 A</td><td>100000</td><td>北京 21.2%，天津 13.2%，其他 65.6%</td></tr><tr><td><em><strong>* 华北 *</strong></em></td><td>商品 P</td><td>80200</td><td>北京 63.0%，太原 10%，其他 27.0%</td></tr><tr><td><em><strong>* 华北 *</strong></em></td><td>商品 M</td><td>40000</td><td>北京 63.0%，太原 10%，其他 27.0%</td></tr><tr><td><em><strong>* 东北 *</strong></em></td><td>商品 J</td><td>92000</td><td>大连 28%，辽宁 17.0%，其他 55.0%</td></tr></tbody></table><h4 id="322-需求分析"><a class="anchor" href="#322-需求分析">#</a> 3.2.2 需求分析</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">SELECT</span> t4<span class="token punctuation">.</span>area<span class="token punctuation">,</span>t4<span class="token punctuation">.</span>product_name<span class="token punctuation">,</span>t4<span class="token punctuation">.</span>clickCount</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">FROM</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="3"></td><td><pre>	<span class="token keyword">SELECT</span> t3<span class="token punctuation">.</span>area<span class="token punctuation">,</span>t3<span class="token punctuation">.</span>product_name<span class="token punctuation">,</span>t3<span class="token punctuation">.</span>clickCount<span class="token punctuation">,</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	RANK<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">over</span><span class="token punctuation">(</span><span class="token keyword">partition</span> <span class="token keyword">by</span> t3<span class="token punctuation">.</span>area  <span class="token keyword">order</span> <span class="token keyword">by</span> clickCount <span class="token keyword">DESC</span> <span class="token punctuation">)</span> <span class="token keyword">as</span> click_rank</pre></td></tr><tr><td data-num="5"></td><td><pre>	<span class="token keyword">FROM</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="6"></td><td><pre>		<span class="token keyword">SELECT</span> t2<span class="token punctuation">.</span>area<span class="token punctuation">,</span>t2<span class="token punctuation">.</span>product_name<span class="token punctuation">,</span><span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">as</span> clickCount </pre></td></tr><tr><td data-num="7"></td><td><pre>	<span class="token keyword">FROM</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="8"></td><td><pre>		<span class="token keyword">SELECT</span> t1<span class="token punctuation">.</span>city_id<span class="token punctuation">,</span>pro<span class="token punctuation">.</span>product_name <span class="token punctuation">,</span>city<span class="token punctuation">.</span>city_name <span class="token punctuation">,</span>city<span class="token punctuation">.</span>area </pre></td></tr><tr><td data-num="9"></td><td><pre>		<span class="token keyword">FROM</span> <span class="token punctuation">(</span></pre></td></tr><tr><td data-num="10"></td><td><pre>			<span class="token keyword">select</span> <span class="token operator">*</span> </pre></td></tr><tr><td data-num="11"></td><td><pre>			<span class="token keyword">FROM</span> user_visit_action </pre></td></tr><tr><td data-num="12"></td><td><pre>			<span class="token keyword">WHERE</span> click_category_id <span class="token operator">!=</span><span class="token operator">-</span><span class="token number">1</span> </pre></td></tr><tr><td data-num="13"></td><td><pre>			<span class="token punctuation">)</span>t1 <span class="token keyword">join</span> product_info pro</pre></td></tr><tr><td data-num="14"></td><td><pre>			<span class="token keyword">on</span>  pro<span class="token punctuation">.</span>product_id  <span class="token operator">=</span> t1<span class="token punctuation">.</span>click_product_id</pre></td></tr><tr><td data-num="15"></td><td><pre>			<span class="token keyword">join</span> city_info city</pre></td></tr><tr><td data-num="16"></td><td><pre>			<span class="token keyword">on</span> t1<span class="token punctuation">.</span>city_id <span class="token operator">=</span> city<span class="token punctuation">.</span>city_id</pre></td></tr><tr><td data-num="17"></td><td><pre>			<span class="token punctuation">)</span>t2</pre></td></tr><tr><td data-num="18"></td><td><pre>		<span class="token keyword">group</span> <span class="token keyword">by</span> t2<span class="token punctuation">.</span>area<span class="token punctuation">,</span>t2<span class="token punctuation">.</span>product_name</pre></td></tr><tr><td data-num="19"></td><td><pre>	<span class="token punctuation">)</span>t3</pre></td></tr><tr><td data-num="20"></td><td><pre>  <span class="token punctuation">)</span>t4</pre></td></tr><tr><td data-num="21"></td><td><pre><span class="token keyword">WHERE</span> t4<span class="token punctuation">.</span>click_rank <span class="token operator">&lt;=</span> <span class="token number">3</span></pre></td></tr></table></figure><p>![image-20200616000034398](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200616000036.png)</p><ul><li>补充备注信息</li></ul><pre><code>
</code></pre></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2020-07-24 14:46:38" itemprop="dateModified" datetime="2020-07-24T14:46:38+08:00">2020-07-24</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Miyazono 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="Miyazono 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="Miyazono 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Miyazono <i class="ic i-at"><em>@</em></i>冬樱茶</li><li class="link"><strong>本文链接：</strong> <a href="https://github.com/Mayizono/miyazono.github.io/big-data/spark/6.SparkSQL/">https://github.com/Mayizono/miyazono.github.io/big-data/spark/6.SparkSQL/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/big-data/spark/5.Spark%E4%B9%8BWordCount/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva4.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gipet8c1a2j20zk0m8kct.jpg" title="未命名"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>未命名</h3></a></div><div class="item right"><a href="/big-data/spark/7.SparkStreaming/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva4.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1gicitcxhpij20zk0m8hdt.jpg" title="未命名"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i></span><h3>未命名</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#sparksql"><span class="toc-number">1.</span> <span class="toc-text">SparkSQL</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-sparksql%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">一、 SparkSQL 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-sparksql%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 SparkSQL 是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-hive-%E5%92%8C-sparksql%E8%A7%A3%E6%9E%90"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 Hive 和 SparkSQL 解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-dataframe%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 DataFrame 是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-dataset%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 DataSet 是什么</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-%E4%B8%89%E8%80%85%E4%B9%8B%E9%97%B4%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.1.5.</span> <span class="toc-text">1.5 三者之间的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-sparksql%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B"><span class="toc-number">1.2.</span> <span class="toc-text">二、 SparkSQL 核心编程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-sparksql%E7%9A%84%E7%8E%AF%E5%A2%83%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 SparkSQL 的环境对象</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-dataframe"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 DataFrame</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#221-%E5%88%9B%E5%BB%BAdataframe"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">2.2.1 创建 DataFrame</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#222-sql%E8%AF%AD%E6%B3%95"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2.2.2 SQL 语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#223-dsl"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">2.2.3 DSL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#224-sql%E8%AF%AD%E6%B3%95%E5%92%8Cdsl%E8%AF%AD%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.2.2.4.</span> <span class="toc-text">2.2.4 SQL 语法和 DSL 语法的区别</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#23-dataframedatesetrdd%E4%B8%89%E8%80%85%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="toc-number">1.2.3.</span> <span class="toc-text">2.3 DataFrame&#x2F;DateSet&#x2F;RDD 三者之间的转换</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#24-idea%E7%BC%96%E7%A8%8B"><span class="toc-number">1.2.4.</span> <span class="toc-text">2.4 IDEA 编程</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#241-%E6%B7%BB%E5%8A%A0%E4%BE%9D%E8%B5%96"><span class="toc-number">1.2.4.1.</span> <span class="toc-text">2.4.1 添加依赖</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#242-%E6%9E%84%E5%BB%BAsparksession%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.2.4.2.</span> <span class="toc-text">2.4.2 构建 sparkSession 对象</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#243-%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.2.4.3.</span> <span class="toc-text">2.4.3 代码实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#25-udf%E5%92%8Cudaf"><span class="toc-number">1.2.5.</span> <span class="toc-text">2.5 UDF 和 UDAF</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#251-udf"><span class="toc-number">1.2.5.1.</span> <span class="toc-text">2.5.1 UDF</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#252-udaf"><span class="toc-number">1.2.5.2.</span> <span class="toc-text">2.5.2 UDAF</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#26-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98"><span class="toc-number">1.2.6.</span> <span class="toc-text">2.6 数据的加载和保存</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#261-%E9%80%9A%E7%94%A8%E7%9A%84%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%92%8C%E4%BF%9D%E5%AD%98%E6%96%B9%E5%BC%8F"><span class="toc-number">1.2.6.1.</span> <span class="toc-text">2.6.1 通用的数据加载和保存方式</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2611-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.6.1.1.</span> <span class="toc-text">2.6.1.1 读取数据</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2612-%E4%BF%9D%E5%AD%98%E6%95%B0%E6%8D%AE"><span class="toc-number">1.2.6.1.2.</span> <span class="toc-text">2.6.1.2 保存数据</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#262-csv"><span class="toc-number">1.2.6.2.</span> <span class="toc-text">2.6.2 CSV</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#263-mysql"><span class="toc-number">1.2.6.3.</span> <span class="toc-text">2.6.3 MySQL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#264-hive"><span class="toc-number">1.2.6.4.</span> <span class="toc-text">2.6.4 Hive</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98"><span class="toc-number">1.3.</span> <span class="toc-text">三、项目实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E6%95%B0%E6%8D%AE%E5%87%86%E5%A4%87"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 数据准备</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-%E9%9C%80%E6%B1%82-%E5%90%84%E5%8C%BA%E5%9F%9F%E7%83%AD%E9%97%A8%E5%95%86%E5%93%81-top3"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 需求 ： 各区域热门商品 Top3</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#321-%E9%9C%80%E6%B1%82"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">3.2.1 需求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#322-%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">3.2.2 需求分析</span></a></li></ol></li></ol></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Miyazono" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Miyazono</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">23</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">6</span> <span class="name">分类</span></a></div></nav><div class="social"><a href="https://github.com/amehime" title="https:&#x2F;&#x2F;github.com&#x2F;amehime" class="item github"><i class="ic i-github"></i></a> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9hbWVoaW1l" title="https:&#x2F;&#x2F;twitter.com&#x2F;amehime"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9ydXJpc216aw==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;rurismzk"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTEyODg2ODIz" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;12886823"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20vYW1laGltZQ==" title="https:&#x2F;&#x2F;weibo.com&#x2F;amehime"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS9hbWVoaW1l" title="https:&#x2F;&#x2F;about.me&#x2F;amehime"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/mikutap/" rel="section"><i class="ic i-star"></i>mikutap</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/big-data/spark/5.Spark%E4%B9%8BWordCount/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/big-data/spark/7.SparkStreaming/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"></div><span><a href="/Day10-%E7%BB%A7%E6%89%BF/" title="Java基础--继承">Java基础--继承</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/7.SparkStreaming/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/1.Spark%E7%8E%AF%E5%A2%83%E7%9A%84%E5%AE%89%E8%A3%85/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/2_Canal/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/4.%20Spark%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%94%B5%E5%95%86%E6%8C%87%E6%A0%87%E7%BB%9F%E8%AE%A1/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/flink/" title="分类于 Flink">Flink</a></div><span><a href="/big-data/flink/1_Nginx/" title="负载均衡Nginx的使用">负载均衡Nginx的使用</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/%E6%A8%A1%E5%9D%97%E6%80%BB%E7%BB%93/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/flume/" title="分类于 Flume">Flume</a></div><span><a href="/big-data/flume/Flume/" title="Flume基础学习">Flume基础学习</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/8.Spark%E5%86%85%E6%A0%B8/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/2.Spark%E6%9E%B6%E6%9E%84%E5%8F%8A%E7%BC%96%E7%A8%8B/" title="未命名">未命名</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Miyazono @ Yume Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">324k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">4:54</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<a href="https://github.com/amehime/hexo-theme-shoka">Shoka</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"big-data/spark/6.SparkSQL/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->