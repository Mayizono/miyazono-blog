<!-- build time:Wed Sep 29 2021 21:12:09 GMT+0800 (中国标准时间) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/rss.xml"><link rel="alternate" type="application/atom+xml" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/atom.xml"><link rel="alternate" type="application/json" title="冬樱茶" href="https://github.com/Mayizono/miyazono.github.io/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><link rel="canonical" href="https://github.com/Mayizono/miyazono.github.io/big-data/hive/Hive%20%E5%AD%A6%E4%B9%A0/"><title>Hive 学习 - Hive - 大数据 | Yume Shoka = 冬樱茶</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Hive 学习</h1><div class="meta"><span class="item" title="创建时间：2019-10-11 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2019-10-11T00:00:00+08:00">2019-10-11</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>23k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>21 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Yume Shoka</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gipewkhf1zj20zk0m81kx.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1giciuv0socj20zk0m8qes.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1giclhnx9glj20zk0m8npd.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicit4jrvuj20zk0m8785.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicm07ih54j20zk0m84qp.jpg"></li><li class="item" data-background-image="https://tva1.sinaimg.cn/large/6833939bly1gicliierfjj20zk0m8npd.jpg"></li></ul></div><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div></header><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/big-data/" itemprop="item" rel="index" title="分类于 大数据"><span itemprop="name">大数据</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/big-data/hive/" itemprop="item" rel="index" title="分类于 Hive"><span itemprop="name">Hive</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://github.com/Mayizono/miyazono.github.io/big-data/hive/Hive%20%E5%AD%A6%E4%B9%A0/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="Miyazono"><meta itemprop="description" content=", "></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="冬樱茶"></span><div class="body md" itemprop="articleBody"><h1 id="hive-学习"><a class="anchor" href="#hive-学习">#</a> Hive 学习</h1><hr><h3 id="01-什么是hive"><a class="anchor" href="#01-什么是hive">#</a> 0.1 什么是 hive</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> Hive：由Facebook开源用于解决<span class="token string">'海量结构化日志'</span>的数据统计<span class="token string">'工具'</span>。</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> Hive是基于Hadoop的一个<span class="token string">'数据仓库工具'</span>，可以将结构化的数据文件<span class="token string">'映射'</span>为一张表，并提供类<span class="token keyword">SQL</span>查询功能。</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token number">3.</span> <span class="token string">'本质'</span>：将HQL转化成MapReduce程序</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token number">4.</span> <span class="token string">'原理介绍'</span></pre></td></tr><tr><td data-num="5"></td><td><pre>   	（<span class="token number">1</span>）Hive处理的数据存储在HDFS</pre></td></tr><tr><td data-num="6"></td><td><pre>    （<span class="token number">2</span>）Hive分析数据底层的实现是MapReduce</pre></td></tr><tr><td data-num="7"></td><td><pre>    （<span class="token number">3</span>）执行程序运行在Yarn上</pre></td></tr></table></figure><h3 id="02-优缺点"><a class="anchor" href="#02-优缺点">#</a> 0.2 优缺点</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 优点：</span></pre></td></tr><tr><td data-num="2"></td><td><pre>   <span class="token number">1.</span> 操作接口采用类<span class="token keyword">SQL</span>语法，提供快速开发的能力（简单、容易上手）。</pre></td></tr><tr><td data-num="3"></td><td><pre>   <span class="token number">2.</span> 避免了去写MapReduce，减少开发人员的学习成本。</pre></td></tr><tr><td data-num="4"></td><td><pre>   <span class="token number">3.</span> Hive的执行延迟比较高，因此Hive常用于数据分析，对实时性要求不高的场合。</pre></td></tr><tr><td data-num="5"></td><td><pre>   <span class="token number">4.</span> Hive优势在于处理大数据，对于处理小数据没有优势，因为Hive的执行延迟比较高。</pre></td></tr><tr><td data-num="6"></td><td><pre>   <span class="token number">5.</span> Hive支持用户自定义函数，用户可以根据自己的需求来实现自己的函数。</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token comment">-- 2. 缺点</span></pre></td></tr><tr><td data-num="8"></td><td><pre>   <span class="token number">1.</span> Hive的HQL表达能力有限</pre></td></tr><tr><td data-num="9"></td><td><pre>   <span class="token number">2.</span> 迭代式算法无法表达</pre></td></tr><tr><td data-num="10"></td><td><pre>   <span class="token number">3.</span> 数据挖掘方面不擅长，由于MapReduce数据处理流程的限制，效率更高的算法却无法实现。</pre></td></tr><tr><td data-num="11"></td><td><pre>   <span class="token number">4.</span> Hive的效率比较低</pre></td></tr><tr><td data-num="12"></td><td><pre>    （<span class="token number">1</span>）Hive自动生成的MapReduce作业，通常情况下不够智能化</pre></td></tr><tr><td data-num="13"></td><td><pre>    （<span class="token number">2</span>）Hive调优比较困难，粒度较粗</pre></td></tr></table></figure><h3 id="03-hive架构原理"><a class="anchor" href="#03-hive架构原理">#</a> 0.3 Hive 架构原理</h3><p><img data-src="https://miyazono-1255488789.cos.ap-shanghai.myqcloud.com/markdown/20200720000427.png" alt="image"></p><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 用户接口：Client</span></pre></td></tr><tr><td data-num="2"></td><td><pre>	CLI（command<span class="token operator">-</span>line interface）、JDBC<span class="token operator">/</span>ODBC<span class="token punctuation">(</span>jdbc访问hive<span class="token punctuation">)</span>、WEBUI（浏览器访问hive）</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">-- 2. 元数据：Metastore</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	元数据包括：</pre></td></tr><tr><td data-num="5"></td><td><pre>	   a、表名</pre></td></tr><tr><td data-num="6"></td><td><pre>	   b、表所属的数据库（默认是<span class="token keyword">default</span>）</pre></td></tr><tr><td data-num="7"></td><td><pre>	   c、表的拥有者</pre></td></tr><tr><td data-num="8"></td><td><pre>	   d、列<span class="token operator">/</span>分区字段</pre></td></tr><tr><td data-num="9"></td><td><pre>	   e、表的类型（是否是外部表）、</pre></td></tr><tr><td data-num="10"></td><td><pre>	   f、表的数据所在目录等；</pre></td></tr><tr><td data-num="11"></td><td><pre>	<span class="token string">'默认存储在自带的derby数据库中，推荐使用MySQL存储Metastore'</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token comment">-- 3. Hadoop</span></pre></td></tr><tr><td data-num="13"></td><td><pre>	使用HDFS进行存储，使用MapReduce进行计算。</pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token comment">-- 4. 驱动器：Driver</span></pre></td></tr><tr><td data-num="15"></td><td><pre>	<span class="token number">1.</span> <span class="token string">'解析器'</span>（<span class="token keyword">SQL</span> Parser）：将<span class="token keyword">SQL</span>字符串转换成抽象语法树AST，这一步一般都用第三方工具库完成，</pre></td></tr><tr><td data-num="16"></td><td><pre>	   比如antlr；对AST进行语法分析，比如表是否存在、字段是否存在、<span class="token keyword">SQL</span>语义是否有误。</pre></td></tr><tr><td data-num="17"></td><td><pre>    <span class="token number">2.</span> <span class="token string">'编译器'</span>（Physical <span class="token keyword">Plan</span>）：将AST编译生成逻辑执行计划。</pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token number">3.</span> <span class="token string">'优化器'</span>（Query Optimizer）：对逻辑执行计划进行优化。</pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token number">4.</span> <span class="token string">'执行器'</span>（Execution）：把逻辑执行计划转换成可以运行的物理计划。对于Hive来说，就是MR<span class="token operator">/</span>Spark。</pre></td></tr></table></figure><h3 id="04-hive与数据库的比较"><a class="anchor" href="#04-hive与数据库的比较">#</a> 0.4 hive 与数据库的比较</h3><blockquote><p>由于 Hive 采用了类似 SQL 的查询语言 HQL (Hive Query Language)，因此很容易将 Hive 理解为数据库。其实从结构上来看，Hive 和数据库除了拥有类似的查询语言，再无类似之处</p></blockquote><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">-- 1. 查询语言</span></pre></td></tr><tr><td data-num="2"></td><td><pre>    hive有类似<span class="token keyword">sql</span>的hql查询语言</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token comment">-- 2. 数据更新</span></pre></td></tr><tr><td data-num="4"></td><td><pre>	<span class="token number">1.</span> hive针对数据仓库而设计，适合读多写少的场景</pre></td></tr><tr><td data-num="5"></td><td><pre>	<span class="token number">2.</span> mysql的数据需要经常进行修改。</pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">-- 3.  执行延迟</span></pre></td></tr><tr><td data-num="7"></td><td><pre>	<span class="token number">1.</span> hive没有索引 <span class="token operator">+</span> 基于mr计算，延迟性高；</pre></td></tr><tr><td data-num="8"></td><td><pre>	<span class="token number">2.</span> 这个低是有条件的，即数据规模较小，当数据规模大到超过数据库的处理能力的时候，Hive的并行计算显然能体现出优势</pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token comment">-- 4. 数据规模</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    <span class="token number">1.</span> 支持大数据规模的数据</pre></td></tr></table></figure><h3 id="05-tez引擎"><a class="anchor" href="#05-tez引擎">#</a> 0.5 tez 引擎</h3><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token number">1.</span> <span class="token string">'mr引擎'</span>：每个任务及任务之间都需要落盘</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token number">2.</span> <span class="token string">'Tez引擎'</span>：可以将多个有依赖的作业转换为一个作业，这样只需写一次HDFS，且中间节点较少，从而大大提升作业的计算性能。</pre></td></tr></table></figure><p><img data-src="https://miyazono-1255488789.cos.ap-shanghai.myqcloud.com/markdown/20200720001522.png" alt="image"></p><h2 id="一-hivejdbc客户端基本操作"><a class="anchor" href="#一-hivejdbc客户端基本操作">#</a> 一、HiveJDBC 客户端基本操作</h2><h3 id="11-hviejdbc的登入与退出"><a class="anchor" href="#11-hviejdbc的登入与退出">#</a> 1.1 HvieJDBC 的登入与退出</h3><pre><code class="language-mysql">-- 方式一：使用beeline方式
访问方式：beeline -u jdbc:hive2://hadoop102:10000 -n lianzp
退出方式：！quit  、!exit 、 ctrl + c
前提：mysql服务和hiveservice2服务一定要启动

-- 方式二： 使用hive的方式
访问方式：hive
退出方式：quit； exit；
</code></pre><h3 id="12-hive常用的交互命令"><a class="anchor" href="#12-hive常用的交互命令">#</a> 1.2 Hive 常用的交互命令</h3><blockquote><ul><li><p>“-e” 不进入 hive 的交互窗口执行 sql 语句 **</p></li><li><p>“-f” 执行脚本中 sql 语句 **</p></li></ul></blockquote><h3 id="13-hive数据类型"><a class="anchor" href="#13-hive数据类型">#</a> 1.3 Hive 数据类型</h3><ul><li>基本数据类型</li></ul><table><thead><tr><th>Hive 数据类型</th><th>Java 数据类型</th><th>长度</th><th>例子</th></tr></thead><tbody><tr><td>TINYINT</td><td>byte</td><td>1byte 有符号整数</td><td>20</td></tr><tr><td>SMALINT</td><td>short</td><td>2byte 有符号整数</td><td>20</td></tr><tr><td>INT</td><td>int</td><td>4byte 有符号整数</td><td>20</td></tr><tr><td>BIGINT</td><td>long</td><td>8byte 有符号整数</td><td>20</td></tr><tr><td>BOOLEAN</td><td>boolean</td><td>布尔类型，true 或者 false</td><td>TRUE FALSE</td></tr><tr><td>FLOAT</td><td>float</td><td>单精度浮点数</td><td>3.14159</td></tr><tr><td>DOUBLE</td><td>double</td><td>双精度浮点数</td><td>3.14159</td></tr><tr><td>STRING</td><td>string</td><td>字符系列。可以指定字符集。可以使用单引号或者双引号。</td><td>‘now is the time’ “for all good men”</td></tr><tr><td>TIMESTAMP</td><td></td><td>时间类型</td><td></td></tr><tr><td>BINARY</td><td></td><td>字节数组</td><td></td></tr></tbody></table><blockquote><ul><li><p>重点关注：int，string，double,bigint ；</p></li><li><p>使用注意事项：在 sql 中需要指定字段的长度，而在 hive 中不需要，可以理解为可变参数 ；</p></li><li><p>数据类型的字节数：</p></li></ul><table><thead><tr><th style="text-align:center">byte</th><th style="text-align:center">short</th><th style="text-align:center">int</th><th style="text-align:center">long</th><th>float</th><th style="text-align:center">double</th><th style="text-align:center">char</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">2</td><td style="text-align:center">4</td><td style="text-align:center">8</td><td>4</td><td style="text-align:center">8</td><td style="text-align:center">2</td></tr></tbody></table><p>​ 其中 float 的取值范围比 long 还要大。</p></blockquote><ul><li><p>集合数据类型</p><table><thead><tr><th style="text-align:center">数据类型</th><th style="text-align:left">描述</th><th>语法示例</th></tr></thead><tbody><tr><td style="text-align:center">STRUCT</td><td style="text-align:left">和 c 语言中的 struct 类似，都可以通过 “点” 符号访问元素内容。例如，如果某个列的数据类型是 STRUCT {first STRING, last STRING}, 那么第 1 个元素可以通过字段.first 来引用。</td><td>struct () 例如 struct&lt;street:string, city:string&gt;</td></tr><tr><td style="text-align:center">MAP</td><td style="text-align:left">MAP 是一组键 - 值对元组集合，使用数组表示法可以访问数据。例如，如果某个列的数据类型是 MAP，其中键值对是’first’-&gt;’John’和’last’-&gt;’Doe’，那么可以通过字段名 [‘last’] 获取最后一个元素</td><td>map () 例如 map&lt;string, int&gt;</td></tr><tr><td style="text-align:center">ARRAY</td><td style="text-align:left">数组是一组具有相同类型和名称的变量的集合。这些变量称为数组的元素，每个数组元素都有一个编号，编号从零开始。例如，数组值为 [‘John’, ‘Doe’]，那么第 2 个元素可以通过数组名 [1] 进行引用。</td><td>Array () 例如 array&lt;string&gt;</td></tr></tbody></table></li></ul><p>创建表的实例：</p><pre><code class="language-mysql">create table if not exists test(
name string,
friends array&lt;string&gt;,  /*--数组的格式--*/
children map&lt;string, int&gt;, /*--集合的格式--*/
address struct&lt;street:string, city:string&gt;/* --Struct格式-- */
)
row format delimited fields terminated by ',' 
/*  行 格式      划分属性    以‘，’分割  ，统称为列分割符*/
collection items terminated by '_'
/*集合（数组，集合，Struct） 多个元素之间以‘_’ 分割，则要求所有的数据的格式均是一样的*/
map keys terminated by ':'
/*指明集合中key和value以‘：’ 进行分割*/
lines terminated by '\n';
/*行数据，以换行符进行分割*/
</code></pre><p>获取集合中属性的方式：</p><pre><code class="language-mysql">* 	数组：使用索引的方式：字段名[index]
*
*	集合：使用key的值获取：字段名[key的值]
*
*	Struct：使用：字段.属性值
</code></pre><h3 id="14-类型转化"><a class="anchor" href="#14-类型转化">#</a> 1.4 类型转化</h3><ol><li><p>隐式类型转换规则</p><ul><li><p>任何整数类型都可以隐式地转换为一个范围更广的类型，如 TINYINT 可以转换成 INT，INT 可以转换成 BIGINT；</p></li><li><p>所有整数类型、FLOAT 和<strong> STRING</strong> 类型都可以隐式地转换成 DOUBLE；</p></li><li><p>TINYINT、SMALLINT、INT 都可以转换为 FLOAT；</p></li><li><p>BOOLEAN 类型不可以转换为任何其它的类型。</p></li></ul></li><li><p><strong>CAST 操作显示进行数据类型转换</strong></p><pre><code class="language-mysql">-- 示例：
select cast ('1' as int) + 3  ;  /* 4 */
select '1' + 3 ; /* 4.0 */
</code></pre></li></ol><h2 id="二-ddl数据定义"><a class="anchor" href="#二-ddl数据定义">#</a> 二、DDL 数据定义</h2><h3 id="21-数据库操作"><a class="anchor" href="#21-数据库操作">#</a> 2.1 数据库操作</h3><h4 id="211显示和查询数据库与表信息"><a class="anchor" href="#211显示和查询数据库与表信息">#</a> 2.1.1 显示和查询数据库与表信息</h4><pre><code class="language-mysql">1.显示数据库
show databases;
2.切换数据库
use 数据库名；
3.查询数据库详细信息
desc database [extended] 数据库名
4.查询表的详细信息
desc [formatted] 表名

</code></pre><h4 id="212-创建数据库"><a class="anchor" href="#212-创建数据库">#</a> 2.1.2 创建数据库</h4><pre><code class="language-mysql">CREATE DATABASE [IF NOT EXISTS] database_name
[COMMENT database_comment]
[LOCATION hdfs_path] 
[WITH DBPROPERTIES (property_name=property_value, ...)];
</code></pre><p>实例：</p><pre><code class="language-mysql">1.create database db_hive;

2.create database if not exists db_hive; 
/* 加上 if not exists 后，当该数据库已存在时，不抛异常，也不做创建数据库的操作*/

3.create database db_hive2 location '/db_hive2.db';
/*指定数据创建时，在hdfs上的路径，如果没有此操作，则默认的路径为：/user/hive/warehouse/数据库名*/
</code></pre><h4 id="213-删除数据库"><a class="anchor" href="#213-删除数据库">#</a> 2.1.3 删除数据库</h4><pre><code class="language-mysql">1.删除空的数据库（何为空的数据库？指该数据中没有表）
drop database db_hive2 ;
2.当数据库不存在时，避免抛异常
drop database if not exists db_hive2 ;
3.当数据库不为空时，加上cascade进行删除
drop database if not exists db_hive2  cascade ;
</code></pre><h3 id="22-表的操作"><a class="anchor" href="#22-表的操作">#</a> 2.2 表的操作</h3><h4 id="221-建表语法"><a class="anchor" href="#221-建表语法">#</a> 2.2.1 建表语法</h4><pre><code class="language-mysql">CREATE [EXTERNAL] TABLE [IF NOT EXISTS] table_name 
[(col_name data_type [COMMENT col_comment], ...)] 
[COMMENT table_comment] 
[PARTITIONED BY (col_name data_type [COMMENT col_comment], ...)] 
[CLUSTERED BY (col_name, col_name, ...) 
[SORTED BY (col_name [ASC|DESC], ...)] INTO num_buckets BUCKETS] 
[ROW FORMAT row_format] 
[STORED AS file_format] 
[LOCATION hdfs_path]
[TBLPROPERTIES (property_name=property_value, ...)]
[AS select_statement]
</code></pre><p>各个参数说明：</p><ol><li><p>EXTERNAL ：表示外部表，在删除表时，只会删除 mysql 中的元数据，在 hdfs 的真实数据不会被删除，如果没 EXTERNAL ，则删除表的时候，元数据和真实数据均为被删除。</p></li><li><p>IF NOT EXISTS ：当表存在时，添加此操作，则不会抛异常，同时也不会执行建表操作。</p></li><li><p>COMMENT ：字段或表的注释；</p></li><li><p>PARTITIONED BY ： 分区 ** <code>（后面详细讲）</code> **；</p></li><li><p>CLUSTERED BY ： 分桶 **（后面详细讲）**；</p></li><li><p>SORTED BY ：文件在 hdfs 的存储格式 ，存储的方式有：SEQUENCEFILE（二进制序列文件）、TEXTFILE（文本）、RCFILE（列式存储格式文件）</p><p>如果文件数据是纯文本，可以使用 STORED AS TEXTFILE。如果数据需要压缩，使用 STORED AS SEQUENCEFILE；</p></li><li><p>ROW FORMAT row_format ：列分割符；</p></li><li><p>LOCATION hdfs_path：指定表在 HDFS 上的存储位置；默认为当前库下。</p></li><li><p>AS select_statement ：建表时进行加载数据，通过 as 后面的查询语句。</p></li></ol><h4 id="222-管理表与外部表"><a class="anchor" href="#222-管理表与外部表">#</a> 2.2.2 管理表与外部表</h4><p>区别：</p><pre><code class="language-mysql">1.管理表：也称内部表，当删除管理表时，hdfs中的数据和mysql中的元数据均会被删除 -- 控制表的生命周期
2.外部表：当删除管理表时，hdfs中的数据不会被删除，mysql中的元数据会被删除  -- 不能控制表的生命周期

在实战过程中，我们一般都是使用外部表。
</code></pre><p>内外部表的定义、查看和转换</p><pre><code class="language-mysql">1.定义：
创建表单时，加上 external 关键字则表示为外部表。

2.查看：
通过 desc formatted 表名 。

3.转换：
alter table 表名 set tblproperties('EXTERNAL'='TRUE');
注意事项：
a、TRUE :   转换为外部表；
b、FALSE ： 转换为内部表;
c、('EXTERNAL'='TRUE')和('EXTERNAL'='FALSE')为固定写法，均需要大写！
</code></pre><h4 id="223-修改表"><a class="anchor" href="#223-修改表">#</a> 2.2.3 修改表</h4><ol><li>重命名表</li></ol><pre><code class="language-mysql">-- 语法：
alter table 旧表名 rename to 新表名 ；
-- 示例：
alter table dept_partition2 rename to dept_partition3;
</code></pre><ol start="2"><li>更新列</li></ol><pre><code class="language-mysql">-- 语法：
alter table 表名 change 旧列名 新列名 数据类型  
-- 示例：
alter table emp change ename naem string first deptno;
</code></pre><ol start="3"><li>增加列</li></ol><pre><code class="language-mysql">-- 语法：
alter table 表名 add 列名 数据类型 [字段注释] [first / after  列名]
-- 示例：
alter table emp add loc string ;
</code></pre><ol start="4"><li>删除表</li></ol><pre><code class="language-mysql">-- 语法：
drop table 表名
-- 示例：
drop table emp ;
</code></pre><h2 id="三-dml-操作"><a class="anchor" href="#三-dml-操作">#</a> 三、DML 操作</h2><p><strong>注意事项：</strong></p><pre><code>当导入数据时，如果加载本地的文件，并是将数据加载到有分区和分桶表的hive表中时，因为此导入数据的过程会跑mr程序，该本地文件需要在所有节点都需要，不然会报文件不存在异常。
</code></pre><h3 id="31-数据的导入"><a class="anchor" href="#31-数据的导入">#</a> 3.1 数据的导入</h3><h4 id="311-方式一"><a class="anchor" href="#311-方式一">#</a> 3.1.1 方式一</h4><ul><li>使用 load</li></ul><pre><code class="language-mysql">-- 语法：
load data [local] inpath '数据的路径'  [overwrite] into table 表名 [partition (分区字段 = value1) (分区字段 = value2)]

-- 说明：
local : 如果使用了，则'数据的路径'写linux本地的路径；
	    如果未使用，则'数据的路径'写hdfs上的路径； 
partition (分区字段 = value1)   ：表示数据上传到哪一个分区，后面详细介绍。  
overwrite : 表示覆盖写。

-- 示例：
本地 ： load data local inpath '/opt/module/hive/datas/emp' into table emp;
hdfs :  load data inpath '/user/hive/warehouse/emp' into table emp;
</code></pre><h4 id="312-方式二"><a class="anchor" href="#312-方式二">#</a> 3.1.2 方式二</h4><ul><li>通过查询语句向表中进行添加</li></ul><pre><code class="language-mysql">-- 语法：
1) insert into table 表名 select 字段 from 表名； -- 追加的方式，原数据不会丢失

2) insert overwrite table 表名 select 字段 from 表名； -- 覆盖原数据的方式，原数据被覆盖

3) insert into table 表名 select 字段 from 表名 partition (分区字段 = Value)； 多分区的插入模式

-- 示例：
1) insert into table emp select id ,name from emp1;

2) insert overwrite table emp  select id ,name from emp1;

3) insert into table emp select id ,name from emp1 partition (month = '2020-02-04');

</code></pre><h4 id="313-方式三"><a class="anchor" href="#313-方式三">#</a> 3.1.3 方式三</h4><ul><li>创建表并使用查询语句加载数据（As Select）</li></ul><pre><code class="language-mysql">-- 语法：
建表语句 + as  + 查询语句

-- 示例：
create  [external] table [if not exists] emp (
id int ,
name string
)
row format delimited fields terminated by '\t'  
as select id , name from emp1; 
</code></pre><h4 id="314-方式四"><a class="anchor" href="#314-方式四">#</a> 3.1.4 方式四</h4><ul><li>创建表时使用 location 的方式</li></ul><pre><code class="language-mysql">-- 语法：
建表语句 + location + 'hdfs数据路径'  

-- 说明：
数据路径：只能是hdfs上的路径，当该路径是一个目录时，则表示加载该文件夹下的所有文件

-- 示例：
create  [external] table [if not exists] emp (
id int ,
name string
)
row format delimited fields terminated by '\t'  
location '/user/hive/warehouse/emp' ;
</code></pre><h4 id="315-方式五"><a class="anchor" href="#315-方式五">#</a> 3.1.5 方式五</h4><ul><li>使用 import 方式</li></ul><p>注意：必须使用 export 的方式导出以后（导出了元数据和真实数据），再使用 import 进行导入。</p><pre><code class="language-mysql">-- 示例：
import table student2  from '/user/hive/warehouse/export/student'
</code></pre><h3 id="32-数据的导出"><a class="anchor" href="#32-数据的导出">#</a> 3.2 数据的导出</h3><ul><li>说明：数据的导出的方式，使用的情况很少。</li></ul><h4 id="321-方式一"><a class="anchor" href="#321-方式一">#</a> 3.2.1 方式一</h4><ul><li>insert 方式</li></ul><pre><code class="language-mysql">-- 语法：
insert  overwrite    [local] directory '输出文件路径' [row format delimited fields terminated by '分割符'] 查询语句

-- 说明：
overwrite ：overwrite 是覆盖原文件的数据写入
[local] ：加它，表示导出到本地，不加，则表示导出到hdfs上
'输出文件路径' ： 配合local来的，加了local，则写本地linux路径，不加，则写hdfs路径
[row format delimited fields terminated by '分割符'] ：表示文件输出的格式

-- 示例：
-- 导入到本地
1）insert overwrite local directory '/opt/module/hive/datas/export/student'  select * from student;

-- 导出到本地，并指定导出的行数据的分割符
2）insert overwrite local directory '/opt/module/hive/datas/export/student1' ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t'  select * from student;

-- 导出到hdfs上，并指定导出的行数据的分割符
3）insert overwrite directory '/user/lianzp/student2'ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' select * from student;

</code></pre><h4 id="322-方式二"><a class="anchor" href="#322-方式二">#</a> 3.2.2 方式二</h4><ul><li>hadoop 的 shell 命令</li></ul><pre><code class="language-mysql">-- 语法：
hdfs dfs -get hdfs数据的输出路径 linux输入路径
</code></pre><h4 id="323-方式三"><a class="anchor" href="#323-方式三">#</a> 3.2.3 方式三</h4><ul><li>hive 的 shell 命令</li></ul><pre><code class="language-mysql">-- 语法：
hive -e 查询语句 &gt; linux输入路径
</code></pre><h4 id="324-方式四"><a class="anchor" href="#324-方式四">#</a> 3.2.4 方式四</h4><ul><li>export 的方式</li></ul><p>说明：export 和 import 主要用于两个 hadoop 平台集群之间的 hive 表迁移。</p><pre><code class="language-mysql">-- 语法：
export table 表名 to  '文件输出路径'  -- 此路径为hdfs路径
</code></pre><h4 id="325-方式五"><a class="anchor" href="#325-方式五">#</a> 3.2.5 方式五</h4><ul><li>Sqoop 导出 -- &gt; 后续有课程单独讲解</li></ul><h3 id="33-清除表中数据"><a class="anchor" href="#33-清除表中数据">#</a> 3.3 清除表中数据</h3><ul><li>使用 truncate</li></ul><pre><code class="language-mysql">-- 语法：
truncate table 表名 ；
</code></pre><h2 id="四-查询"><a class="anchor" href="#四-查询">#</a> 四、查询</h2><h3 id="41-关键词的总结"><a class="anchor" href="#41-关键词的总结">#</a> 4.1 关键词的总结</h3><pre><code class="language-mysql">-- 建表：
1) partitioned by :分区表
2）clustered by  : 分桶表

-- 查询：
1） order by : 全排序
2） distribute by : 查询中做分区
3） sort by : 查询中每个MapReduce内部排序
4） cluster by : 查询中做分区排序

-- 窗口函数：
1) partition by :窗口函数中做分区
2) order by ：窗口函数中做排序
</code></pre><h3 id="42-sql执行的顺序"><a class="anchor" href="#42-sql执行的顺序">#</a> 4.2 sql 执行的顺序</h3><pre><code class="language-mysql">1. from ;
2. on ;
3. join ;
4. where ; -- 不能使用列的别名
5. group by ; -- 不能使用列的别名
6. having ; -- 可以使用列的别名
7. select ;
8. distinct ;
9. order by ; -- 可以使用列的别名
10. limit ; -- 可以使用列的别名

注意事项： 表名一旦使用了别名，所有的位置均需使用表的别名。
</code></pre><h3 id="43-查询语法"><a class="anchor" href="#43-查询语法">#</a> 4.3 查询语法</h3><pre><code class="language-mysql">-- 语法：
SELECT [ALL | DISTINCT] select_expr, select_expr, ...
  FROM table_reference
  [WHERE where_condition]
  [GROUP BY col_list]
  [ORDER BY col_list]
  [CLUST BY col_list
    | [DISTRIBUTE BY col_list] [SORT BY col_list]
  ]
 [LIMIT number]
 
-- 说明：
 DISTINCT ：去重；
 CLUST BY col_list  
   
 
</code></pre><h3 id="44-基本查询"><a class="anchor" href="#44-基本查询">#</a> 4.4 基本查询</h3><h4 id="441-全表和特定列查询"><a class="anchor" href="#441-全表和特定列查询">#</a> 4.4.1 全表和特定列查询</h4><pre><code class="language-mysql">-- 语法：
select * from 表名 ；  -- 全表查询
select 列名1、列名2 from 表名 ； -- 特定列查询
</code></pre><h4 id="442-别名"><a class="anchor" href="#442-别名">#</a> 4.4.2 别名</h4><pre><code class="language-mysql">定义： 在查询中紧跟列名，也可以在列名与别名之间加as；
注意事项：
1）在hive中，中文的别名使用 一对 `` 来注释；
2）as 一般可以省略 ；
3） where 、 group by 后面不能使用列的别名；
4）having 、order by 、limit 可以使用列的别名 ；
</code></pre><h4 id="443-算术运算符"><a class="anchor" href="#443-算术运算符">#</a> 4.4.3 算术运算符</h4><table><thead><tr><th style="text-align:center">运算符</th><th style="text-align:center">描述</th></tr></thead><tbody><tr><td style="text-align:center">A+B</td><td style="text-align:center">A 和 B 相加</td></tr><tr><td style="text-align:center">A-B</td><td style="text-align:center">A 减去 B</td></tr><tr><td style="text-align:center">A*B</td><td style="text-align:center">A 和 B 相乘</td></tr><tr><td style="text-align:center">A/B</td><td style="text-align:center">A 除以 B</td></tr><tr><td style="text-align:center">A%B</td><td style="text-align:center">A 对 B 取余</td></tr><tr><td style="text-align:center">A&amp;B</td><td style="text-align:center">A 和 B 按位取与</td></tr><tr><td style="text-align:center">A|B</td><td style="text-align:center">A 和 B 按位取或</td></tr><tr><td style="text-align:center">A^B</td><td style="text-align:center">A 和 B 按位取异或</td></tr><tr><td style="text-align:center">~A</td><td style="text-align:center">A 按位取反</td></tr></tbody></table><h4 id="444-常用函数"><a class="anchor" href="#444-常用函数">#</a> 4.4.4 常用函数</h4><pre><code class="language-mysql">1)  c求和 ： sum（）；
2） 求平均数 ： avg () ;
3)  求最大值 ： max（）；
4） 求最小值 ： min（）；
5） 求个数 ： count（）；

-- 说明：
1） count（）：不计算null值；
2） avg () : 计算平均数时，分母也是不计算null个数的；
3） 所以： avg (字段) = sum (字段) / count(字段)，因此我们在计算一些列的平均值时，一般使用count（*）或者是count（1）；
</code></pre><h4 id="445-where-语句"><a class="anchor" href="#445-where-语句">#</a> 4.4.5 Where 语句</h4><pre><code class="language-mysql">1） 条件的筛选；
2） 紧跟from后面。
</code></pre><h4 id="446-比较运算符"><a class="anchor" href="#446-比较运算符">#</a> 4.4.6 比较运算符</h4><table><thead><tr><th>操作符</th><th style="text-align:center">支持的数据类型</th><th style="text-align:left">描述</th></tr></thead><tbody><tr><td>A=B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">如果 A 等于 B 则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A&lt;=&gt;B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">如果 A 和 B 都为 NULL，则返回 TRUE，如果一边为 NULL，返回 False</td></tr><tr><td>A&lt;&gt;B, A!=B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">A 或者 B 为 NULL 则返回 NULL；如果 A 不等于 B，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A&lt;B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">A 或者 B 为 NULL，则返回 NULL；如果 A 小于 B，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A&lt;=B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">A 或者 B 为 NULL，则返回 NULL；如果 A 小于等于 B，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A&gt;B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">A 或者 B 为 NULL，则返回 NULL；如果 A 大于 B，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A&gt;=B</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">A 或者 B 为 NULL，则返回 NULL；如果 A 大于等于 B，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A [NOT] BETWEEN B AND C</td><td style="text-align:center">基本数据类型</td><td style="text-align:left">如果 A，B 或者 C 任一为 NULL，则结果为 NULL。如果 A 的值大于等于 B 而且小于或等于 C，则结果为 TRUE，反之为 FALSE。如果使用 NOT 关键字则可达到相反的效果。</td></tr><tr><td>A IS NULL</td><td style="text-align:center">所有数据类型</td><td style="text-align:left">如果 A 等于 NULL，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>A IS NOT NULL</td><td style="text-align:center">所有数据类型</td><td style="text-align:left">如果 A 不等于 NULL，则返回 TRUE，反之返回 FALSE</td></tr><tr><td>IN (数值 1, 数值 2)</td><td style="text-align:center">所有数据类型</td><td style="text-align:left">使用 IN 运算显示列表中的值</td></tr><tr><td>A [NOT] LIKE B</td><td style="text-align:center">STRING 类型</td><td style="text-align:left">B 是一个 SQL 下的简单正则表达式，也叫通配符模式，如果 A 与其匹配的话，则返回 TRUE；反之返回 FALSE。B 的表达式说明如下：‘x%’表示 A 必须以字母‘x’开头，‘% x’表示 A 必须以字母’x’结尾，而‘% x%’表示 A 包含有字母’x’, 可以位于开头，结尾或者字符串中间。如果使用 NOT 关键字则可达到相反的效果。</td></tr><tr><td>A RLIKE B, A REGEXP B</td><td style="text-align:center">STRING 类型</td><td style="text-align:left">B 是基于 java 的正则表达式，如果 A 与其匹配，则返回 TRUE；反之返回 FALSE。匹配使用的是 JDK 中的正则表达式接口实现的，因为正则也依据其中的规则。例如，正则表达式必须和整个字符串 A 相匹配，而不是只需与其字符串匹配。</td></tr></tbody></table><h4 id="447-like-和-rlike"><a class="anchor" href="#447-like-和-rlike">#</a> 4.4.7 like 和 rlike</h4><pre><code class="language-mysql">1） like
% : 代表零个或者是多个字符（即时任意字符）	
_ : 代表一个字符；
\ :  转义字符；

2） Rlike ：后面紧跟随正则表达式
 \ : 转义字符，即屏蔽特殊字符的含义：\$;
 ^ : 从头开始匹配，如：name  rlike ^a  : 表示以a开头的name
 $ : 匹配结尾 ，如  name Rlike t$ ：匹配以t结尾的name
 * ： 0-n 个 ，如 name rlike a* : 匹配 0-n a的name
[] : 表示范围，如 [0-9,a-z]:匹配0-9或者是a-z都可以。
</code></pre><h4 id="448-逻辑运算符"><a class="anchor" href="#448-逻辑运算符">#</a> 4.4.8 逻辑运算符</h4><table><thead><tr><th>操作符</th><th>含义</th></tr></thead><tbody><tr><td>AND</td><td>逻辑并</td></tr><tr><td>OR</td><td>逻辑或</td></tr><tr><td>NOT</td><td>逻辑否</td></tr></tbody></table><h3 id="45-分组"><a class="anchor" href="#45-分组">#</a> 4.5 分组</h3><h4 id="451-group-by"><a class="anchor" href="#451-group-by">#</a> 4.5.1 group by</h4><figure class="highlight sql"><figcaption data-lang="SQL"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token operator">-</span> 常和聚合函数在一起<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token operator">-</span> 出现在 <span class="token keyword">group</span> <span class="token keyword">by</span> 中的字段可以出现在 <span class="token keyword">select</span>中，也可以不出现，</pre></td></tr><tr><td data-num="3"></td><td><pre>  但是出现在 <span class="token keyword">select</span>中字段（除函数和常量外）必须在<span class="token keyword">group</span> <span class="token keyword">by</span> 出现过的字段。</pre></td></tr></table></figure><h4 id="451-having"><a class="anchor" href="#451-having">#</a> 4.5.1 Having</h4><pre><code class="language-mysql"> having  与 where 的不同
1） where 后面不能写分组函数，但是 having 可以 ；
2） having 只用于 Group by 分组统计语句；
</code></pre><h3 id="46-join"><a class="anchor" href="#46-join">#</a> 4.6 join</h3><pre><code class="language-mysql">-- 说明：
1） 常见的7种 join 要会写；
2） 不支持非等值连接；
3） 支持满外连接 ： full join ;
4)  关于主表和从表： -- 左右外连接，主表数据全要，从表数据只要交集的部分。
 	左外连接 ： 左边为主表，右边为从表 ；
	右外连接 ： 右边为主表，左边为从表。
</code></pre><h3 id="47-排序"><a class="anchor" href="#47-排序">#</a> 4.7 排序</h3><h4 id="471-全局排序-order-by"><a class="anchor" href="#471-全局排序-order-by">#</a> 4.7.1 全局排序 ： Order By</h4><pre><code class="language-mysql">1)  全局排序，只能有一个Reducer ；
2） DESC : 降序 ；
3)  ASC : 升序（'默认值'）；
4） Order by 子句必须在SELECT语句的结尾 ；
5)  排序的字段可以是多个；
示例：
select id , name ,sal from emp order by sal desc ,name asc ;
-- 先按照薪水降序，薪水相同的，则按照名字进行升序排序；
</code></pre><h4 id="472-mapreduce内部排序-sort-by"><a class="anchor" href="#472-mapreduce内部排序-sort-by">#</a> 4.7.2 mapreduce 内部排序 ：sort by</h4><pre><code class="language-mysql">1)  理解：
理解为在 reduce 中进行排序。所以一般是需要有多个 reduce 才有作用，是在每个reduce中进行排序，属于局部排序，而不是全局排序。
2） 使用场景：
当数据量很大时，不要进行全局排序，只需要进行局部排序。
3） 一般不单独使用，因为无法控制什么样的数据进入同一个 reduce 中；
-- 一般配合distribute by 使用，分区排序就是指定什么样的数据会进入同一个reduce中。
4） 单独使用时，进入同一个 reduce 任务中的数据是随机的。 -- 伪随机，就是每次计算的结果是一样的，但是进入每一个reduce 中的数据是随机的。

-- 示例：
1） 设置reducer的个数：
set mapreduce.job.reduces=3; -- 设置reduce个数为3
2） 根据部门编号降序查看员工信息 ： 
select * from emp sort by deptno desc;
-- 此时生成3个结果文件，并且每个结果文件中均是按照deptno 进行降序排序。
</code></pre><h4 id="473-分区排序-distribute-by"><a class="anchor" href="#473-分区排序-distribute-by">#</a> 4.7.3 分区排序 ： distribute by</h4><pre><code class="language-mysql">1. 理解 ： 类似在 MapReduce 中的自定义分区（partition ）;
2. 一般就是配合 sort by 使用；
3. 同样，在使用的时候，不能是一个reduce，需要多个reduce；
4. 什么样的数据会进行同一个reduce 呢 ？
  1）首先，这个分区不是很智能，使用的方式是：分区的字段的 （ hashcode  % reduce的个数 ），计算值相等的，则进入同一个reduce；
  2）不会使用toString方式进行分区。
5. distribute by 必须写在sort by 的前面；
6. tez 引擎会进行reduce的优化，即假设设置为3个reduce，但是运行时有可能是2个reduce，所以验证时032，需使用mr引擎。-- set hive.execution.engine=mr;

-- 示例：
insert overwrite local directory '/opt/module/hive/datas/distribute-result' select * from emp distribute by deptno sort by empno desc; -- 假设 reduce = 3 ；
-- 先按照deptno进行分区(m = hashcode(deptno) % 3 , m值相等的数据进入同一个分区），然后在分区内进行局部排序，最后将查询的结果导出到本地指定的一个文件中。
</code></pre><h4 id="474-cluster-by"><a class="anchor" href="#474-cluster-by">#</a> 4.7.4 Cluster By</h4><pre><code class="language-mysql">1. 理解 ：当distribute by 和 sort by 的字段相同时，可以使用Cluster by 进行替代；
2. 不能指定排序的顺序，只能是升序。

-- 示例：
方式一 ：select * from emp  cluster by deptno ;
方式二 ：select * from emp distribute by deptno sort by deptno ;
-- 方式一和方式二是等价的。
</code></pre><h2 id="五-分区表和分桶表"><a class="anchor" href="#五-分区表和分桶表">#</a> 五、 分区表和分桶表</h2><h3 id="51-分区表"><a class="anchor" href="#51-分区表">#</a> 5.1 分区表</h3><p>分区表的解析：</p><pre><code class="language-mysql">-- 理解：
1） Hive 中的分区就是分目录 ；
2） 分区表对应一个hdfs文件系统的独立的文件；
3） 实际上是把一个大的数据集根据业务的需求分割成多个小的数集；
4） 在查询时，通过where语句进行条件筛选，指定数据在哪个分区内，提高查询的效率；
5)  同时用于解决数据倾斜的问题。
</code></pre><h4 id="511-分区表的基本操作"><a class="anchor" href="#511-分区表的基本操作">#</a> 5.1.1 分区表的基本操作</h4><ol><li>创建分区表</li></ol><pre><code class="language-mysql">-- 语法：
create table [if not exists] 表名 (
字段1 数据类型1，
字段2 数据类型2，
字段3 数据类型3，
    ...
)
partition by (字段1 数据类型1 ， 字段2 数据类型2 ，...) -- 分区，字段不能与表中属性字段相同
clustered by (字段1 ， 字段2 ， ...) -- 分桶，字段来自于表中的字段，所以是没有数据类型的。
row format delimited fields terminated by '\t'
-- 分区的字段也是可以作为表的字段使用。
-- 示例：
create table dept_partition(
deptno int ,
dname string ,
loc string
)
partition by (month string , day string) -- 二级分区，先按照月进行分区，在月中再根据day进行分区
row format delimited fields terminated by '\t'
</code></pre><ol start="2"><li>加载数据</li></ol><pre><code class="language-mysql">方式一 ： 常规加载数据 load方式
-- 语法：
load data local inpath '本地数据路径' into table 表名 partition by (字段1'***',字段2  '***')
-- 示例：
load data local inpath '/opt/module/hive/datas/2020-04-04.log' into table dept_partition partition by (month='2020-04',day='04')

方式二：上传数据后修复 -- 因为单独上传数据到指定的目录下，hive是不能自动读取，需要进行数据的修复
第一步： 根据分区字段的信息，创建文件夹，此文件夹与表的路径相同
第二步： 本地的数据上传到指定的目录下，使用 【 hdfs dfs -put 本地数据路径 hdfs文件路径 】
第三步： 进行数据的修复 ，使用语句 【msck repair table 表名】

方式三： 上传数据后添加分区的方式 -- 该方式使用的情况最多
第一步和第二步与方式二完全相同；
第三步： 执行添加分区的方式
alter table 表名 add partition (字段1='***',字段2='***')

-- 实例：
第一步：hdfs dfs -mkdir -p  /user/hive/warehouse/dept_partition/month=2020-04/day=04 ;
第二步：hdfs dfs -put /opt/module/hive/datas/2020-04-04.logs /user/hive/warehouse/dept_partition/month=2020-04/day=04
第三步：
方式二： msck repair table dept_partition;
方式二： alter table dept_partition add partition (month='2020-04',day='04');

</code></pre><ol start="3"><li>根据分区进行查询</li></ol><pre><code class="language-mysql">-- 语法：
查询语句 + where 分区字段='***' ;

-- 示例：
select  * from dept_partition where day='04' or day='05' ；
</code></pre><ol start="4"><li>增加分区</li></ol><pre><code class="language-mysql">-- 语法：
alter table 表名 add partition (字段1=&quot;***&quot;,字段2='***')  partition  (字段1=&quot;***&quot;,字段2='***');
-- 说明：
增加多个分区时，分区与分区之间使用空格隔开。
</code></pre><ol start="5"><li>删除分区</li></ol><pre><code class="language-mysql">-- 语法：
alter table 表名 drop partition (字段1=&quot;***&quot;,字段2='***') , partition  (字段1=&quot;***&quot;,字段2='***');
-- 说明：
删除的多个分区之间使用','进行分隔。
</code></pre><ol start="6"><li>查看多个分区</li></ol><pre><code class="language-mysql">-- 语法：
show partitions 表名；
</code></pre><h4 id="512-动态分区调整"><a class="anchor" href="#512-动态分区调整">#</a> 5.1.2 动态分区调整</h4><pre><code class="language-mysql">-- 理解：为什么要使用动态分区呢？
在实际的情况中，我们的数据通过前端收集过来以后，一般都是存储在hdfs上面，我们只需要通过 insert + 查询语句的方式将数据导入到指定的数据表，在此时需要指定按照什么字段进行分区。
</code></pre><ol><li>前期的准备工作 --<strong> 开启动态分区参数设置</strong></li></ol><pre><code class="language-mysql">（1）开启动态分区功能（默认true，开启）
hive.exec.dynamic.partition=true

（2）设置为非严格模式（动态分区的模式，默认strict，表示必须指定至少一个分区为静态分区，nonstrict模式表示允许所有的分区字段都可以使用动态分区。）
hive.exec.dynamic.partition.mode=nonstrict

（3）在所有执行MR的节点上，最大一共可以创建多少个动态分区。默认1000
hive.exec.max.dynamic.partitions=1000

（4）在每个执行MR的节点上，最大可以创建多少个动态分区。该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即day字段有365个值，那么该参数就需要设置成大于365，如果使用默认值100，则会报错。
hive.exec.max.dynamic.partitions.pernode=100

（5）整个MR Job中，最大可以创建多少个HDFS文件。默认100000
hive.exec.max.created.files=100000

（6）当有空分区生成时，是否抛出异常。一般不需要设置。默认false
hive.error.on.empty.partition=false
</code></pre><ol start="2"><li>实操</li></ol><pre><code class="language-mysql">-- 需求：将dept表中的数据按照地区（loc字段），插入到目标表dept——partition的分区中：

1）创建目标dept_partition表
create table dept_partition (
id int,
name string
)
partitioned by (loc string)
row format delimited fields terminated by '\t';

2) 插入数据
insert into table dept_partition partition (loc) select deptno , name, loc from dept; 

</code></pre><h3 id="52-分桶表"><a class="anchor" href="#52-分桶表">#</a> 5.2 分桶表</h3><pre><code class="language-mysql">-- 理解：为什么会有分桶表？或者说分桶表是用来解决什么问题呢？
1）提供一个数据隔离和优化查询的便利方式，如当某一个表或者是某一个分区的数据量特别大时，通过分桶的方式，可以将数据再进行分解成多个模块，这样在进行查询时，提供了查询的效率。 -- 说明查询的分区操作时自动的。
2）什么样的数据会进入同一个桶中呢？
通过 （分桶字段的）hashcode % 桶的个数 ，取模数相等的进入同一个桶内。（不适用于TEZ引擎）
3）分桶表针对的是数据文件；而分区是针对数据路径。                                        
</code></pre><p>创建分桶表</p><pre><code class="language-mysql">在创建表单时，增加如下语法子句：
******
clustered by (字段1，字段2，***) into num buckets;
******
-- 说明：
1） 字段1-n : 均来自于表中的字段；
2） num : 表示分桶的个数。
</code></pre><h3 id="53-抽样查询"><a class="anchor" href="#53-抽样查询">#</a> 5.3 抽样查询</h3><pre><code class="language-mysql">-- 理解：
当数据特别大的时候，我们不要通过查询所有的数据来获取数据的情况。
例如：工厂生产的产品，OQC 是按比例抽样来判定产品的良率。

-- 示例：
select *  from dept tablesample (bucket 1 out of 4 on id);
-- 说明：
on :表示依据哪个字段进行抽样；
4 ： 表示按照on后面的字段将数据分成几份。
1 ： 则表示第一份，2 表示第二份。

如上只是抽样方法中非常简单的一种，还有很多种方式。
</code></pre><h2 id="六-函数-重点"><a class="anchor" href="#六-函数-重点">#</a> 六 、函数 （重点）</h2><h3 id="61-常用函数"><a class="anchor" href="#61-常用函数">#</a> 6.1 常用函数</h3><p>日期函数：</p><pre><code class="language-mysql">1） unix_timestamp : 返回当前或指定的时间戳；
SELECT  unix_timestamp(&quot;2020-05-02 11:22:00&quot;); ==&gt;1588418520
2） from_unixtime : 将时间戳转化为日期格式
SELECT FROM_unixtime(1588418520); ==&gt; 2020-05-02 11:22:00
3) current_date : 当前日期
4）current_timestamp: 当前日期 + 时间；
5）to_date : 获取日期部分
6）year/month/day/hour/minute/second() : 获取年、月、日、小时、分、秒
7）weekofyear(): 当前时间是一年中的第几周
8）dayofmonth(): 当前时间是一个月中的第几天
9）months_between() : 两个日期间的月份
10) datediff() : 两个日期相差的天数
11) add_months：日期加减月
12) date_add：日期加天数
13) date_sub：日期减天数
14) last_day: 日期的当月的最后一天
</code></pre><p>取整函数</p><pre><code class="language-mysql">1) round： 四舍五入
2) ceil：  向上取整
3) floor： 向下取整
</code></pre><p>字符串函数</p><pre><code class="language-mysql">1）upper： 转大写
2）lower： 转小写
3）length： 长度
4）trim：  前后去空格
5）lpad： 向左补齐，到指定长度
6）rpad：  向右补齐，到指定长度
7）regexp_replace： SELECT regexp_replace('100-200', '(\\d+)', 'num') ；
	使用正则表达式匹配目标字符串，匹配成功后替换！
</code></pre><p>集合操作</p><pre><code class="language-mysql">1） size： 集合中元素的个数
2） map_keys： 返回map中的key
3） map_values: 返回map中的value
4） array_contains: 判断array中是否包含某个元素
5） sort_array： 将array中的元素排序
</code></pre><h3 id="62-系统内置函数"><a class="anchor" href="#62-系统内置函数">#</a> 6.2 系统内置函数</h3><pre><code class="language-mysql">1） 查看系统自带的函数
show functions;

2) 查询函数的用法
desc function extended 函数名
</code></pre><h3 id="63-常用的内置函数"><a class="anchor" href="#63-常用的内置函数">#</a> 6.3 常用的内置函数</h3><h4 id="631-空字段赋值-nvl"><a class="anchor" href="#631-空字段赋值-nvl">#</a> 6.3.1 空字段赋值 NVL</h4><pre><code class="language-mysql">-- 语法：
nvl(value,default_value)

-- 说明：
1）如果value 为null，则返回default_value ，否则返回vaule；
2）如果两个值（value , default_value）均为null，则返回null；
</code></pre><h4 id="632-case-when"><a class="anchor" href="#632-case-when">#</a> 6.3.2 CASE WHEN</h4><pre><code class="language-mysql">-- 示例：
select 
  dept_id,
  sum(case sex when '男' then 1 else 0 end) male_count,
  sum(case sex when '女' then 1 else 0 end) female_count
from 
  emp_sex
group by
  dept_id;
  
  /*  解读：
  1.按照dept_id 进行分组，同一组的数据先进行计算；
  2.假设dept_id=10的数据有10条，则10数据分别在sum函数中进行计算，计算完成以后得出一个结果；
  3.一组数据最后得到一条数据结果。
  */
</code></pre><h4 id="633-行转列"><a class="anchor" href="#633-行转列">#</a> 6.3.3 行转列</h4><pre><code class="language-mysql">-- 相关函数
1） concat('str1','str2','str3',...) : 表示将str1/str2/str3... 依次进行连接，str1/str2/str3... 可以说任何数据类型；
-- 示例：SELECT  concat('132','-','456'); ==&gt; 132-456

2) concat_ws('连接符'，'str1','str2',...) : 表示使用'连接符'将str1/str2...依次进行连接，str1/str2...只能是字符串或者是字符串数组。
-- 示例：
SELECT  concat_ws('-','java','maven'); ==&gt; java-maven;
SELECT  concat_ws(null,'java','maven'); ==&gt; null -- 当连接符为null时，结果返回null
SELECT  concat_ws('.', 'www', array('facebook', 'com')) ；==&gt; www.facebook.com

3） collect_set(col) : 函数只接受基本数据类型，它的主要作用是将某字段的值进行去重汇总，产生array类型字段
-- 示例：
SELECT COLLECT_set(deptno) from emp; ==&gt;[20,30,10]

</code></pre><h4 id="634-列转行"><a class="anchor" href="#634-列转行">#</a> 6.3.4 列转行</h4><pre><code class="language-mysql">-- 语法：
lateral view explode (split(字段，分割符)) 表名 as 列名
-- 说明：
lateral view : 侧写；
explode(): 将指定的集合拆解分成多行 -- 炸裂
split(字段，分割符) : 将指定的字符串按照分割符封装成一个集合。

-- 示例：
SELECT movie,category_name 
FROM movie_info 
lateral VIEW
explode(split(category,&quot;,&quot;)) movie_info_tmp  AS category_name ; -- categor_name 为炸裂的列名，move_info_tmp为侧写的表名

</code></pre><p>![image-20200630212310025](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200630212310.png)</p><p>![image-20200630212550900](<span class="exturl" data-url="aHR0cHM6Ly9saWFuLXpwLm9zcy1jbi1zaGVuemhlbi5hbGl5dW5jcy5jb20vcGlj">https://lian-zp.oss-cn-shenzhen.aliyuncs.com/pic</span> GO/20200630212551.png)</p><h3 id="64-开窗函数"><a class="anchor" href="#64-开窗函数">#</a> 6.4 开窗函数</h3><pre><code class="language-mysql">相关函数说明：开窗函数是为每一条数据进行开窗
1） over() : 单独使用此函数，默认的窗口大小为结果集的大小。
2） partition by : 在窗口函数中进行分区
 	over(partition by 字段) ：对结果集内进行分区，每条数据的开窗大小为该结果集中分区集的大小。
3) over( order by 字段) ： 在窗口函数中只用到了order by 排序时，也会对每条数据进行开一个窗口，默认的开窗大小为：从结果集的开始位置到当前处理数据的位置。
-- 实例：
-- 1.查询在2017年4月份购买过的顾客及总人数
-- 解析，顾客全部要，多个顾客，多行，人数为一个值，一行，则是需要进行开窗，因为不是一一匹配的。
        SELECT  name ,
        COUNT(*)   OVER () `人数`
        from business 
        WHERE  SUBSTRING(orderdate,1,7)='2017-04' 
        group by name ;

-- 2.查询顾客的购买明细及月购买总额
    SELECT name ,orderdate ,cost ,
    sum (cost) over(partition by MONTH (orderdate))
    from business;
    
-- 3.上述的场景, 将每个顾客的cost按照日期进行累加
    SELECT name ,orderdate ,cost ,
    sum (cost) over(partition by name order by orderdate)
    from business;
    
4） CURRENT ROW：当前行
	n PRECEDING：往前n行数据
	n FOLLOWING：往后n行数据
5）UNBOUNDED：起点，
	UNBOUNDED PRECEDING 表示从前面的起点 
    UNBOUNDED FOLLOWING 表示到后面的终点
6）LAG(col,n,default_val)：往前第n行数据
7）LEAD(col,n, default_val)：往后第n行数据
8）NTILE(n)：把有序窗口的行分发到指定数据的组中，各个组有编号，编号从1开始，对于每一行，NTILE返回此行所属的组的编号。注意：n必须为int类型。
示例：
-- 需求：查询前20%时间的订单信息
select * from (
    select name,orderdate,cost, ntile(5) over(order by orderdate) sorted
    from business
) t
where sorted = 1;
</code></pre><h3 id="65-rank"><a class="anchor" href="#65-rank">#</a> 6.5 Rank</h3><pre><code class="language-mysql">-- 函数说明
1) RANK() 排序相同时会重复，总数不会变; 
   -- 1 2 2 4 5 5 7
2) DENSE_RANK() 排序相同时会重复，总数会减少; 
  -- 1 2 2 3 3 4 4 5
3) ROW_NUMBER() 会根据顺序计算。
  -- 1 2 3 4 5 6 
</code></pre><h3 id="66-自定义函数"><a class="anchor" href="#66-自定义函数">#</a> 6.6 自定义函数</h3><pre><code class="language-mysql">自定函数的分类：
1） UDF（User-Defined-Function） -- 一进一出

2） UDAF（User-Defined Aggregation Function） -- 聚集函数，多进一出
	类似于：count/max/min
	
3） UDTF（User-Defined Table-Generating Functions） -- 一进多出
	如lateral view explode()
</code></pre><h4 id="661-自定义udf函数"><a class="anchor" href="#661-自定义udf函数">#</a> 6.6.1 自定义 UDF 函数</h4><ol><li>需求：UDF 实现计算给定字符串的长度</li></ol><pre><code class="language-mysql">示例：
select my_len(&quot;abcd&quot;); ==&gt; 4 
</code></pre><ol start="2"><li>创建一个 Maven 工程</li><li>导入依赖</li></ol><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token generics"><span class="token punctuation">&lt;</span>dependencies<span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="2"></td><td><pre>		<span class="token generics"><span class="token punctuation">&lt;</span>dependency<span class="token punctuation">></span></span></pre></td></tr><tr><td data-num="3"></td><td><pre>			<span class="token generics"><span class="token punctuation">&lt;</span>groupId<span class="token punctuation">></span></span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hive<span class="token operator">&lt;</span><span class="token operator">/</span>groupId<span class="token operator">></span></pre></td></tr><tr><td data-num="4"></td><td><pre>			<span class="token generics"><span class="token punctuation">&lt;</span>artifactId<span class="token punctuation">></span></span>hive<span class="token operator">-</span>exec<span class="token operator">&lt;</span><span class="token operator">/</span>artifactId<span class="token operator">></span></pre></td></tr><tr><td data-num="5"></td><td><pre>			<span class="token generics"><span class="token punctuation">&lt;</span>version<span class="token punctuation">></span></span><span class="token number">3.1</span><span class="token number">.2</span><span class="token operator">&lt;</span><span class="token operator">/</span>version<span class="token operator">></span></pre></td></tr><tr><td data-num="6"></td><td><pre>		<span class="token operator">&lt;</span><span class="token operator">/</span>dependency<span class="token operator">></span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token operator">&lt;</span><span class="token operator">/</span>dependencies<span class="token operator">></span></pre></td></tr></table></figure><ol start="4"><li>创建一个类继承于 GenericUDF</li></ol><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>lianzp<span class="token punctuation">.</span>hive</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span></span><span class="token class-name">UDFArgumentException</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span></span><span class="token class-name">UDFArgumentLengthException</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span></span><span class="token class-name">UDFArgumentTypeException</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span></span><span class="token class-name">HiveException</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>generic<span class="token punctuation">.</span></span><span class="token class-name">GenericUDF</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span></span><span class="token class-name">ObjectInspector</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>primitive<span class="token punctuation">.</span></span><span class="token class-name">PrimitiveObjectInspectorFactory</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token comment">/**</span></pre></td></tr><tr><td data-num="12"></td><td><pre> * 自定义 UDF 函数，需要继承 GenericUDF 类</pre></td></tr><tr><td data-num="13"></td><td><pre> * 需求：计算指定字符串的长度</pre></td></tr><tr><td data-num="14"></td><td><pre> */</pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyStringLength</span> <span class="token keyword">extends</span> <span class="token class-name">GenericUDF</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token comment">/**</span></pre></td></tr><tr><td data-num="17"></td><td><pre>     *</pre></td></tr><tr><td data-num="18"></td><td><pre>     * @param arguments 输入参数类型的鉴别器对象</pre></td></tr><tr><td data-num="19"></td><td><pre>     * @return 返回值类型的鉴别器对象</pre></td></tr><tr><td data-num="20"></td><td><pre>     * @throws UDFArgumentException</pre></td></tr><tr><td data-num="21"></td><td><pre>     */</pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token annotation punctuation">@Override</span></pre></td></tr><tr><td data-num="23"></td><td><pre>    <span class="token keyword">public</span> <span class="token class-name">ObjectInspector</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token class-name">ObjectInspector</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arguments<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">UDFArgumentException</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token comment">// 判断输入参数的个数</span></pre></td></tr><tr><td data-num="25"></td><td><pre>        <span class="token keyword">if</span><span class="token punctuation">(</span>arguments<span class="token punctuation">.</span>length <span class="token operator">!=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="26"></td><td><pre>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">UDFArgumentLengthException</span><span class="token punctuation">(</span><span class="token string">"Input Args Length Error!!!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        <span class="token comment">// 判断输入参数的类型</span></pre></td></tr><tr><td data-num="29"></td><td><pre>        <span class="token keyword">if</span><span class="token punctuation">(</span><span class="token operator">!</span>arguments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">getCategory</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">equals</span><span class="token punctuation">(</span><span class="token class-name">ObjectInspector<span class="token punctuation">.</span>Category</span><span class="token punctuation">.</span>PRIMITIVE<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="30"></td><td><pre>            <span class="token keyword">throw</span> <span class="token keyword">new</span> <span class="token class-name">UDFArgumentTypeException</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token string">"Input Args Type Error!!!"</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        <span class="token comment">// 函数本身返回值为 int，需要返回 int 类型的鉴别器对象</span></pre></td></tr><tr><td data-num="33"></td><td><pre>        <span class="token keyword">return</span> <span class="token class-name">PrimitiveObjectInspectorFactory</span><span class="token punctuation">.</span>javaIntObjectInspector<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="35"></td><td><pre></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token comment">/**</span></pre></td></tr><tr><td data-num="37"></td><td><pre>     * 函数的逻辑处理</pre></td></tr><tr><td data-num="38"></td><td><pre>     * @param arguments 输入的参数</pre></td></tr><tr><td data-num="39"></td><td><pre>     * @return 返回值</pre></td></tr><tr><td data-num="40"></td><td><pre>     * @throws HiveException</pre></td></tr><tr><td data-num="41"></td><td><pre>     */</pre></td></tr><tr><td data-num="42"></td><td><pre>    <span class="token annotation punctuation">@Override</span></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token keyword">public</span> <span class="token class-name">Object</span> <span class="token function">evaluate</span><span class="token punctuation">(</span><span class="token class-name">DeferredObject</span><span class="token punctuation">[</span><span class="token punctuation">]</span> arguments<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">HiveException</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="44"></td><td><pre>       <span class="token keyword">if</span><span class="token punctuation">(</span>arguments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token keyword">null</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="45"></td><td><pre>           <span class="token keyword">return</span> <span class="token number">0</span> <span class="token punctuation">;</span></pre></td></tr><tr><td data-num="46"></td><td><pre>       <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="47"></td><td><pre>       <span class="token keyword">return</span> arguments<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">get</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">length</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="49"></td><td><pre></pre></td></tr><tr><td data-num="50"></td><td><pre>    <span class="token annotation punctuation">@Override</span></pre></td></tr><tr><td data-num="51"></td><td><pre>    <span class="token keyword">public</span> <span class="token class-name">String</span> <span class="token function">getDisplayString</span><span class="token punctuation">(</span><span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> children<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="52"></td><td><pre>        <span class="token keyword">return</span> <span class="token string">""</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="53"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="54"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><ol start="5"><li>打成 jar 包上传到服务器 /opt/module/hive/datas/myudf.jar</li><li>将 jar 包添加到 hive 的 classpath</li></ol><pre><code class="language-mysql">add jar /opt/module/hive/datas/myudf.jar;
</code></pre><ol start="7"><li>创建临时函数与开发好的 java class 关联</li></ol><pre><code class="language-mysql">create temporary function my_len as &quot;com.lianzp.hive. MyStringLength&quot;;
</code></pre><ol start="8"><li>即可在 hql 中使用自定义的函数 my_len</li></ol><pre><code class="language-mysql">select ename,my_len(ename) ename_len from emp;
</code></pre><h4 id="662-自定义udtf函数"><a class="anchor" href="#662-自定义udtf函数">#</a> 6.6.2 自定义 UDTF 函数</h4><p>和 udf 的最大区别就是自定义函数不同。</p><figure class="highlight java"><figcaption data-lang="java"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">package</span> <span class="token namespace">com<span class="token punctuation">.</span>lianzp<span class="token punctuation">.</span>udtf</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>exec<span class="token punctuation">.</span></span><span class="token class-name">UDFArgumentException</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>metadata<span class="token punctuation">.</span></span><span class="token class-name">HiveException</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="5"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>udf<span class="token punctuation">.</span>generic<span class="token punctuation">.</span></span><span class="token class-name">GenericUDTF</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span></span><span class="token class-name">ObjectInspector</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span></span><span class="token class-name">ObjectInspectorFactory</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span></span><span class="token class-name">StructObjectInspector</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>serde2<span class="token punctuation">.</span>objectinspector<span class="token punctuation">.</span>primitive<span class="token punctuation">.</span></span><span class="token class-name">PrimitiveObjectInspectorFactory</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">ArrayList</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="12"></td><td><pre><span class="token keyword">import</span> <span class="token namespace">java<span class="token punctuation">.</span>util<span class="token punctuation">.</span></span><span class="token class-name">List</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">MyUDTF</span> <span class="token keyword">extends</span> <span class="token class-name">GenericUDTF</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="15"></td><td><pre></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">private</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> outList <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    <span class="token annotation punctuation">@Override</span></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token keyword">public</span> <span class="token class-name">StructObjectInspector</span> <span class="token function">initialize</span><span class="token punctuation">(</span><span class="token class-name">StructObjectInspector</span> argOIs<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">UDFArgumentException</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="20"></td><td><pre></pre></td></tr><tr><td data-num="21"></td><td><pre></pre></td></tr><tr><td data-num="22"></td><td><pre>        <span class="token comment">//1. 定义输出数据的列名和类型</span></pre></td></tr><tr><td data-num="23"></td><td><pre>        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">></span></span> fieldNames <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="24"></td><td><pre>        <span class="token class-name">List</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">ObjectInspector</span><span class="token punctuation">></span></span> fieldOIs <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">ArrayList</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>        <span class="token comment">//2. 添加输出数据的列名和类型</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        fieldNames<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token string">"lineToWord"</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        fieldOIs<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span><span class="token class-name">PrimitiveObjectInspectorFactory</span><span class="token punctuation">.</span>javaStringObjectInspector<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>        <span class="token keyword">return</span> <span class="token class-name">ObjectInspectorFactory</span><span class="token punctuation">.</span><span class="token function">getStandardStructObjectInspector</span><span class="token punctuation">(</span>fieldNames<span class="token punctuation">,</span> fieldOIs<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token annotation punctuation">@Override</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">process</span><span class="token punctuation">(</span><span class="token class-name">Object</span><span class="token punctuation">[</span><span class="token punctuation">]</span> args<span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">HiveException</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="35"></td><td><pre>        </pre></td></tr><tr><td data-num="36"></td><td><pre>        <span class="token comment">//1. 获取原始数据</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        <span class="token class-name">String</span> arg <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>        <span class="token comment">//2. 获取数据传入的第二个参数，此处为分隔符</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token class-name">String</span> splitKey <span class="token operator">=</span> args<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span><span class="token function">toString</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="41"></td><td><pre></pre></td></tr><tr><td data-num="42"></td><td><pre>        <span class="token comment">//3. 将原始数据按照传入的分隔符进行切分</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        <span class="token class-name">String</span><span class="token punctuation">[</span><span class="token punctuation">]</span> fields <span class="token operator">=</span> arg<span class="token punctuation">.</span><span class="token function">split</span><span class="token punctuation">(</span>splitKey<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="44"></td><td><pre></pre></td></tr><tr><td data-num="45"></td><td><pre>        <span class="token comment">//4. 遍历切分后的结果，并写出</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">String</span> field <span class="token operator">:</span> fields<span class="token punctuation">)</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre>            <span class="token comment">// 集合为复用的，首先清空集合</span></pre></td></tr><tr><td data-num="49"></td><td><pre>            outList<span class="token punctuation">.</span><span class="token function">clear</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="50"></td><td><pre></pre></td></tr><tr><td data-num="51"></td><td><pre>            <span class="token comment">// 将每一个单词添加至集合</span></pre></td></tr><tr><td data-num="52"></td><td><pre>            outList<span class="token punctuation">.</span><span class="token function">add</span><span class="token punctuation">(</span>field<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="53"></td><td><pre></pre></td></tr><tr><td data-num="54"></td><td><pre>            <span class="token comment">// 将集合内容写出</span></pre></td></tr><tr><td data-num="55"></td><td><pre>            <span class="token function">forward</span><span class="token punctuation">(</span>outList<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="56"></td><td><pre>        <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="57"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre>    <span class="token annotation punctuation">@Override</span></pre></td></tr><tr><td data-num="60"></td><td><pre>    <span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">close</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">HiveException</span> <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="61"></td><td><pre></pre></td></tr><tr><td data-num="62"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="63"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><h2 id="七-压缩与存储"><a class="anchor" href="#七-压缩与存储">#</a> 七 、 压缩与存储</h2><pre><code class="language-mysql">总结几点：
1）不同存储格式的存储文件的大小对比总结：
ORC &gt;  Parquet &gt;  textFile
2）存储文件的查询速度测试：基本相差不大。

-- 在实际的项目开发当中，hive表的数据存储格式一般选择：orc或parquet；压缩方式一般选择snappy，lzo。
</code></pre><p>压缩方式：</p><table><thead><tr><th>压缩格式</th><th>工具</th><th>算法</th><th>文件扩展名</th><th>是否可切分</th></tr></thead><tbody><tr><td>DEFLATE</td><td>无</td><td>DEFLATE</td><td>.deflate</td><td>否</td></tr><tr><td>Gzip</td><td>gzip</td><td>DEFLATE</td><td>.gz</td><td>否</td></tr><tr><td>bzip2</td><td>bzip2</td><td>bzip2</td><td>.bz2</td><td>是</td></tr><tr><td>LZO</td><td>lzop</td><td>LZO</td><td>.lzo</td><td>是</td></tr><tr><td>Snappy</td><td>无</td><td>Snappy</td><td>.snappy</td><td>否</td></tr></tbody></table><p>编码 / 解码器：</p><table><thead><tr><th>压缩格式</th><th>对应的编码 / 解码器</th></tr></thead><tbody><tr><td>DEFLATE</td><td>org.apache.hadoop.io.compress.DefaultCodec</td></tr><tr><td>gzip</td><td>org.apache.hadoop.io.compress.GzipCodec</td></tr><tr><td>bzip2</td><td>org.apache.hadoop.io.compress.BZip2Codec</td></tr><tr><td>LZO</td><td>com.hadoop.compression.lzo.LzopCodec</td></tr><tr><td>Snappy</td><td>org.apache.hadoop.io.compress.SnappyCodec</td></tr></tbody></table><p>压缩性能的比较：</p><table><thead><tr><th>压缩算法</th><th>原始文件大小</th><th>压缩文件大小</th><th>压缩速度</th><th>解压速度</th></tr></thead><tbody><tr><td>gzip</td><td>8.3GB</td><td>1.8GB</td><td>17.5MB/s</td><td>58MB/s</td></tr><tr><td>bzip2</td><td>8.3GB</td><td>1.1GB</td><td>2.4MB/s</td><td>9.5MB/s</td></tr><tr><td>LZO</td><td>8.3GB</td><td>2.9GB</td><td>49.3MB/s</td><td>74.6MB/s</td></tr></tbody></table><pre><code class="language-mysql">create table log_parquet_snappy(
track_time string,
url string,
session_id string,
referer string,
ip string,
end_user_id string,
city_id string
)
row format delimited fields terminated by '\t'
stored as parquet  -- 指明文件的存储格式
tblproperties(&quot;parquet.compression&quot;=&quot;SNAPPY&quot;); -- 指明文件的压缩方式
</code></pre></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2021-09-29 21:11:56" itemprop="dateModified" datetime="2021-09-29T21:11:56+08:00">2021-09-29</time></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="Miyazono 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="Miyazono 支付宝"><p>支付宝</p></div><div><img data-src="/images/paypal.png" alt="Miyazono 贝宝"><p>贝宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>Miyazono <i class="ic i-at"><em>@</em></i>冬樱茶</li><li class="link"><strong>本文链接：</strong> <a href="https://github.com/Mayizono/miyazono.github.io/big-data/hive/Hive%20%E5%AD%A6%E4%B9%A0/" title="Hive 学习">https://github.com/Mayizono/miyazono.github.io/big-data/hive/Hive 学习/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"></div><div class="item right"><a href="/big-data/flume/Flume/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva1.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giclxxcb6rj20zk0m8b29.jpg" title="Flume基础学习"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> Flume</span><h3>Flume基础学习</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#hive-%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.</span> <span class="toc-text">Hive 学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#01-%E4%BB%80%E4%B9%88%E6%98%AFhive"><span class="toc-number">1.0.1.</span> <span class="toc-text">0.1 什么是 hive</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#02-%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.0.2.</span> <span class="toc-text">0.2 优缺点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#03-hive%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86"><span class="toc-number">1.0.3.</span> <span class="toc-text">0.3 Hive 架构原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#04-hive%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E6%AF%94%E8%BE%83"><span class="toc-number">1.0.4.</span> <span class="toc-text">0.4 hive 与数据库的比较</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#05-tez%E5%BC%95%E6%93%8E"><span class="toc-number">1.0.5.</span> <span class="toc-text">0.5 tez 引擎</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80-hivejdbc%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">1.1.</span> <span class="toc-text">一、HiveJDBC 客户端基本操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#11-hviejdbc%E7%9A%84%E7%99%BB%E5%85%A5%E4%B8%8E%E9%80%80%E5%87%BA"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 HvieJDBC 的登入与退出</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-hive%E5%B8%B8%E7%94%A8%E7%9A%84%E4%BA%A4%E4%BA%92%E5%91%BD%E4%BB%A4"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 Hive 常用的交互命令</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-hive%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 Hive 数据类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-%E7%B1%BB%E5%9E%8B%E8%BD%AC%E5%8C%96"><span class="toc-number">1.1.4.</span> <span class="toc-text">1.4 类型转化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C-ddl%E6%95%B0%E6%8D%AE%E5%AE%9A%E4%B9%89"><span class="toc-number">1.2.</span> <span class="toc-text">二、DDL 数据定义</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#21-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 数据库操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#211%E6%98%BE%E7%A4%BA%E5%92%8C%E6%9F%A5%E8%AF%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8E%E8%A1%A8%E4%BF%A1%E6%81%AF"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">2.1.1 显示和查询数据库与表信息</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#212-%E5%88%9B%E5%BB%BA%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">2.1.2 创建数据库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#213-%E5%88%A0%E9%99%A4%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-number">1.2.1.3.</span> <span class="toc-text">2.1.3 删除数据库</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#22-%E8%A1%A8%E7%9A%84%E6%93%8D%E4%BD%9C"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 表的操作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#221-%E5%BB%BA%E8%A1%A8%E8%AF%AD%E6%B3%95"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">2.2.1 建表语法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#222-%E7%AE%A1%E7%90%86%E8%A1%A8%E4%B8%8E%E5%A4%96%E9%83%A8%E8%A1%A8"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">2.2.2 管理表与外部表</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#223-%E4%BF%AE%E6%94%B9%E8%A1%A8"><span class="toc-number">1.2.2.3.</span> <span class="toc-text">2.2.3 修改表</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89-dml-%E6%93%8D%E4%BD%9C"><span class="toc-number">1.3.</span> <span class="toc-text">三、DML 操作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#31-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%85%A5"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 数据的导入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#311-%E6%96%B9%E5%BC%8F%E4%B8%80"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">3.1.1 方式一</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#312-%E6%96%B9%E5%BC%8F%E4%BA%8C"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">3.1.2 方式二</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#313-%E6%96%B9%E5%BC%8F%E4%B8%89"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">3.1.3 方式三</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#314-%E6%96%B9%E5%BC%8F%E5%9B%9B"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">3.1.4 方式四</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#315-%E6%96%B9%E5%BC%8F%E4%BA%94"><span class="toc-number">1.3.1.5.</span> <span class="toc-text">3.1.5 方式五</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#32-%E6%95%B0%E6%8D%AE%E7%9A%84%E5%AF%BC%E5%87%BA"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 数据的导出</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#321-%E6%96%B9%E5%BC%8F%E4%B8%80"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">3.2.1 方式一</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#322-%E6%96%B9%E5%BC%8F%E4%BA%8C"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">3.2.2 方式二</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#323-%E6%96%B9%E5%BC%8F%E4%B8%89"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">3.2.3 方式三</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#324-%E6%96%B9%E5%BC%8F%E5%9B%9B"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">3.2.4 方式四</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#325-%E6%96%B9%E5%BC%8F%E4%BA%94"><span class="toc-number">1.3.2.5.</span> <span class="toc-text">3.2.5 方式五</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#33-%E6%B8%85%E9%99%A4%E8%A1%A8%E4%B8%AD%E6%95%B0%E6%8D%AE"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 清除表中数据</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B-%E6%9F%A5%E8%AF%A2"><span class="toc-number">1.4.</span> <span class="toc-text">四、查询</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#41-%E5%85%B3%E9%94%AE%E8%AF%8D%E7%9A%84%E6%80%BB%E7%BB%93"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 关键词的总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#42-sql%E6%89%A7%E8%A1%8C%E7%9A%84%E9%A1%BA%E5%BA%8F"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 sql 执行的顺序</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#43-%E6%9F%A5%E8%AF%A2%E8%AF%AD%E6%B3%95"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 查询语法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#44-%E5%9F%BA%E6%9C%AC%E6%9F%A5%E8%AF%A2"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 基本查询</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#441-%E5%85%A8%E8%A1%A8%E5%92%8C%E7%89%B9%E5%AE%9A%E5%88%97%E6%9F%A5%E8%AF%A2"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">4.4.1 全表和特定列查询</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#442-%E5%88%AB%E5%90%8D"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">4.4.2 别名</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#443-%E7%AE%97%E6%9C%AF%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">4.4.3 算术运算符</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#444-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">1.4.4.4.</span> <span class="toc-text">4.4.4 常用函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#445-where-%E8%AF%AD%E5%8F%A5"><span class="toc-number">1.4.4.5.</span> <span class="toc-text">4.4.5 Where 语句</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#446-%E6%AF%94%E8%BE%83%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-number">1.4.4.6.</span> <span class="toc-text">4.4.6 比较运算符</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#447-like-%E5%92%8C-rlike"><span class="toc-number">1.4.4.7.</span> <span class="toc-text">4.4.7 like 和 rlike</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#448-%E9%80%BB%E8%BE%91%E8%BF%90%E7%AE%97%E7%AC%A6"><span class="toc-number">1.4.4.8.</span> <span class="toc-text">4.4.8 逻辑运算符</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#45-%E5%88%86%E7%BB%84"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.5 分组</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#451-group-by"><span class="toc-number">1.4.5.1.</span> <span class="toc-text">4.5.1 group by</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#451-having"><span class="toc-number">1.4.5.2.</span> <span class="toc-text">4.5.1 Having</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#46-join"><span class="toc-number">1.4.6.</span> <span class="toc-text">4.6 join</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#47-%E6%8E%92%E5%BA%8F"><span class="toc-number">1.4.7.</span> <span class="toc-text">4.7 排序</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#471-%E5%85%A8%E5%B1%80%E6%8E%92%E5%BA%8F-order-by"><span class="toc-number">1.4.7.1.</span> <span class="toc-text">4.7.1 全局排序 ： Order By</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#472-mapreduce%E5%86%85%E9%83%A8%E6%8E%92%E5%BA%8F-sort-by"><span class="toc-number">1.4.7.2.</span> <span class="toc-text">4.7.2 mapreduce 内部排序 ：sort by</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#473-%E5%88%86%E5%8C%BA%E6%8E%92%E5%BA%8F-distribute-by"><span class="toc-number">1.4.7.3.</span> <span class="toc-text">4.7.3 分区排序 ： distribute by</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#474-cluster-by"><span class="toc-number">1.4.7.4.</span> <span class="toc-text">4.7.4 Cluster By</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94-%E5%88%86%E5%8C%BA%E8%A1%A8%E5%92%8C%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">1.5.</span> <span class="toc-text">五、 分区表和分桶表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#51-%E5%88%86%E5%8C%BA%E8%A1%A8"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 分区表</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#511-%E5%88%86%E5%8C%BA%E8%A1%A8%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">5.1.1 分区表的基本操作</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#512-%E5%8A%A8%E6%80%81%E5%88%86%E5%8C%BA%E8%B0%83%E6%95%B4"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">5.1.2 动态分区调整</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#52-%E5%88%86%E6%A1%B6%E8%A1%A8"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 分桶表</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#53-%E6%8A%BD%E6%A0%B7%E6%9F%A5%E8%AF%A2"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 抽样查询</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD-%E5%87%BD%E6%95%B0-%E9%87%8D%E7%82%B9"><span class="toc-number">1.6.</span> <span class="toc-text">六 、函数 （重点）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#61-%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 常用函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#62-%E7%B3%BB%E7%BB%9F%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 系统内置函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#63-%E5%B8%B8%E7%94%A8%E7%9A%84%E5%86%85%E7%BD%AE%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.3.</span> <span class="toc-text">6.3 常用的内置函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#631-%E7%A9%BA%E5%AD%97%E6%AE%B5%E8%B5%8B%E5%80%BC-nvl"><span class="toc-number">1.6.3.1.</span> <span class="toc-text">6.3.1 空字段赋值 NVL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#632-case-when"><span class="toc-number">1.6.3.2.</span> <span class="toc-text">6.3.2 CASE WHEN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#633-%E8%A1%8C%E8%BD%AC%E5%88%97"><span class="toc-number">1.6.3.3.</span> <span class="toc-text">6.3.3 行转列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#634-%E5%88%97%E8%BD%AC%E8%A1%8C"><span class="toc-number">1.6.3.4.</span> <span class="toc-text">6.3.4 列转行</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#64-%E5%BC%80%E7%AA%97%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.4.</span> <span class="toc-text">6.4 开窗函数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#65-rank"><span class="toc-number">1.6.5.</span> <span class="toc-text">6.5 Rank</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#66-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.6.</span> <span class="toc-text">6.6 自定义函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#661-%E8%87%AA%E5%AE%9A%E4%B9%89udf%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.6.1.</span> <span class="toc-text">6.6.1 自定义 UDF 函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#662-%E8%87%AA%E5%AE%9A%E4%B9%89udtf%E5%87%BD%E6%95%B0"><span class="toc-number">1.6.6.2.</span> <span class="toc-text">6.6.2 自定义 UDTF 函数</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83-%E5%8E%8B%E7%BC%A9%E4%B8%8E%E5%AD%98%E5%82%A8"><span class="toc-number">1.7.</span> <span class="toc-text">七 、 压缩与存储</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li class="active"><a href="/big-data/hive/Hive%20%E5%AD%A6%E4%B9%A0/" rel="bookmark" title="Hive学习">Hive学习</a></li><li><a href="/big-data/hive/HQL%E7%BB%83%E4%B9%A0%E9%A2%98/" rel="bookmark" title="HQL练习题">HQL练习题</a></li><li><a href="/big-data/hive/HQL%E4%B8%8A%E7%BA%BF%E4%BA%BA%E6%95%B0/" rel="bookmark" title="HQL之同时在线人数">HQL之同时在线人数</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="Miyazono" data-src="/images/avatar.jpg"><p class="name" itemprop="name">Miyazono</p><div class="description" itemprop="description"></div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">25</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">6</span> <span class="name">分类</span></a></div></nav><div class="social"><a href="https://github.com/amehime" title="https:&#x2F;&#x2F;github.com&#x2F;amehime" class="item github"><i class="ic i-github"></i></a> <span class="exturl item twitter" data-url="aHR0cHM6Ly90d2l0dGVyLmNvbS9hbWVoaW1l" title="https:&#x2F;&#x2F;twitter.com&#x2F;amehime"><i class="ic i-twitter"></i></span> <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL3Blb3BsZS9ydXJpc216aw==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;rurismzk"><i class="ic i-zhihu"></i></span> <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvdXNlci9ob21lP2lkPTEyODg2ODIz" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;user&#x2F;home?id&#x3D;12886823"><i class="ic i-cloud-music"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20vYW1laGltZQ==" title="https:&#x2F;&#x2F;weibo.com&#x2F;amehime"><i class="ic i-weibo"></i></span> <span class="exturl item about" data-url="aHR0cHM6Ly9hYm91dC5tZS9hbWVoaW1l" title="https:&#x2F;&#x2F;about.me&#x2F;amehime"><i class="ic i-address-card"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>friends</a></li><li class="item"><a href="/mikutap/" rel="section"><i class="ic i-star"></i>mikutap</a></li></ul></div></div></div><ul id="quick"><li class="prev pjax"></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/kafka/" title="分类于 Kafka">Kafka</a></div><span><a href="/big-data/kafka/Kafka%E6%80%BB%E7%BB%93/" title="Kafka学习">Kafka学习</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/8.Spark%E5%86%85%E6%A0%B8/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/4.%20Spark%E5%AE%9E%E6%88%98%E9%A1%B9%E7%9B%AE%E2%80%94%E2%80%94%E7%94%B5%E5%95%86%E6%8C%87%E6%A0%87%E7%BB%9F%E8%AE%A1/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/big-data/" title="分类于 大数据">大数据</a> <i class="ic i-angle-right"></i> <a href="/categories/big-data/flume/" title="分类于 Flume">Flume</a></div><span><a href="/big-data/flume/Flume%E7%BB%83%E4%B9%A0%E9%A2%98/" title="Flume练习题">Flume练习题</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/%E6%A8%A1%E5%9D%97%E6%80%BB%E7%BB%93/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/3_ElasticSearch/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/7.SparkStreaming/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/spark/3.Spark%E7%BC%96%E7%A8%8B2/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/hadoop/hadoop/" title="未命名">未命名</a></span></li><li class="item"><div class="breadcrumb"></div><span><a href="/big-data/flink/4_Kibana/" title="未命名">未命名</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2021</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">Miyazono @ Yume Shoka</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">359k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">5:26</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<a href="https://github.com/amehime/hexo-theme-shoka">Shoka</a></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"big-data/hive/Hive 学习/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->